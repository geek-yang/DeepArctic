{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Predict the Spatial Sea Ice Concentration with ConvLSTM at weekly time scale** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2020.03.27 ** <br>\n",
    "** Last Update  : 2020.03.27 ** <br>\n",
    "** Library      : Pytorth, Numpy, NetCDF4, os, iris, cartopy, dlacs, matplotlib **<br>\n",
    "Description     : This notebook serves to predict the Arctic sea ice using deep learning. We also include many climate index (to represent the forcing from atmosphere). The convolutional Long Short Time Memory neural network is used to deal with this spatial-temporal sequence problem. We use Pytorch as the deep learning framework. <br>\n",
    "<br>\n",
    "** Here we predict sea ice concentration with one extra relevant field from either ocean or atmosphere to test the predictor.** <br>\n",
    "\n",
    "Return Values   : Time series and figures <br>\n",
    "\n",
    "The regionalization adopted here follows that of the MASIE (Multisensor Analyzed Sea Ice Extent) product available from the National Snow and Ice Data Center:<br>\n",
    "https://nsidc.org/data/masie/browse_regions<br>\n",
    "It is given by paper J.Walsh et. al., 2019. Benchmark seasonal prediction skill estimates based on regional indices.<br>\n",
    "\n",
    "The method comes from the study by Shi et. al. (2015) Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numbers\n",
    "\n",
    "# for data loading\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "# for pre-processing and machine learning\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#import scipy\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "#sys.path.append(os.path.join('C:','Users','nosta','ML4Climate','Scripts','DeepClim'))\n",
    "sys.path.append(\"C:\\\\Users\\\\nosta\\\\ML4Climate\\\\Scripts\\\\DLACs\")\n",
    "import dlacs\n",
    "import dlacs.ConvLSTM\n",
    "import dlacs.preprocess\n",
    "import dlacs.function\n",
    "import dlacs.saveNetCDF\n",
    "\n",
    "# for visualization\n",
    "import dlacs.visual\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import iris # also helps with regriding\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing device is Dell Inspirion 5680 with Intel Core i7-8700 x64 CPU and Nvidia GTX 1060 6GB GPU.<br>\n",
    "Here is a benchmark about cpu v.s. gtx 1060 <br>\n",
    "https://www.analyticsindiamag.com/deep-learning-tensorflow-benchmark-intel-i5-4210u-vs-geforce-nvidia-1060-6gb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "constant = {'g' : 9.80616,      # gravititional acceleration [m / s2]\n",
    "            'R' : 6371009,      # radius of the earth [m]\n",
    "            'cp': 1004.64,      # heat capacity of air [J/(Kg*K)]\n",
    "            'Lv': 2264670,      # Latent heat of vaporization [J/Kg]\n",
    "            'R_dry' : 286.9,    # gas constant of dry air [J/(kg*K)]\n",
    "            'R_vap' : 461.5,    # gas constant for water vapour [J/(kg*K)]\n",
    "            'rho' : 1026,       # sea water density [kg/m3]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data ** <br>\n",
    "Time span of each product included: <br>\n",
    "** Reanalysis ** <br>\n",
    "- **ERA-Interim** 1979 - 2016 (ECMWF)\n",
    "- **ORAS4**       1958 - 2014 (ECMWF)\n",
    "\n",
    "** Index ** <br>\n",
    "- **NINO3.4**     1950 - 2017 (NOAA)\n",
    "- **AO**          1950 - 2017 (NOAA)\n",
    "- **NAO**         1950 - 2017 (NOAA)\n",
    "- **AMO**         1950 - 2017 (NOAA)\n",
    "- **PDO**         1950 - 2017 (University of Washington)\n",
    "\n",
    "!! These index are given by NCEP/NCAR Reanalysis (CDAS) <br>\n",
    "\n",
    "\n",
    "Alternative (not in use yet) <br>\n",
    "** Reanalysis ** <br>\n",
    "- **MERRA2**      1980 - 2016 (NASA)\n",
    "- **JRA55**       1979 - 2015 (JMA)\n",
    "- **GLORYS2V3**   1993 - 2014 (Mercartor Ocean)\n",
    "- **SODA3**       1980 - 2015\n",
    "- **PIOMASS**     1980 - 2015\n",
    "\n",
    "** Observations ** <br>\n",
    "- **NSIDC**       1958 - 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# \n",
    "#########                           datapath                             ########\n",
    "#################################################################################\n",
    "# please specify data path\n",
    "#datapath_ERAI = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ERA-Interim'\n",
    "datapath_ERAI = 'H:\\\\Creator_Zone\\\\Core_Database_DeepLearn\\\\ERA-Interim'\n",
    "#datapath_ORAS4 = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ORAS4'\n",
    "datapath_ORAS4 = 'H:\\\\Creator_Zone\\\\Core_Database_DeepLearn\\\\ORAS4'\n",
    "#datapath_ORAS4_mask = '/home/ESLT0068/WorkFlow/Core_Database_AMET_OMET_reanalysis/ORAS4'\n",
    "datapath_ORAS4_mask = 'H:\\\\Creator_Zone\\\\Core_Database_DeepLearn\\\\ORAS4'\n",
    "#output_path = '/home/ESLT0068/NLeSC/Computation_Modeling/ML4Climate/PredictArctic/Maps'\n",
    "output_path = 'C:\\\\Users\\\\nosta\\\\ML4Climate\\\\PredictArctic\\\\Maps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** get the key to the datasets *************************\n",
      "*********************** extract variables *************************\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    print ('*********************** get the key to the datasets *************************')\n",
    "    # weekly variables on ERAI grid\n",
    "    dataset_ERAI_fields_sic = Dataset(os.path.join(datapath_ERAI,\n",
    "                                      'sic_weekly_erai_1979_2017.nc'))\n",
    "    # OHC interpolated on ERA-Interim grid\n",
    "    dataset_ORAS4_OHC = Dataset(os.path.join(datapath_ORAS4,\n",
    "                                'ohc_monthly_oras2erai_1978_2017.nc'))\n",
    "    # mask\n",
    "    dataset_ORAS4_mask = Dataset(os.path.join(datapath_ORAS4_mask, 'mesh_mask.nc'))\n",
    "    print ('*********************** extract variables *************************')\n",
    "    #################################################################################\n",
    "    #########                        data gallery                           #########\n",
    "    #################################################################################\n",
    "    # we use time series from 1979 to 2016 (468 months in total)\n",
    "    # training data: 1979 - 2013\n",
    "    # validation: 2014 - 2016\n",
    "    # variables list:\n",
    "    # SIC (ERA-Interim) / SIV (PIOMASS) / SST (ERA-Interim) / ST (ERA-Interim) / OHC (ORAS4) / AO-NAO-AMO-NINO3.4 (NOAA)\n",
    "    # integrals from spatial fields cover the area from 20N - 90N (4D fields [year, month, lat, lon])\n",
    "    # *************************************************************************************** #\n",
    "    # SIC (ERA-Interim) - benckmark\n",
    "    SIC_ERAI = dataset_ERAI_fields_sic.variables['sic'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "    year_ERAI = dataset_ERAI_fields_sic.variables['year'][:-1]\n",
    "    week_ERAI = dataset_ERAI_fields_sic.variables['week'][:]\n",
    "    latitude_ERAI = dataset_ERAI_fields_sic.variables['latitude'][:]\n",
    "    longitude_ERAI = dataset_ERAI_fields_sic.variables['longitude'][:]\n",
    "    #SIV (PIOMASS)\n",
    "    #SIV_PIOMASS = dataset_PIOMASS_siv.variables['SIV'][:-12]\n",
    "    #year_SIV = dataset_PIOMASS_siv.variables['year'][:-1]\n",
    "    # OHC (ORAS4)\n",
    "    # from 1978 - 2017 (for interpolation) / from 90 N upto 40 N\n",
    "    OHC_300_ORAS4 = dataset_ORAS4_OHC.variables['OHC'][:-1,:,:67,:]/1000 # unit Peta Joule\n",
    "    latitude_ORAS4 = dataset_ORAS4_OHC.variables['latitude'][:]\n",
    "    longitude_ORAS4 = dataset_ORAS4_OHC.variables['longitude'][:]\n",
    "    mask_OHC = np.ma.getmask(OHC_300_ORAS4[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** create mask *************************\n",
      "*********************** calc mask *************************\n",
      "*********************** packing *************************\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ###########                 global land-sea mask                      ###########\n",
    "    #################################################################################\n",
    "    sea_ice_mask_global = np.ones((len(latitude_ERAI),len(longitude_ERAI)),dtype=float)\n",
    "    sea_ice_mask_global[SIC_ERAI[0,0,:,:]==-1] = 0\n",
    "    #################################################################################\n",
    "    ###########                regionalization sea mask                   ###########\n",
    "    #################################################################################\n",
    "    print ('*********************** create mask *************************')\n",
    "    # W:-156 E:-124 N:80 S:67\n",
    "    mask_Beaufort = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:-180 E:-156 N:80 S:66\n",
    "    mask_Chukchi = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:146 E:180 N:80 S:67\n",
    "    mask_EastSiberian = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:100 E:146 N:80 S:67\n",
    "    mask_Laptev = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:60 E:100 N:80 S:67\n",
    "    mask_Kara = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:18 E:60 N:80 S:64\n",
    "    mask_Barents = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:-44 E:18 N:80 S:55\n",
    "    mask_Greenland = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:-180 E:180 N:90 S:80\n",
    "    mask_CenArctic = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    print ('*********************** calc mask *************************')\n",
    "    mask_Beaufort[13:31,32:76] = 1\n",
    "\n",
    "    mask_Chukchi[13:32,0:32] = 1\n",
    "    mask_Chukchi[13:32,-1] = 1\n",
    "\n",
    "    mask_EastSiberian[13:31,434:479] = 1\n",
    "\n",
    "    mask_Laptev[13:31,374:434] = 1\n",
    "\n",
    "    mask_Kara[13:31,320:374] = 1\n",
    "\n",
    "    mask_Barents[13:36,264:320] = 1\n",
    "\n",
    "    mask_Greenland[13:47,179:264] = 1\n",
    "    mask_Greenland[26:47,240:264] = 0\n",
    "\n",
    "    mask_CenArctic[:13,:] = 1\n",
    "    print ('*********************** packing *************************')\n",
    "    mask_dict = {'Beaufort': mask_Beaufort[:,:],\n",
    "                 'Chukchi': mask_Chukchi[:,:],\n",
    "                 'EastSiberian': mask_EastSiberian[:,:],\n",
    "                 'Laptev': mask_Laptev[:,:],\n",
    "                 'Kara': mask_Kara[:,:],\n",
    "                 'Barents': mask_Barents[:,:],\n",
    "                 'Greenland': mask_Greenland[:,:],\n",
    "                 'CenArctic': mask_CenArctic[:,:]}\n",
    "    seas_namelist = ['Beaufort','Chukchi','EastSiberian','Laptev',\n",
    "                     'Kara', 'Barents', 'Greenland','CenArctic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #################################################################################\n",
    "    ########                  temporal interpolation matrix                  ########\n",
    "    #################################################################################\n",
    "    # interpolate from monthly to weekly\n",
    "    # original monthly data will be taken as the last week of the month\n",
    "    OHC_300_ORAS4_weekly_series = np.zeros(SIC_ERAI.reshape(len(year_ERAI)*48,len(latitude_ERAI),len(longitude_ERAI)).shape,\n",
    "                                           dtype=float)\n",
    "    OHC_300_ORAS4_series= dlacs.preprocess.operator.unfold(OHC_300_ORAS4)\n",
    "    # calculate the difference between two months\n",
    "    OHC_300_ORAS4_deviation_series = (OHC_300_ORAS4_series[1:,:,:] - OHC_300_ORAS4_series[:-1,:,:]) / 4\n",
    "    for i in np.arange(4):\n",
    "        OHC_300_ORAS4_weekly_series[3-i::4,:,:] = OHC_300_ORAS4_series[12:,:,:] - i * OHC_300_ORAS4_deviation_series[11:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************  calculate extent from spatial fields  *******************\n",
      "================  reshape input data into time series  =================\n"
     ]
    }
   ],
   "source": [
    "    print ('******************  calculate extent from spatial fields  *******************')\n",
    "    # size of the grid box\n",
    "    dx = 2 * np.pi * constant['R'] * np.cos(2 * np.pi * latitude_ERAI /\n",
    "                                            360) / len(longitude_ERAI)\n",
    "    dy = np.pi * constant['R'] / 480\n",
    "    # calculate the sea ice area\n",
    "    SIC_ERAI_area = np.zeros(SIC_ERAI.shape, dtype=float)\n",
    "    for i in np.arange(len(latitude_ERAI[:])):\n",
    "        # change the unit to terawatt\n",
    "        SIC_ERAI_area[:,:,i,:] = SIC_ERAI[:,:,i,:]* dx[i] * dy / 1E+6 # unit km2\n",
    "    SIC_ERAI_area[SIC_ERAI_area<0] = 0 # switch the mask from -1 to 0\n",
    "    print ('================  reshape input data into time series  =================')\n",
    "    SIC_ERAI_area_series = dlacs.preprocess.operator.unfold(SIC_ERAI_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************  choose the fields from target region  *******************\n",
      "******************  choose the fields from target region  *******************\n",
      "(1824, 24, 56)\n",
      "(1824, 24, 56)\n",
      "[80.5  79.75 79.   78.25 77.5  76.75 76.   75.25 74.5  73.75 73.   72.25\n",
      " 71.5  70.75 70.   69.25 68.5  67.75 67.   66.25 65.5  64.75 64.   63.25]\n",
      "[18.   18.75 19.5  20.25 21.   21.75 22.5  23.25 24.   24.75 25.5  26.25\n",
      " 27.   27.75 28.5  29.25 30.   30.75 31.5  32.25 33.   33.75 34.5  35.25\n",
      " 36.   36.75 37.5  38.25 39.   39.75 40.5  41.25 42.   42.75 43.5  44.25\n",
      " 45.   45.75 46.5  47.25 48.   48.75 49.5  50.25 51.   51.75 52.5  53.25\n",
      " 54.   54.75 55.5  56.25 57.   57.75 58.5  59.25]\n",
      "[80.5  79.75 79.   78.25 77.5  76.75 76.   75.25 74.5  73.75 73.   72.25\n",
      " 71.5  70.75 70.   69.25 68.5  67.75 67.   66.25 65.5  64.75 64.   63.25]\n",
      "[18.   18.75 19.5  20.25 21.   21.75 22.5  23.25 24.   24.75 25.5  26.25\n",
      " 27.   27.75 28.5  29.25 30.   30.75 31.5  32.25 33.   33.75 34.5  35.25\n",
      " 36.   36.75 37.5  38.25 39.   39.75 40.5  41.25 42.   42.75 43.5  44.25\n",
      " 45.   45.75 46.5  47.25 48.   48.75 49.5  50.25 51.   51.75 52.5  53.25\n",
      " 54.   54.75 55.5  56.25 57.   57.75 58.5  59.25]\n"
     ]
    }
   ],
   "source": [
    "    print ('******************  choose the fields from target region  *******************')\n",
    "    # select land-sea mask\n",
    "    sea_ice_mask_barents = sea_ice_mask_global[12:36,264:320]\n",
    "    print ('******************  choose the fields from target region  *******************')\n",
    "    # select the area between greenland and ice land for instance 60-70 N / 44-18 W\n",
    "    sic_exp = SIC_ERAI_area_series[:,12:36,264:320]\n",
    "    ohc_exp = OHC_300_ORAS4_weekly_series[:,12:36,264:320]\n",
    "    print(sic_exp.shape)\n",
    "    print(ohc_exp.shape)\n",
    "    print(latitude_ERAI[12:36])\n",
    "    print(longitude_ERAI[264:320])\n",
    "    print(latitude_ORAS4[12:36])\n",
    "    print(longitude_ORAS4[264:320])\n",
    "    #print(latitude_ERAI[26:40])\n",
    "    #print(longitude_ERAI[180:216])\n",
    "    #print(sic_exp[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  pre-processing  *********************\n",
      "=========================   normalize data   ===========================\n",
      "================  save the normalizing factor  =================\n",
      "1565.2049481856002 km2\n",
      "0.0 km2\n",
      "====================    A series of time (index)    ====================\n",
      "===================  artificial data for evaluation ====================\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  pre-processing  *********************')\n",
    "    print ('=========================   normalize data   ===========================')\n",
    "    sic_exp_norm = dlacs.preprocess.operator.normalize(sic_exp)\n",
    "    ohc_exp_norm = dlacs.preprocess.operator.normalize(ohc_exp)\n",
    "    print('================  save the normalizing factor  =================')\n",
    "    sic_max = np.amax(sic_exp)\n",
    "    sic_min = np.amin(sic_exp)\n",
    "    print(sic_max,\"km2\")\n",
    "    print(sic_min,\"km2\")\n",
    "    print ('====================    A series of time (index)    ====================')\n",
    "    _, yy, xx = sic_exp_norm.shape # get the lat lon dimension\n",
    "    year = np.arange(1979,2017,1)\n",
    "    year_cycle = np.repeat(year,48)\n",
    "    month_cycle = np.repeat(np.arange(1,13,1),4)\n",
    "    month_cycle = np.tile(month_cycle,len(year)+1) # one extra repeat for lead time dependent prediction\n",
    "    month_cycle.astype(float)\n",
    "    month_2D = np.repeat(month_cycle[:,np.newaxis],yy,1)\n",
    "    month_exp = np.repeat(month_2D[:,:,np.newaxis],xx,2)\n",
    "    print ('===================  artificial data for evaluation ====================')\n",
    "    # calculate climatology of SIC\n",
    "#     seansonal_cycle_SIC = np.zeros(48,dtype=float)\n",
    "#     for i in np.arange(48):\n",
    "#         seansonal_cycle_SIC[i] = np.mean(SIC_ERAI_sum_norm[i::48],axis=0)\n",
    "    # weight for loss\n",
    "#     weight_month = np.array([0,1,1,\n",
    "#                              1,0,0,\n",
    "#                              1,1,1,\n",
    "#                              0,0,0])\n",
    "    #weight_loss = np.repeat(weight_month,4)\n",
    "    #weight_loss = np.tile(weight_loss,len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565.2049481856002\n",
      "0.0\n",
      "(1824, 24, 56)\n",
      "[[251.4346045  251.05600413 250.50871172 ... 244.2139345  244.13173904\n",
      "  244.01692955]\n",
      " [246.64799721 246.04600942 245.45885542 ... 245.36829478 245.24715214\n",
      "  245.12353721]\n",
      " [246.7402512  247.31849816 248.16998491 ... 246.47754407 246.37387686\n",
      "  246.26773736]\n",
      " ...\n",
      " [271.39089775 271.56084288 271.75937185 ... 272.40565781 271.30805881\n",
      "  270.25455477]\n",
      " [271.93968032 272.07067828 272.09157428 ... 273.35488503 272.4173081\n",
      "  271.39831464]\n",
      " [272.82825155 272.92514534 272.69329114 ... 274.15672261 273.34753587\n",
      "  272.70551716]]\n",
      "(24, 56)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    print(t2m_exp.shape)\n",
    "    ax = plt.contourf(t2m_exp[443,:,:])\n",
    "    print(t2m_exp[443,:,:])\n",
    "    print(month_exp[0,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26267704 0.26046318 0.25661401 ... 0.22950646 0.22708498 0.22442972]\n",
      " [0.20302922 0.20179229 0.20073181 ... 0.23818486 0.23636252 0.23451899]\n",
      " [0.19524795 0.20810658 0.22415041 ... 0.25322432 0.25219251 0.25112267]\n",
      " ...\n",
      " [0.48474634 0.48954066 0.49081374 ... 0.36213768 0.336037   0.3028926 ]\n",
      " [0.49387301 0.5059012  0.52108218 ... 0.37193518 0.34423099 0.31239209]\n",
      " [0.52729484 0.54777388 0.5776589  ... 0.38700331 0.35481465 0.32946398]]\n",
      "(4, 24, 56)\n"
     ]
    }
   ],
   "source": [
    "    x_input = np.stack((sic_exp_norm[1,:,:],\n",
    "                        t2m_exp_norm[1,:,:],\n",
    "                        ohc_exp_norm[1,:,:],\n",
    "                        month_exp[1,:,:]))\n",
    "    print(x_input[1,:,:])\n",
    "    print(x_input[:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure for LSTM <br>\n",
    "** We use Pytorth to implement LSTM neural network with time series of climate data. ** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  parameter for check  *********************\n",
      "*******************  create basic dimensions for tensor and network  *********************\n",
      "1.1.0\n",
      "Is CUDA available? True\n",
      "*******************  cross validation and testing data  *********************\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  parameter for check  *********************')\n",
    "    choice_exp_norm = ohc_exp_norm\n",
    "    print ('*******************  create basic dimensions for tensor and network  *********************')\n",
    "    # specifications of neural network\n",
    "    input_channels = 3\n",
    "    #hidden_channels = [3, 2, 1] # number of channels & hidden layers, the channels of last layer is the channels of output, too\n",
    "    #hidden_channels = [3, 3, 3, 3, 2]\n",
    "    hidden_channels = [1]\n",
    "    kernel_size = 3\n",
    "    # here we input a sequence and predict the next step only\n",
    "    #step = 1 # how many steps to predict ahead\n",
    "    #effective_step = [0] # step to output\n",
    "    batch_size = 1\n",
    "    #num_layers = 1\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 500\n",
    "    print (torch.__version__)\n",
    "    # check if CUDA is available\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(\"Is CUDA available? {}\".format(use_cuda))\n",
    "    # CUDA settings torch.__version__ must > 0.4\n",
    "    # !!! This is important for the model!!! The first option is gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print ('*******************  cross validation and testing data  *********************')\n",
    "    # take 10% data as cross-validation data\n",
    "    cross_valid_year = 4\n",
    "    # take 10% years as testing data\n",
    "    test_year = 4\n",
    "    # minibatch\n",
    "    #iterations = 3 # training data divided into 3 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  preview of input tensor  *********************\n",
      "1824\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  preview of input tensor  *********************')\n",
    "    #plt.plot(SIC_ERAI_sum)\n",
    "    #print(SIC_ERAI_sum_norm[:-test_year*12])\n",
    "    #print(x_input.shape)\n",
    "    #print(x_input[:,:,:])\n",
    "    sequence_len, _, _ = sic_exp_norm.shape\n",
    "    print(sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print ('*******************  module for calculating accuracy  *********************')\n",
    "#     def accuracy(out, labels):\n",
    "#         outputs = np.argmax(out, axis=1)\n",
    "#     return np.sum(outputs==labels)/float(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  load exsited LSTM model  *********************\n",
      "ConvLSTM(\n",
      "  (cell0): ConvLSTMCell(\n",
      "    (Wxi): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whi): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxf): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whf): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxc): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whc): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxo): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Who): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "Wall time: 37.9 ms\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print ('*******************  load exsited LSTM model  *********************')\n",
    "    # load model parameters\n",
    "    model = dlacs.ConvLSTM.ConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(output_path, 'convlstm_era_sic_oras_ohc_Barents_hl_1_kernel_3_lr_0.01_epoch_500_validSIC.pkl'),\n",
    "                                     map_location=device))\n",
    "    #model = torch.load(os.path.join(output_path, 'Barents','convlstm_era_sic_z850_Barents_hl_3_kernel_3_lr_0.005_epoch_1500_validSIC.pkl'))\n",
    "    print(model)\n",
    "    # check the sequence length (dimension in need for post-processing)\n",
    "    sequence_len, height, width = sic_exp_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  run LSTM  *********************\n",
      "The model is designed to make many to one prediction.\n",
      "A series of multi-chanel variables will be input to the model.\n",
      "The model learns by verifying the output at each timestep.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM(\n",
      "  (cell0): ConvLSTMCell(\n",
      "    (Wxi): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whi): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxf): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whf): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxc): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Whc): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (Wxo): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (Who): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  run LSTM  *********************')\n",
    "    print ('The model is designed to make many to one prediction.')\n",
    "    print ('A series of multi-chanel variables will be input to the model.')\n",
    "    print ('The model learns by verifying the output at each timestep.')\n",
    "    # check the sequence length\n",
    "    sequence_len, height, width = sic_exp_norm.shape\n",
    "\n",
    "    # initialize our model\n",
    "    model = dlacs.ConvLSTM.ConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    loss_fn = torch.nn.MSELoss(size_average=True)\n",
    "    # stochastic gradient descent\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # Adam optimizer\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(model)\n",
    "    print(loss_fn)\n",
    "    print(optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell0.Wxi.weight\n",
      "tensor([[[[ 0.1471,  0.1546,  0.1804],\n",
      "          [-0.0623,  0.1344,  0.0143],\n",
      "          [-0.0706, -0.1344, -0.0659]],\n",
      "\n",
      "         [[-0.1899, -0.1006, -0.0626],\n",
      "          [-0.1409, -0.0492,  0.1408],\n",
      "          [-0.0304, -0.1617,  0.0958]],\n",
      "\n",
      "         [[ 0.0922, -0.1399, -0.0059],\n",
      "          [ 0.0494,  0.0600, -0.1834],\n",
      "          [-0.1335,  0.0242, -0.1719]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxi.bias\n",
      "tensor([0.0106], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Whi.weight\n",
      "tensor([[[[-0.0101,  0.2697,  0.2264],\n",
      "          [ 0.3265, -0.1155, -0.2117],\n",
      "          [ 0.2380,  0.2017,  0.3228]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf.weight\n",
      "tensor([[[[-0.0451, -0.1699, -0.0752],\n",
      "          [ 0.0125,  0.1685, -0.1466],\n",
      "          [ 0.1300, -0.0386,  0.0511]],\n",
      "\n",
      "         [[ 0.0829,  0.1438,  0.0772],\n",
      "          [ 0.1325, -0.0713,  0.1843],\n",
      "          [ 0.1822,  0.1320,  0.1737]],\n",
      "\n",
      "         [[-0.0680,  0.1750,  0.1705],\n",
      "          [-0.1772, -0.0527,  0.1196],\n",
      "          [-0.0104, -0.1320,  0.0184]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf.bias\n",
      "tensor([-0.0669], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Whf.weight\n",
      "tensor([[[[-0.3307,  0.0557, -0.2241],\n",
      "          [ 0.0460,  0.2257,  0.2412],\n",
      "          [-0.1946, -0.0946,  0.3123]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc.weight\n",
      "tensor([[[[-0.1467,  0.1874, -0.1694],\n",
      "          [ 0.0497, -0.1013, -0.1464],\n",
      "          [ 0.0449, -0.0977,  0.1821]],\n",
      "\n",
      "         [[ 0.1470, -0.1270,  0.1297],\n",
      "          [ 0.1512, -0.1789,  0.0409],\n",
      "          [ 0.1748,  0.0257,  0.1638]],\n",
      "\n",
      "         [[ 0.1060,  0.1502,  0.1561],\n",
      "          [-0.0750,  0.0174,  0.1151],\n",
      "          [ 0.1726, -0.0516, -0.0550]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc.bias\n",
      "tensor([-0.1402], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Whc.weight\n",
      "tensor([[[[-0.1359,  0.1321,  0.0763],\n",
      "          [-0.2653,  0.1883, -0.1193],\n",
      "          [ 0.0019, -0.2462,  0.2233]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo.weight\n",
      "tensor([[[[ 0.0513,  0.1010, -0.1900],\n",
      "          [ 0.1171, -0.1054,  0.1125],\n",
      "          [-0.1071, -0.1114,  0.0328]],\n",
      "\n",
      "         [[ 0.0926,  0.0848, -0.0740],\n",
      "          [ 0.0941, -0.1702,  0.0557],\n",
      "          [-0.0240, -0.0372, -0.1604]],\n",
      "\n",
      "         [[-0.1118,  0.0395,  0.1729],\n",
      "          [-0.1345,  0.0069,  0.1352],\n",
      "          [ 0.1725, -0.1199,  0.0226]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo.bias\n",
      "tensor([-0.1672], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Who.weight\n",
      "tensor([[[[ 0.0959, -0.3212,  0.0952],\n",
      "          [ 0.0960,  0.3163, -0.2606],\n",
      "          [-0.0476,  0.2521,  0.2545]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print (name)\n",
    "            print (param.data)\n",
    "            print (param.size())\n",
    "            print (\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('##############################################################')\n",
    "    print('#############  preview model parameters matrix  ###############')\n",
    "    print('##############################################################')\n",
    "    print('Number of parameter matrices: ', len(list(model.parameters())))\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell0.Wxi.weight\n",
      "tensor([[[[ 0.2100,  0.2937,  0.2441],\n",
      "          [ 0.6942,  1.8515,  0.4301],\n",
      "          [ 0.2743,  0.3660,  0.3679]],\n",
      "\n",
      "         [[ 0.0503,  0.0342,  0.1289],\n",
      "          [ 0.1278,  0.0318,  0.0518],\n",
      "          [-0.1734, -0.1264,  0.1462]],\n",
      "\n",
      "         [[ 0.2020, -0.1442, -0.0084],\n",
      "          [-0.0990,  0.0531, -0.0742],\n",
      "          [-0.0510,  0.1205,  0.0665]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxi.bias\n",
      "tensor([-0.2394], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Whi.weight\n",
      "tensor([[[[-0.4486, -0.5492, -0.5339],\n",
      "          [-0.9652, -0.4239, -0.7970],\n",
      "          [-0.0928, -0.3976, -0.1379]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf.weight\n",
      "tensor([[[[-0.0477,  0.0252, -0.0036],\n",
      "          [ 0.2305,  2.0422,  0.2321],\n",
      "          [-0.3835, -0.1172, -0.5815]],\n",
      "\n",
      "         [[-0.1524, -0.0603,  0.1648],\n",
      "          [-0.3124, -0.1034,  0.0684],\n",
      "          [-0.1934, -0.3385, -0.3151]],\n",
      "\n",
      "         [[-0.0791, -0.0115, -0.0047],\n",
      "          [ 0.0389, -0.2054,  0.0306],\n",
      "          [-0.1190,  0.0676, -0.0252]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf.bias\n",
      "tensor([-1.2185], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Whf.weight\n",
      "tensor([[[[ 0.1940,  0.1679,  0.2023],\n",
      "          [-0.0573,  0.1419, -0.0281],\n",
      "          [ 0.1701,  0.0272,  0.2145]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc.weight\n",
      "tensor([[[[ 5.7357e-02,  8.9240e-02,  1.0976e-01],\n",
      "          [ 3.2863e-02,  2.2477e+00,  1.1710e-01],\n",
      "          [ 4.2918e-02,  6.5531e-02,  1.8771e-02]],\n",
      "\n",
      "         [[-1.8873e-02, -6.1826e-03, -1.7936e-02],\n",
      "          [ 6.5975e-03,  8.4340e-03, -8.5399e-03],\n",
      "          [-1.1180e-03,  2.8609e-03,  6.0633e-03]],\n",
      "\n",
      "         [[ 8.1273e-03, -1.2963e-02, -7.9271e-05],\n",
      "          [ 2.9753e-02, -3.8650e-02,  1.8675e-02],\n",
      "          [-3.6463e-02,  5.1926e-02, -1.8019e-02]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc.bias\n",
      "tensor([0.0168], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Whc.weight\n",
      "tensor([[[[-0.0363, -0.0860, -0.0609],\n",
      "          [-0.1173, -0.3630, -0.1617],\n",
      "          [-0.0388, -0.0808, -0.0198]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo.weight\n",
      "tensor([[[[ 0.5034,  0.5281,  0.5978],\n",
      "          [ 1.0651,  1.5054,  1.0440],\n",
      "          [ 0.3690,  0.6871,  0.6593]],\n",
      "\n",
      "         [[-0.0596, -0.1672, -0.1365],\n",
      "          [ 0.0758, -0.1214, -0.1284],\n",
      "          [ 0.1358,  0.2425,  0.0062]],\n",
      "\n",
      "         [[-0.0804,  0.0453,  0.0051],\n",
      "          [ 0.0773, -0.0517, -0.2029],\n",
      "          [ 0.0948,  0.0304,  0.1601]]]], device='cuda:0')\n",
      "torch.Size([1, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo.bias\n",
      "tensor([0.0028], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell0.Who.weight\n",
      "tensor([[[[-0.1663, -0.1250, -0.1106],\n",
      "          [ 0.1931,  0.3003,  0.3597],\n",
      "          [-0.3523,  0.1148, -0.2699]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print (name)\n",
    "            print (param.data)\n",
    "            print (param.size())\n",
    "            print (\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "##################  start training loop  #####################\n",
      "##############################################################\n",
      "Epoch  0 MSE:  82.4634780883789\n",
      "Epoch  10 MSE:  41.403411865234375\n",
      "Epoch  20 MSE:  28.646265029907227\n",
      "Epoch  30 MSE:  23.70143699645996\n",
      "Epoch  40 MSE:  19.04079246520996\n",
      "Epoch  50 MSE:  14.740525245666504\n",
      "Epoch  60 MSE:  10.664468765258789\n",
      "Epoch  70 MSE:  8.548810958862305\n",
      "Epoch  80 MSE:  7.227262020111084\n",
      "Epoch  90 MSE:  6.322158336639404\n",
      "Epoch  100 MSE:  5.330409526824951\n",
      "Epoch  110 MSE:  4.553230285644531\n",
      "Epoch  120 MSE:  4.067165374755859\n",
      "Epoch  130 MSE:  3.8071792125701904\n",
      "Epoch  140 MSE:  3.4318900108337402\n",
      "Epoch  150 MSE:  3.194655418395996\n",
      "Epoch  160 MSE:  3.6786718368530273\n",
      "Epoch  170 MSE:  3.1180269718170166\n",
      "Epoch  180 MSE:  2.938451051712036\n",
      "Epoch  190 MSE:  2.8304226398468018\n",
      "Epoch  200 MSE:  2.763756275177002\n",
      "Epoch  210 MSE:  2.7328269481658936\n",
      "Epoch  220 MSE:  2.69623064994812\n",
      "Epoch  230 MSE:  2.8117799758911133\n",
      "Epoch  240 MSE:  2.805446147918701\n",
      "Epoch  250 MSE:  2.7205724716186523\n",
      "Epoch  260 MSE:  2.6301205158233643\n",
      "Epoch  270 MSE:  2.619652032852173\n",
      "Epoch  280 MSE:  2.5976831912994385\n",
      "Epoch  290 MSE:  2.5874123573303223\n",
      "Epoch  300 MSE:  2.5644335746765137\n",
      "Epoch  310 MSE:  2.6312572956085205\n",
      "Epoch  320 MSE:  2.7439019680023193\n",
      "Epoch  330 MSE:  2.5847439765930176\n",
      "Epoch  340 MSE:  2.58103609085083\n",
      "Epoch  350 MSE:  2.548860549926758\n",
      "Epoch  360 MSE:  2.5279769897460938\n",
      "Epoch  370 MSE:  2.518894672393799\n",
      "Epoch  380 MSE:  2.5029850006103516\n",
      "Epoch  390 MSE:  2.5001165866851807\n",
      "Epoch  400 MSE:  2.4900927543640137\n",
      "Epoch  410 MSE:  2.955949306488037\n",
      "Epoch  420 MSE:  2.6040451526641846\n",
      "Epoch  430 MSE:  2.5505926609039307\n",
      "Epoch  440 MSE:  2.5085885524749756\n",
      "Epoch  450 MSE:  2.4810636043548584\n",
      "Epoch  460 MSE:  2.4613776206970215\n",
      "Epoch  470 MSE:  2.4553682804107666\n",
      "Epoch  480 MSE:  2.4528443813323975\n",
      "Epoch  490 MSE:  2.43935489654541\n",
      "Wall time: 1h 6min 57s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print('##############################################################')\n",
    "    print('##################  start training loop  #####################')\n",
    "    print('##############################################################')\n",
    "    hist = np.zeros(num_epochs)\n",
    "    # loop of epoch\n",
    "    for t in range(num_epochs):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "        # loop of timestep\n",
    "        for timestep in range(sequence_len - cross_valid_year*12*4 - test_year*12*4):\n",
    "            # hidden state re-initialized inside the model when timestep=0\n",
    "            #################################################################################\n",
    "            ########          create input tensor with multi-input dimension         ########\n",
    "            #################################################################################\n",
    "            # create variables\n",
    "            x_input = np.stack((sic_exp_norm[timestep,:,:],\n",
    "                                choice_exp_norm[timestep,:,:],\n",
    "                                month_exp[timestep,:,:])) #vstack,hstack,dstack\n",
    "            x_var = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width)).to(device)\n",
    "            #################################################################################\n",
    "            ########       create training tensor with multi-input dimension         ########\n",
    "            #################################################################################\n",
    "            y_train_stack = sic_exp_norm[timestep+1,:,:] #vstack,hstack,dstack\n",
    "            y_var = torch.autograd.Variable(torch.Tensor(y_train_stack).view(-1,hidden_channels[-1],height,width)).to(device)\n",
    "            #################################################################################   \n",
    "            # Forward pass\n",
    "            y_pred, _ = model(x_var, timestep)\n",
    "            # choose training data\n",
    "            y_train = y_var        \n",
    "            # torch.nn.functional.mse_loss(y_pred, y_train) can work with (scalar,vector) & (vector,vector)\n",
    "            # Please Make Sure y_pred & y_train have the same dimension\n",
    "            # accumulate loss\n",
    "            if timestep == 0:\n",
    "                loss = loss_fn(y_pred, y_train)\n",
    "            else:\n",
    "                loss += loss_fn(y_pred, y_train)\n",
    "            #print (timestep)\n",
    "        #print(y_pred.shape)\n",
    "        #print(y_train.shape)\n",
    "        # print loss at certain iteration\n",
    "        if t % 10 == 0:\n",
    "            print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "            #print(y_pred)\n",
    "            # gradient check\n",
    "            # Gradcheck requires double precision numbers to run\n",
    "            #res = torch.autograd.gradcheck(loss_fn, (y_pred.double(), y_train.double()), eps=1e-6, raise_exception=True)\n",
    "            #print(res)\n",
    "        hist[t] = loss.item()\n",
    "\n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "    # save the model\n",
    "    # (recommended) save the model parameters only\n",
    "    torch.save(model.state_dict(), os.path.join(output_path,'convlstm.pkl'))\n",
    "    # save the entire model\n",
    "    #torch.save(model, os.path.join(output_path,'convlstm.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  Loss with time  **********************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    print (\"*******************  Loss with time  **********************\")\n",
    "    fig00 = plt.figure()\n",
    "    try:\n",
    "        plt.plot(hist, label=\"Training loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        fig00.savefig(os.path.join(output_path,'SIC_ERAI_LSTM_pred_error.png'),dpi=200)\n",
    "    except:\n",
    "        print('Model is reloaded instead of trained!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  evaluation matrix  *********************\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  evaluation matrix  *********************')\n",
    "    # The prediction will be evaluated through RMSE against climatology\n",
    "    \n",
    "    # error score for temporal-spatial fields, without keeping spatial pattern\n",
    "    def RMSE(x,y):\n",
    "        \"\"\"\n",
    "        Calculate the RMSE. x is input series and y is reference series.\n",
    "        It calculates RMSE over the domain, not over time. The spatial structure\n",
    "        will not be kept.\n",
    "        Parameter\n",
    "        ----------------------\n",
    "        x: input time series with the shape [time, lat, lon]\n",
    "        \"\"\"\n",
    "        x_series = x.reshape(x.shape[0],-1)\n",
    "        y_series = y.reshape(y.shape[0],-1)\n",
    "        rmse = np.sqrt(np.mean((x_series - y_series)**2,1))\n",
    "        rmse_std = np.sqrt(np.std((x_series - y_series)**2,1))\n",
    "    \n",
    "        return rmse, rmse_std\n",
    "    \n",
    "    # error score for temporal-spatial fields, keeping spatial pattern\n",
    "    def MAE(x,y):\n",
    "        \"\"\"\n",
    "        Calculate the MAE. x is input series and y is reference series.\n",
    "        It calculate MAE over time and keeps the spatial structure.\n",
    "        \"\"\"\n",
    "        mae = np.mean(np.abs(x-y),0)\n",
    "        \n",
    "        return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "###################  start prediction loop ###################\n",
      "##############################################################\n",
      "*******************************  one step ahead forecast  *********************************\n",
      "************  the last 4 years of total time series are treated as test data  ************\n",
      "Save output fields as netCDF4 files.\n",
      "Create netcdf files successfully!!\n",
      "Wall time: 12min 35s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    #################################################################################\n",
    "    ########  operational lead time dependent prediction with testing data   ########\n",
    "    #################################################################################\n",
    "    print('##############################################################')\n",
    "    print('###################  start prediction loop ###################')\n",
    "    print('##############################################################')\n",
    "    # the model learn from time series and try to predict the next time step based on the previous time series\n",
    "    print ('*******************************  one step ahead forecast  *********************************')\n",
    "    print ('************  the last {} years of total time series are treated as test data  ************'.format(test_year))\n",
    "    # time series before test data\n",
    "    pred_base_sic = sic_exp_norm[:-test_year*12*4,:,:]\n",
    "    # predict x steps ahead\n",
    "    step_lead = 16 # unit week\n",
    "    # create a matrix for the prediction\n",
    "    lead_pred_sic = np.zeros((test_year*12*4,step_lead,height,width),dtype=float) # dim [predict time, lead time, lat, lon]\n",
    "    # save output as nc file\n",
    "    ncKey = dlacs.saveNetCDF.savenc(output_path, 'pred_sic.nc')\n",
    "    # start the prediction loop\n",
    "    for step in range(test_year*12*4):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "        # Don't do this if you want your LSTM to be stateful\n",
    "        # Otherwise the hidden state should be cleaned up at each time step for prediction (we don't clear hidden state in our forward function)\n",
    "        # see example from (https://github.com/pytorch/examples/blob/master/time_sequence_prediction/train.py)\n",
    "        # model.hidden = model.init_hidden()\n",
    "        # based on the design of this module, the hidden states and cell states are initialized when the module is called.\n",
    "        for i in np.arange(1,sequence_len-test_year*12*4 + step + step_lead,1): # here i is actually the time step (index) of prediction, we use var[:i] to predict var[i]\n",
    "            #############################################################################\n",
    "            ###############           before time of prediction           ###############\n",
    "            #############################################################################\n",
    "            if i <= (sequence_len-test_year*12*4 + step):\n",
    "                # create variables\n",
    "                x_input = np.stack((sic_exp_norm[i-1,:,:],\n",
    "                                    choice_exp_norm[i-1,:,:],\n",
    "                                    month_exp[i-1,:,:])) #vstack,hstack,dstack\n",
    "                x_var_pred = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width),\n",
    "                                                     requires_grad=False).to(device)\n",
    "                # make prediction\n",
    "                last_pred, _ = model(x_var_pred, i-1)\n",
    "                # record the real prediction after the time of prediction\n",
    "                if i == (sequence_len-test_year*12*4 + step):\n",
    "                    lead = 0\n",
    "                    # GPU data should be transferred to CPU\n",
    "                    lead_pred_sic[step,0,:,:] = last_pred[0,0,:,:].cpu().data.numpy()\n",
    "            #############################################################################\n",
    "            ###############            after time of prediction           ###############\n",
    "            #############################################################################\n",
    "            else:\n",
    "                lead += 1\n",
    "                # prepare predictor\n",
    "                if i <= sequence_len:\n",
    "                    # use the predicted data to make new prediction\n",
    "                    x_input = np.stack((lead_pred_sic[step,i-(sequence_len-test_year*12*4 + step +1),:,:],\n",
    "                                        choice_exp_norm[i-1,:,:],\n",
    "                                        month_exp[i-1,:,:])) #vstack,hstack,dstack\n",
    "                else: # choice_exp_norm out of range, use the last value\n",
    "                    x_input = np.stack((lead_pred_sic[step,i-(sequence_len-test_year*12*4 + step +1),:,:],\n",
    "                                        choice_exp_norm[-1,:,:],\n",
    "                                        month_exp[i-1,:,:])) #vstack,hstack,dstack                    \n",
    "                x_var_pred = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width),\n",
    "                                                     requires_grad=False).to(device)\n",
    "                # make prediction\n",
    "                last_pred, _ = model(x_var_pred, i-1)\n",
    "                # record the prediction\n",
    "                lead_pred_sic[step,lead,:,:] = last_pred[0,0,:,:].cpu().data.numpy()\n",
    "    ncKey.ncfile(lead_pred_sic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week2month(series, m):\n",
    "    \"\"\"\n",
    "    Select certain month from yearly data at weekly resolution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : array-like\n",
    "        Three-dimensional numeric arrays with time as the first dimenison [time, lat, lon]\n",
    "    m: int\n",
    "        Month (from 1 to 12).\n",
    "    \"\"\"\n",
    "    time_year, lat, lon = series.shape\n",
    "    time_month = time_year // 12\n",
    "    series_month = np.zeros((time_month, lat, lon), dtype=float)\n",
    "    series_month[::4,:,:] = series[(m-1)*4::48,:,:]\n",
    "    series_month[1::4,:,:] = series[(m-1)*4+1::48,:,:]\n",
    "    series_month[2::4,:,:] = series[(m-1)*4+2::48,:,:]\n",
    "    series_month[3::4,:,:] = series[(m-1)*4+3::48,:,:]\n",
    "    \n",
    "    return series_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "############   start prediction with climatology  ############\n",
      "##############################################################\n",
      "##############################################################\n",
      "############   start prediction with persistence  ############\n",
      "##############################################################\n",
      "##############################################################\n",
      "########   land-sea correction for sic prediction    #########\n",
      "##############################################################\n",
      "#################################################################################\n",
      "############   evaluation and statistical matrix for the entire year ############\n",
      "#################################################################################\n",
      "*******************     Lead time 0     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "50.706676528696136 +- 101.52656804735905\n",
      "Mean RMSE with testing data - Climatology\n",
      "137.91125915081744 +- 212.30182952186146\n",
      "Mean RMSE with testing data - Persistence\n",
      "50.170794466755474 +- 104.00027668956385\n",
      "*******************     Lead time 1     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "73.80067980850241 +- 143.49283429508566\n",
      "Mean RMSE with testing data - Persistence\n",
      "75.9458837476023 +- 153.19988772374379\n",
      "*******************     Lead time 2     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "87.97012328792476 +- 167.7852734894779\n",
      "Mean RMSE with testing data - Persistence\n",
      "93.91398900099325 +- 186.0275468269465\n",
      "*******************     Lead time 3     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "98.5188860402766 +- 185.6837423753026\n",
      "Mean RMSE with testing data - Persistence\n",
      "110.1283583502817 +- 213.094235734779\n",
      "*******************     Lead time 4     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "107.31380808774915 +- 198.38616487734134\n",
      "Mean RMSE with testing data - Persistence\n",
      "124.67600441157826 +- 234.89027045606795\n",
      "*******************     Lead time 5     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "114.11048065520377 +- 207.20630612685207\n",
      "Mean RMSE with testing data - Persistence\n",
      "138.19688180429785 +- 253.81677913415027\n",
      "*******************     Lead time 6     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "120.01947589345633 +- 214.58713240940858\n",
      "Mean RMSE with testing data - Persistence\n",
      "149.77746834844268 +- 270.6962810970926\n",
      "*******************     Lead time 7     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "124.84219094751715 +- 218.869082473999\n",
      "Mean RMSE with testing data - Persistence\n",
      "159.60545845774672 +- 284.95967429502997\n",
      "*******************     Lead time 8     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "128.7138520548639 +- 221.84704752394927\n",
      "Mean RMSE with testing data - Persistence\n",
      "169.0739008031674 +- 298.8606259213634\n",
      "*******************     Lead time 9     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "131.58849734108065 +- 222.60721890135395\n",
      "Mean RMSE with testing data - Persistence\n",
      "178.18772775645525 +- 312.3710063626479\n",
      "*******************     Lead time 10     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "134.20592838035523 +- 222.89458852948098\n",
      "Mean RMSE with testing data - Persistence\n",
      "186.4387677456621 +- 324.1197528679833\n",
      "*******************     Lead time 11     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "136.4485921157947 +- 222.887362112187\n",
      "Mean RMSE with testing data - Persistence\n",
      "193.67677658258384 +- 334.85034457777834\n",
      "*******************     Lead time 12     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "138.1939411275557 +- 221.5000900636044\n",
      "Mean RMSE with testing data - Persistence\n",
      "200.32998646154147 +- 343.7878046378051\n",
      "*******************     Lead time 13     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "139.60593380026867 +- 219.41595016377573\n",
      "Mean RMSE with testing data - Persistence\n",
      "206.51543766766818 +- 351.4327196584504\n",
      "*******************     Lead time 14     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "140.67190120656565 +- 217.0785990279794\n",
      "Mean RMSE with testing data - Persistence\n",
      "212.35298561146928 +- 358.3893891527145\n",
      "*******************     Lead time 15     *******************\n",
      "Mean RMSE with testing data - ConvLSTM\n",
      "142.5877510277676 +- 215.99804451496826\n",
      "Mean RMSE with testing data - Persistence\n",
      "218.3251307542433 +- 365.56173747786585\n",
      "##############################################################\n",
      "############           create a txt file          ############\n",
      "##############################################################\n",
      "*******************    1     *******************\n",
      "RMSE - ConvLSTM       90.03199503565503 + - 176.79836619229437\n",
      "RMSE - Climatology    183.7509720006571 + - 280.49158911076336\n",
      "RMSE - Persistence    91.5997479178463 + - 180.9916370668999\n",
      "*******************    2     *******************\n",
      "RMSE - ConvLSTM       85.42853607325918 + - 170.12721098131493\n",
      "RMSE - Climatology    183.30330023934812 + - 273.347176573773\n",
      "RMSE - Persistence    82.42039524259681 + - 160.9626777381962\n",
      "*******************    3     *******************\n",
      "RMSE - ConvLSTM       80.57466662639172 + - 148.43041863129613\n",
      "RMSE - Climatology    199.89157834353045 + - 304.6694702911925\n",
      "RMSE - Persistence    83.91081918286545 + - 157.80740953153088\n",
      "*******************    4     *******************\n",
      "RMSE - ConvLSTM       73.26888508374091 + - 139.66337783029985\n",
      "RMSE - Climatology    207.80614115696767 + - 313.8306190145979\n",
      "RMSE - Persistence    76.4423650624924 + - 151.35030443127886\n",
      "*******************    5     *******************\n",
      "RMSE - ConvLSTM       60.01419233058145 + - 114.76646554868893\n",
      "RMSE - Climatology    182.62746359795213 + - 261.6904610096677\n",
      "RMSE - Persistence    69.48336388255558 + - 138.76485236989456\n",
      "*******************    6     *******************\n",
      "RMSE - ConvLSTM       36.12961583718595 + - 83.99245611134056\n",
      "RMSE - Climatology    149.31103629366999 + - 224.27726748630144\n",
      "RMSE - Persistence    46.7494984784352 + - 108.87355954907032\n",
      "*******************    7     *******************\n",
      "RMSE - ConvLSTM       18.469664978555283 + - 44.83353200868966\n",
      "RMSE - Climatology    73.29991659481595 + - 129.15866781119783\n",
      "RMSE - Persistence    23.531599159186072 + - 60.06396625220598\n",
      "*******************    8     *******************\n",
      "RMSE - ConvLSTM       17.788191297756605 + - 42.45268822018319\n",
      "RMSE - Climatology    46.699229356606295 + - 95.94623801740428\n",
      "RMSE - Persistence    10.98501001991176 + - 29.099367694308427\n",
      "*******************    9     *******************\n",
      "RMSE - ConvLSTM       17.088487755091954 + - 35.9739502981632\n",
      "RMSE - Climatology    42.771801967839494 + - 84.80483251772198\n",
      "RMSE - Persistence    5.635869541447041 + - 14.67266230343604\n",
      "*******************    10     *******************\n",
      "RMSE - ConvLSTM       28.363484686519065 + - 53.370271119785706\n",
      "RMSE - Climatology    72.14880256647942 + - 122.6752667121632\n",
      "RMSE - Persistence    14.224962737838037 + - 31.34599103819741\n",
      "*******************    11     *******************\n",
      "RMSE - ConvLSTM       36.86205923514393 + - 78.88086771393324\n",
      "RMSE - Climatology    147.2286115015819 + - 210.92864385138375\n",
      "RMSE - Persistence    30.528658826634373 + - 76.59773465361295\n",
      "*******************    12     *******************\n",
      "RMSE - ConvLSTM       64.46033940447249 + - 129.02921191231889\n",
      "RMSE - Climatology    166.09625619036072 + - 245.80172186617085\n",
      "RMSE - Persistence    66.53724354925671 + - 137.47315764613458\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ########                performance evaluation with RMSE                 ########\n",
    "    ########              RMSE over time, and sum over domain                ########\n",
    "    #################################################################################\n",
    "    sequence_len, height, width = sic_exp_norm.shape\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with climatology  ############')\n",
    "    print('##############################################################')\n",
    "    # compute climatology\n",
    "    climatology = np.zeros((48, height, width),dtype=float)\n",
    "    for i in range(48):\n",
    "        climatology[i,:,:] = np.mean(sic_exp_norm[i::48,:,:],axis=0)\n",
    "    # repeat this climatology and calculate the RMSE\n",
    "    climatology_seq = np.tile(climatology,(test_year,1,1))\n",
    "    RMSE_climatology, RMSE_climatology_std  = RMSE(climatology_seq * sic_max,sic_exp_norm[-test_year*12*4:,:,:] * sic_max)\n",
    "    RMSE_climatology = np.mean(RMSE_climatology)\n",
    "    RMSE_climatology_std = np.mean(RMSE_climatology_std)\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with persistence  ############')\n",
    "    print('##############################################################')\n",
    "    RMSE_persist_0, RMSE_persist_0_std = RMSE(sic_exp_norm[-test_year*12*4-1:-1,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4:,:,:] * sic_max)\n",
    "    RMSE_persist_1, RMSE_persist_1_std = RMSE(sic_exp_norm[-test_year*12*4-1:-2,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+1:,:,:] * sic_max)\n",
    "    RMSE_persist_2, RMSE_persist_2_std = RMSE(sic_exp_norm[-test_year*12*4-1:-3,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+2:,:,:] * sic_max)\n",
    "    RMSE_persist_3, RMSE_persist_3_std = RMSE(sic_exp_norm[-test_year*12*4-1:-4,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+3:,:,:] * sic_max)\n",
    "    RMSE_persist_4, RMSE_persist_4_std = RMSE(sic_exp_norm[-test_year*12*4-1:-5,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+4:,:,:] * sic_max)\n",
    "    RMSE_persist_5, RMSE_persist_5_std = RMSE(sic_exp_norm[-test_year*12*4-1:-6,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+5:,:,:] * sic_max)\n",
    "    RMSE_persist_6, RMSE_persist_6_std = RMSE(sic_exp_norm[-test_year*12*4-1:-7,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+6:,:,:] * sic_max)\n",
    "    RMSE_persist_7, RMSE_persist_7_std = RMSE(sic_exp_norm[-test_year*12*4-1:-8,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+7:,:,:] * sic_max)\n",
    "    RMSE_persist_8, RMSE_persist_8_std = RMSE(sic_exp_norm[-test_year*12*4-1:-9,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+8:,:,:] * sic_max)\n",
    "    RMSE_persist_9, RMSE_persist_9_std = RMSE(sic_exp_norm[-test_year*12*4-1:-10,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+9:,:,:] * sic_max)\n",
    "    RMSE_persist_10, RMSE_persist_10_std = RMSE(sic_exp_norm[-test_year*12*4-1:-11,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+10:,:,:] * sic_max)\n",
    "    RMSE_persist_11, RMSE_persist_11_std = RMSE(sic_exp_norm[-test_year*12*4-1:-12,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+11:,:,:] * sic_max)\n",
    "    RMSE_persist_12, RMSE_persist_12_std = RMSE(sic_exp_norm[-test_year*12*4-1:-13,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+12:,:,:] * sic_max)\n",
    "    RMSE_persist_13, RMSE_persist_13_std = RMSE(sic_exp_norm[-test_year*12*4-1:-14,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+13:,:,:] * sic_max)\n",
    "    RMSE_persist_14, RMSE_persist_14_std = RMSE(sic_exp_norm[-test_year*12*4-1:-15,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+14:,:,:] * sic_max)\n",
    "    RMSE_persist_15, RMSE_persist_15_std = RMSE(sic_exp_norm[-test_year*12*4-1:-16,:,:] * sic_max,\n",
    "                                              sic_exp_norm[-test_year*12*4+15:,:,:] * sic_max)\n",
    "    print('##############################################################')\n",
    "    print('########   land-sea correction for sic prediction    #########')\n",
    "    print('##############################################################')\n",
    "    # correction for float point at 0\n",
    "    lead_pred_sic[lead_pred_sic<0] = 0\n",
    "    # extend the dimension of sea ice mask\n",
    "    sea_ice_mask_test = np.repeat(sea_ice_mask_barents[np.newaxis,:,:],test_year*48,0)\n",
    "    # correct the land cells in the prediction\n",
    "    for i in range(step_lead):\n",
    "        lead_pred_sic[:,i,:,:] = lead_pred_sic[:,i,:,:] * sea_ice_mask_test\n",
    "    print('#################################################################################')\n",
    "    print('############   evaluation and statistical matrix for the entire year ############')\n",
    "    print('#################################################################################')\n",
    "    RMSE_ConvLSTM_0, RMSE_ConvLSTM_0_std = RMSE(lead_pred_sic[:,0,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_1, RMSE_ConvLSTM_1_std = RMSE(lead_pred_sic[:-1,1,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+1:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_2, RMSE_ConvLSTM_2_std = RMSE(lead_pred_sic[:-2,2,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+2:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_3, RMSE_ConvLSTM_3_std = RMSE(lead_pred_sic[:-3,3,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+3:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_4, RMSE_ConvLSTM_4_std = RMSE(lead_pred_sic[:-4,4,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+4:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_5, RMSE_ConvLSTM_5_std = RMSE(lead_pred_sic[:-5,5,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+5:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_6, RMSE_ConvLSTM_6_std = RMSE(lead_pred_sic[:-6,6,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+6:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_7, RMSE_ConvLSTM_7_std = RMSE(lead_pred_sic[:-7,7,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+7:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_8, RMSE_ConvLSTM_8_std = RMSE(lead_pred_sic[:-8,8,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+8:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_9, RMSE_ConvLSTM_9_std = RMSE(lead_pred_sic[:-9,9,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+9:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_10, RMSE_ConvLSTM_10_std = RMSE(lead_pred_sic[:-10,10,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+10:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_11, RMSE_ConvLSTM_11_std = RMSE(lead_pred_sic[:-11,11,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+11:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_12, RMSE_ConvLSTM_12_std = RMSE(lead_pred_sic[:-12,12,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+12:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_13, RMSE_ConvLSTM_13_std = RMSE(lead_pred_sic[:-13,13,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+13:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_14, RMSE_ConvLSTM_14_std = RMSE(lead_pred_sic[:-14,14,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+14:,:,:] * sic_max)\n",
    "    RMSE_ConvLSTM_15, RMSE_ConvLSTM_15_std = RMSE(lead_pred_sic[:-15,15,:,:] * sic_max,\n",
    "                                                sic_exp_norm[-test_year*12*4+15:,:,:] * sic_max)\n",
    "    print(\"*******************     Lead time 0     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_0),\"+-\",np.mean(RMSE_ConvLSTM_0_std))\n",
    "    print(\"Mean RMSE with testing data - Climatology\")\n",
    "    print(RMSE_climatology,\"+-\",RMSE_climatology_std)\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_0),\"+-\",np.mean(RMSE_persist_0_std))\n",
    "    print(\"*******************     Lead time 1     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_1),\"+-\",np.mean(RMSE_ConvLSTM_1_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_1),\"+-\",np.mean(RMSE_persist_1_std))\n",
    "    print(\"*******************     Lead time 2     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_2),\"+-\",np.mean(RMSE_ConvLSTM_2_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_2),\"+-\",np.mean(RMSE_persist_2_std))\n",
    "    print(\"*******************     Lead time 3     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_3),\"+-\",np.mean(RMSE_ConvLSTM_3_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_3),\"+-\",np.mean(RMSE_persist_3_std))\n",
    "    print(\"*******************     Lead time 4     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_4),\"+-\",np.mean(RMSE_ConvLSTM_4_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_4),\"+-\",np.mean(RMSE_persist_4_std))\n",
    "    print(\"*******************     Lead time 5     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_5),\"+-\",np.mean(RMSE_ConvLSTM_5_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_5),\"+-\",np.mean(RMSE_persist_5_std))\n",
    "    print(\"*******************     Lead time 6     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_6),\"+-\",np.mean(RMSE_ConvLSTM_6_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_6),\"+-\",np.mean(RMSE_persist_6_std))\n",
    "    print(\"*******************     Lead time 7     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_7),\"+-\",np.mean(RMSE_ConvLSTM_7_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_7),\"+-\",np.mean(RMSE_persist_7_std))\n",
    "    print(\"*******************     Lead time 8     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_8),\"+-\",np.mean(RMSE_ConvLSTM_8_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_8),\"+-\",np.mean(RMSE_persist_8_std))\n",
    "    print(\"*******************     Lead time 9     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_9),\"+-\",np.mean(RMSE_ConvLSTM_9_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_9),\"+-\",np.mean(RMSE_persist_9_std))\n",
    "    print(\"*******************     Lead time 10     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_10),\"+-\",np.mean(RMSE_ConvLSTM_10_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_10),\"+-\",np.mean(RMSE_persist_10_std))\n",
    "    print(\"*******************     Lead time 11     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_11),\"+-\",np.mean(RMSE_ConvLSTM_11_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_11),\"+-\",np.mean(RMSE_persist_11_std))\n",
    "    print(\"*******************     Lead time 12     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_12),\"+-\",np.mean(RMSE_ConvLSTM_12_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_12),\"+-\",np.mean(RMSE_persist_12_std))\n",
    "    print(\"*******************     Lead time 13     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_13),\"+-\",np.mean(RMSE_ConvLSTM_13_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_13),\"+-\",np.mean(RMSE_persist_13_std))\n",
    "    print(\"*******************     Lead time 14     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_14),\"+-\",np.mean(RMSE_ConvLSTM_14_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_14),\"+-\",np.mean(RMSE_persist_14_std))\n",
    "    print(\"*******************     Lead time 15     *******************\")\n",
    "    print(\"Mean RMSE with testing data - ConvLSTM\")\n",
    "    print(np.mean(RMSE_ConvLSTM_15),\"+-\",np.mean(RMSE_ConvLSTM_15_std))\n",
    "    print(\"Mean RMSE with testing data - Persistence\")\n",
    "    print(np.mean(RMSE_persist_15),\"+-\",np.mean(RMSE_persist_15_std))\n",
    "    print('##############################################################')\n",
    "    print('############           create a txt file          ############')\n",
    "    print('##############################################################')\n",
    "    f = open(os.path.join(output_path,\"report_rmse_pred_16weeks.txt\"),\"w+\")\n",
    "    f.write(\"############   evaluation of prediction   ############\\n\")\n",
    "    f.write(\"############   Total RMSE with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_0),np.mean(RMSE_ConvLSTM_0_std)))\n",
    "    f.write(\"RMSE - Climatology    {} + - {}\\n\".format(RMSE_climatology, RMSE_climatology_std))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_0),np.mean(RMSE_persist_0_std)))\n",
    "    f.write(\"*******************     Lead time 1     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_1),np.mean(RMSE_ConvLSTM_1_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_1),np.mean(RMSE_persist_1_std)))\n",
    "    f.write(\"*******************     Lead time 2     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_2),np.mean(RMSE_ConvLSTM_2_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_2),np.mean(RMSE_persist_2_std)))\n",
    "    f.write(\"*******************     Lead time 3     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_3),np.mean(RMSE_ConvLSTM_3_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_3),np.mean(RMSE_persist_3_std)))\n",
    "    f.write(\"*******************     Lead time 4     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_4),np.mean(RMSE_ConvLSTM_4_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_4),np.mean(RMSE_persist_4_std)))\n",
    "    f.write(\"*******************     Lead time 5     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_5),np.mean(RMSE_ConvLSTM_5_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_5),np.mean(RMSE_persist_5_std)))\n",
    "    f.write(\"*******************     Lead time 6     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_6),np.mean(RMSE_ConvLSTM_6_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_6),np.mean(RMSE_persist_6_std)))\n",
    "    f.write(\"*******************     Lead time 7     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_7),np.mean(RMSE_ConvLSTM_7_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_7),np.mean(RMSE_persist_7_std)))\n",
    "    f.write(\"*******************     Lead time 8     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_8),np.mean(RMSE_ConvLSTM_8_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_8),np.mean(RMSE_persist_8_std)))\n",
    "    f.write(\"*******************     Lead time 9     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_9),np.mean(RMSE_ConvLSTM_9_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_9),np.mean(RMSE_persist_9_std)))\n",
    "    f.write(\"*******************     Lead time 10     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_10),np.mean(RMSE_ConvLSTM_10_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_10),np.mean(RMSE_persist_10_std)))\n",
    "    f.write(\"*******************     Lead time 11     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_11),np.mean(RMSE_ConvLSTM_11_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_11),np.mean(RMSE_persist_11_std)))\n",
    "    f.write(\"*******************     Lead time 12     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_12),np.mean(RMSE_ConvLSTM_12_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_12),np.mean(RMSE_persist_12_std)))\n",
    "    f.write(\"*******************     Lead time 13     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_13),np.mean(RMSE_ConvLSTM_13_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_13),np.mean(RMSE_persist_13_std)))\n",
    "    f.write(\"*******************     Lead time 14     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_14),np.mean(RMSE_ConvLSTM_14_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_14),np.mean(RMSE_persist_14_std)))\n",
    "    f.write(\"*******************     Lead time 15     *******************\\n\")\n",
    "    f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(RMSE_ConvLSTM_15),np.mean(RMSE_ConvLSTM_15_std)))\n",
    "    f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(RMSE_persist_15),np.mean(RMSE_persist_15_std)))\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"############   Monthly RMSE with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    for i in np.arange(1,13,1):\n",
    "        ConvLSTM_monthly_series = week2month(lead_pred_sic[:,0,:,:], i)\n",
    "        persist_monthly_series = week2month(sic_exp_norm[-test_year*12*4-1:-1,:,:], i)\n",
    "        climatology_monthly_series = week2month(climatology_seq, i)\n",
    "        truth_monthly_series = week2month(sic_exp_norm[-test_year*12*4:,:,:], i)\n",
    "        \n",
    "        rmse_ConvLSTM_monthly, rmse_ConvLSTM_monthly_std = RMSE(ConvLSTM_monthly_series * sic_max,truth_monthly_series * sic_max)\n",
    "        rmse_persist_monthly, rmse_persist_monthly_std = RMSE(persist_monthly_series * sic_max,truth_monthly_series * sic_max)\n",
    "        rmse_climatology_monthly, rmse_climatology_monthly_std = RMSE(climatology_monthly_series * sic_max,truth_monthly_series * sic_max)\n",
    "        \n",
    "        print(\"*******************    {}     *******************\".format(i))\n",
    "        print(\"RMSE - ConvLSTM       {} + - {}\".format(np.mean(rmse_ConvLSTM_monthly), np.mean(rmse_ConvLSTM_monthly_std)))\n",
    "        print(\"RMSE - Climatology    {} + - {}\".format(np.mean(rmse_climatology_monthly), np.mean(rmse_climatology_monthly_std)))\n",
    "        print(\"RMSE - Persistence    {} + - {}\".format(np.mean(rmse_persist_monthly), np.mean(rmse_persist_monthly_std)))\n",
    "        f.write(\"*******************    {}     *******************\\n\".format(i))\n",
    "        f.write(\"RMSE - ConvLSTM       {} + - {}\\n\".format(np.mean(rmse_ConvLSTM_monthly), np.mean(rmse_ConvLSTM_monthly_std)))\n",
    "        f.write(\"RMSE - Climatology    {} + - {}\\n\".format(np.mean(rmse_climatology_monthly), np.mean(rmse_climatology_monthly_std)))\n",
    "        f.write(\"RMSE - Persistence    {} + - {}\\n\".format(np.mean(rmse_persist_monthly), np.mean(rmse_persist_monthly_std)))\n",
    "        \n",
    "    #f.write(\"*******************     Lead time 6     *******************\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  module for calculating accuracy/recall/precision  *********************\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  module for calculating accuracy/recall/precision  *********************')\n",
    "    def accuracy(pred, label):\n",
    "        #print(\"Input size must be [seq, lat, lon]\")\n",
    "        seq, lat, lon = pred.shape\n",
    "        boolean = (pred==label)\n",
    "        accu_seq = np.mean(np.mean(boolean.astype(float),2),1)\n",
    "        accu_spa = np.mean(boolean.astype(float),0)\n",
    "        \n",
    "        return accu_seq, accu_spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #################################################################################\n",
    "    ########          transfer the sea ice fields into binary data           ########\n",
    "    #################################################################################\n",
    "    # ice concentration below the threshold is regarded as no ice, the value is from\n",
    "    # https://nsidc.org/cryosphere/seaice/data/terminology.html\n",
    "    criterion_0 = 0.15 \n",
    "    # remove the area weight\n",
    "    sic_exp_denorm = np.zeros(sic_exp_norm.shape, dtype=float)\n",
    "    lead_pred_sic_denorm = np.zeros(lead_pred_sic.shape, dtype=float)\n",
    "    for i in np.arange(height):\n",
    "        lead_pred_sic_denorm[:,:,i,:] = lead_pred_sic[:,:,i,:] /dx[i+12] * dx[35]\n",
    "        sic_exp_denorm[:,i,:] = sic_exp_norm[:,i,:] / dx[i+12] * dx[35]\n",
    "    # turn sea ice fields into binary data\n",
    "    lead_pred_sic_bin = lead_pred_sic_denorm[:]\n",
    "    sic_exp_bin = sic_exp_denorm[:]\n",
    "    lead_pred_sic_bin[lead_pred_sic_bin <= criterion_0] = 0\n",
    "    lead_pred_sic_bin[lead_pred_sic_bin > criterion_0] = 1\n",
    "    sic_exp_bin[sic_exp_bin <= criterion_0] = 0\n",
    "    sic_exp_bin[sic_exp_bin > criterion_0] = 1\n",
    "    # turn matrix into int\n",
    "    lead_pred_sic_bin = lead_pred_sic_bin.astype(int)\n",
    "    sic_exp_bin = sic_exp_bin.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "############   start prediction with climatology  ############\n",
      "##############################################################\n",
      "##############################################################\n",
      "############   start prediction with persistence  ############\n",
      "##############################################################\n",
      "##############################################################\n",
      "########   start prediction with linear regression   #########\n",
      "##############################################################\n",
      "#################################################################################\n",
      "############   evaluation and statistical matrix for the entire year ############\n",
      "#################################################################################\n",
      "*******************     Lead time 0     *******************\n",
      "Total accuracy with testing data - ConvLSTM\n",
      "0.9742024739583334\n",
      "Total accuracy with testing data - Climatology\n",
      "0.8557477678571428\n",
      "Total accuracy with testing data - Persistence\n",
      "0.9749193948412698\n",
      "*******************     Lead time 1     *******************\n",
      "Total accuracy with testing data - ConvLSTM\n",
      "0.9553493517825979\n",
      "Total accuracy with testing data - Persistence\n",
      "0.9597396222887059\n",
      "*******************     Lead time 2     *******************\n",
      "Total accuracy with testing data - ConvLSTM\n",
      "0.9427279135338344\n",
      "Total accuracy with testing data - Persistence\n",
      "0.9483787593984963\n",
      "*******************     Lead time 3     *******************\n",
      "Total accuracy with testing data - ConvLSTM\n",
      "0.9320475875535399\n",
      "Total accuracy with testing data - Persistence\n",
      "0.936889802217183\n",
      "*******************     Lead time 4     *******************\n",
      "Total accuracy with testing data - ConvLSTM\n",
      "0.9215583839918947\n",
      "Total accuracy with testing data - Persistence\n",
      "0.9253340298885512\n",
      "*******************     Lead time 5     *******************\n",
      "Total accuracy with testing data - ConvLSTM\n",
      "0.9106744970715559\n",
      "Total accuracy with testing data - Persistence\n",
      "0.9133960402342755\n",
      "##############################################################\n",
      "############           create a txt file          ############\n",
      "##############################################################\n",
      "*******************    1     *******************\n",
      "accuracy - ConvLSTM       0.9496372767857143\n",
      "accuracy - Climatology    0.8189174107142857\n",
      "accuracy - Persistence    0.9498697916666667\n",
      "*******************    2     *******************\n",
      "accuracy - ConvLSTM       0.9633556547619048\n",
      "accuracy - Climatology    0.8280784970238095\n",
      "accuracy - Persistence    0.9636811755952381\n",
      "*******************    3     *******************\n",
      "accuracy - ConvLSTM       0.9649367559523809\n",
      "accuracy - Climatology    0.8337983630952381\n",
      "accuracy - Persistence    0.9605189732142858\n",
      "*******************    4     *******************\n",
      "accuracy - ConvLSTM       0.9706566220238095\n",
      "accuracy - Climatology    0.8166852678571428\n",
      "accuracy - Persistence    0.968563988095238\n",
      "*******************    5     *******************\n",
      "accuracy - ConvLSTM       0.9681454613095238\n",
      "accuracy - Climatology    0.7997116815476191\n",
      "accuracy - Persistence    0.9637276785714285\n",
      "*******************    6     *******************\n",
      "accuracy - ConvLSTM       0.9808872767857144\n",
      "accuracy - Climatology    0.8109654017857143\n",
      "accuracy - Persistence    0.9734933035714286\n",
      "*******************    7     *******************\n",
      "accuracy - ConvLSTM       0.9902808779761905\n",
      "accuracy - Climatology    0.905087425595238\n",
      "accuracy - Persistence    0.9868396577380952\n",
      "*******************    8     *******************\n",
      "accuracy - ConvLSTM       0.9959077380952381\n",
      "accuracy - Climatology    0.9574032738095237\n",
      "accuracy - Persistence    0.9961402529761905\n",
      "*******************    9     *******************\n",
      "accuracy - ConvLSTM       0.9962332589285714\n",
      "accuracy - Climatology    0.9603329613095238\n",
      "accuracy - Persistence    0.998046875\n",
      "*******************    10     *******************\n",
      "accuracy - ConvLSTM       0.9816313244047619\n",
      "accuracy - Climatology    0.9025762648809523\n",
      "accuracy - Persistence    0.9930245535714286\n",
      "*******************    11     *******************\n",
      "accuracy - ConvLSTM       0.9683314732142857\n",
      "accuracy - Climatology    0.8140811011904763\n",
      "accuracy - Persistence    0.9844680059523809\n",
      "*******************    12     *******************\n",
      "accuracy - ConvLSTM       0.9604259672619049\n",
      "accuracy - Climatology    0.8213355654761905\n",
      "accuracy - Persistence    0.9606584821428572\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ########              performance evaluation with accuracy               ########\n",
    "    #################################################################################\n",
    "    sequence_len, height, width = sic_exp_norm.shape\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with climatology  ############')\n",
    "    print('##############################################################')\n",
    "    # compute climatology\n",
    "    climatology = np.zeros((48, height, width),dtype=float)\n",
    "    for i in range(48):\n",
    "        climatology[i,:,:] = np.mean(sic_exp_norm[i::48,:,:],axis=0)\n",
    "    # repeat this climatology and calculate the RMSE\n",
    "    climatology_seq = np.tile(climatology,(test_year,1,1))\n",
    "    # turn into binary\n",
    "    climatology_denorm = np.zeros(climatology_seq.shape, dtype=float)\n",
    "    for i in np.arange(height):\n",
    "        climatology_denorm[:,i,:] = climatology_seq[:,i,:] / dx[i+12] * dx[35]    \n",
    "    climatology_denorm[climatology_denorm <= criterion_0] = 0\n",
    "    climatology_denorm[climatology_denorm > criterion_0] = 1\n",
    "    # turn matrix into int\n",
    "    climatology_denorm = climatology_denorm.astype(int)\n",
    "    \n",
    "    accu_climatology, _ = accuracy(climatology_denorm, sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with persistence  ############')\n",
    "    print('##############################################################')\n",
    "    accu_persist_0, _ = accuracy(sic_exp_bin[-test_year*12*4-1:-1,:,:],sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    accu_persist_1, _ = accuracy(sic_exp_bin[-test_year*12*4-1:-2,:,:],sic_exp_bin[-test_year*12*4+1:,:,:])\n",
    "    accu_persist_2, _ = accuracy(sic_exp_bin[-test_year*12*4-1:-3,:,:],sic_exp_bin[-test_year*12*4+2:,:,:])\n",
    "    accu_persist_3, _ = accuracy(sic_exp_bin[-test_year*12*4-1:-4,:,:],sic_exp_bin[-test_year*12*4+3:,:,:])\n",
    "    accu_persist_4, _ = accuracy(sic_exp_bin[-test_year*12*4-1:-5,:,:],sic_exp_bin[-test_year*12*4+4:,:,:])\n",
    "    accu_persist_5, _ = accuracy(sic_exp_bin[-test_year*12*4-1:-6,:,:],sic_exp_bin[-test_year*12*4+5:,:,:])\n",
    "    print('##############################################################')\n",
    "    print('########   start prediction with linear regression   #########')\n",
    "    print('##############################################################')\n",
    "    \n",
    "    print('#################################################################################')\n",
    "    print('############   evaluation and statistical matrix for the entire year ############')\n",
    "    print('#################################################################################')\n",
    "    accu_ConvLSTM_0, _ = accuracy(lead_pred_sic_bin[:,0,:,:],sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    accu_ConvLSTM_1, _ = accuracy(lead_pred_sic_bin[:-1,1,:,:],sic_exp_bin[-test_year*12*4+1:,:,:])\n",
    "    accu_ConvLSTM_2, _ = accuracy(lead_pred_sic_bin[:-2,2,:,:],sic_exp_bin[-test_year*12*4+2:,:,:])\n",
    "    accu_ConvLSTM_3, _ = accuracy(lead_pred_sic_bin[:-3,3,:,:],sic_exp_bin[-test_year*12*4+3:,:,:])\n",
    "    accu_ConvLSTM_4, _ = accuracy(lead_pred_sic_bin[:-4,4,:,:],sic_exp_bin[-test_year*12*4+4:,:,:])\n",
    "    accu_ConvLSTM_5, _ = accuracy(lead_pred_sic_bin[:-5,5,:,:],sic_exp_bin[-test_year*12*4+5:,:,:])\n",
    "    print(\"*******************     Lead time 0     *******************\")\n",
    "    print(\"Total accuracy with testing data - ConvLSTM\")\n",
    "    print(np.mean(accu_ConvLSTM_0))\n",
    "    print(\"Total accuracy with testing data - Climatology\")\n",
    "    print(np.mean(accu_climatology))\n",
    "    print(\"Total accuracy with testing data - Persistence\")\n",
    "    print(np.mean(accu_persist_0))\n",
    "    print(\"*******************     Lead time 1     *******************\")\n",
    "    print(\"Total accuracy with testing data - ConvLSTM\")\n",
    "    print(np.mean(accu_ConvLSTM_1))\n",
    "    print(\"Total accuracy with testing data - Persistence\")\n",
    "    print(np.mean(accu_persist_1))\n",
    "    print(\"*******************     Lead time 2     *******************\")\n",
    "    print(\"Total accuracy with testing data - ConvLSTM\")\n",
    "    print(np.mean(accu_ConvLSTM_2))\n",
    "    print(\"Total accuracy with testing data - Persistence\")\n",
    "    print(np.mean(accu_persist_2))\n",
    "    print(\"*******************     Lead time 3     *******************\")\n",
    "    print(\"Total accuracy with testing data - ConvLSTM\")\n",
    "    print(np.mean(accu_ConvLSTM_3))\n",
    "    print(\"Total accuracy with testing data - Persistence\")\n",
    "    print(np.mean(accu_persist_3))\n",
    "    print(\"*******************     Lead time 4     *******************\")\n",
    "    print(\"Total accuracy with testing data - ConvLSTM\")\n",
    "    print(np.mean(accu_ConvLSTM_4))\n",
    "    print(\"Total accuracy with testing data - Persistence\")\n",
    "    print(np.mean(accu_persist_4))\n",
    "    print(\"*******************     Lead time 5     *******************\")\n",
    "    print(\"Total accuracy with testing data - ConvLSTM\")\n",
    "    print(np.mean(accu_ConvLSTM_5))\n",
    "    print(\"Total accuracy with testing data - Persistence\")\n",
    "    print(np.mean(accu_persist_5))\n",
    "    print('##############################################################')\n",
    "    print('############           create a txt file          ############')\n",
    "    print('##############################################################')\n",
    "    f = open(os.path.join(output_path,\"report_accuracy_pred_bin.txt\"),\"w+\")\n",
    "    f.write(\"############   evaluation of prediction   ############\\n\")\n",
    "    f.write(\"############   Total accuracy with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accu_ConvLSTM_0)))\n",
    "    f.write(\"accuracy - Climatology    {}\\n\".format(np.mean(accu_climatology)))\n",
    "    f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accu_persist_0)))\n",
    "    f.write(\"*******************     Lead time 1     *******************\\n\")\n",
    "    f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accu_ConvLSTM_1)))\n",
    "    f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accu_persist_1)))\n",
    "    f.write(\"*******************     Lead time 2     *******************\\n\")\n",
    "    f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accu_ConvLSTM_2)))\n",
    "    f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accu_persist_2)))\n",
    "    f.write(\"*******************     Lead time 3     *******************\\n\")\n",
    "    f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accu_ConvLSTM_3)))\n",
    "    f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accu_persist_3)))\n",
    "    f.write(\"*******************     Lead time 4     *******************\\n\")\n",
    "    f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accu_ConvLSTM_4)))\n",
    "    f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accu_persist_4)))\n",
    "    f.write(\"*******************     Lead time 5     *******************\\n\")\n",
    "    f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accu_ConvLSTM_5)))\n",
    "    f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accu_persist_5)))\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"############   Monthly accuracy with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    for i in np.arange(1,13,1):\n",
    "        ConvLSTM_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        persist_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        climatology_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        truth_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        for j in np.arange(4):\n",
    "            ConvLSTM_monthly_series[j::4,:,:] = lead_pred_sic_bin[(i-1)*4+j::48,0,:,:]\n",
    "            persist_monthly_series[j::4,:,:] = sic_exp_bin[-test_year*12*4-1+(i-1)*4+j:-1:48,:,:]\n",
    "            climatology_monthly_series[j::4,:,:] = climatology_denorm[(i-1)*4+j::48,:,:]\n",
    "            truth_monthly_series[j::4,:,:] = sic_exp_bin[-test_year*12*4+(i-1)*4+j::48,:,:]\n",
    "        print(\"*******************    {}     *******************\".format(i))\n",
    "        print(\"accuracy - ConvLSTM       {}\".format(np.mean(accuracy(ConvLSTM_monthly_series,truth_monthly_series)[0])))\n",
    "        print(\"accuracy - Climatology    {}\".format(np.mean(accuracy(climatology_monthly_series,truth_monthly_series)[0])))\n",
    "        print(\"accuracy - Persistence    {}\".format(np.mean(accuracy(persist_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"*******************    {}     *******************\\n\".format(i))\n",
    "        f.write(\"accuracy - ConvLSTM       {}\\n\".format(np.mean(accuracy(ConvLSTM_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"accuracy - Climatology    {}\\n\".format(np.mean(accuracy(climatology_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"accuracy - Persistence    {}\\n\".format(np.mean(accuracy(persist_monthly_series,truth_monthly_series)[0])))\n",
    "    f.write(\"*******************     Lead time 6     *******************\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  module for calculating recall/precision  *********************\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  module for calculating recall/precision  *********************')\n",
    "    # positive is sea ice = 1\n",
    "    \n",
    "    def recall(pred, label):\n",
    "        \"\"\"\n",
    "        True positive / Total actual positive\n",
    "        Input fields must contain only 0 / 1. 1 is positive.\n",
    "        \"\"\"\n",
    "        #print(\"Input size must be [seq, lat, lon]\")\n",
    "        seq, lat, lon = pred.shape\n",
    "        # initialize dummy matrix\n",
    "        pred_dummy_1 = np.zeros(pred.shape,dtype=int)\n",
    "        label_dummy_1 = np.zeros(label.shape,dtype=int)\n",
    "        # True positive\n",
    "        # create dummy matrix to save the labels\n",
    "        pred_dummy_1[:] = pred[:]\n",
    "        label_dummy_1[:] = label[:]\n",
    "        # change the label of negative events\n",
    "        pred_dummy_1[pred == 0] = 2\n",
    "        label_dummy_1[label == 0] = 3\n",
    "        # count True Positive events\n",
    "        truePositive = (pred_dummy_1 == label_dummy_1)\n",
    "\n",
    "        # initialize dummy matrix\n",
    "        pred_dummy_2 = np.zeros(pred.shape,dtype=int)\n",
    "        label_dummy_2 = np.zeros(label.shape,dtype=int)\n",
    "        # False negative (is 1 but predict 0)\n",
    "        # create dummy matrix to save the labels (reset dummy)\n",
    "        pred_dummy_2[:] = pred[:]\n",
    "        label_dummy_2[:] = label[:]\n",
    "        pred_dummy_2[pred == 0] = 2\n",
    "        label_dummy_2[label == 1] = 2\n",
    "        # count False Positive events\n",
    "        falseNegative = (pred_dummy_2 == label_dummy_2)\n",
    "\n",
    "#         recall_seq = np.mean(np.mean(np.nan_to_num(truePositive.astype(float) / \n",
    "#                                     (truePositive.astype(float) + falseNegative.astype(float))),2),1)\n",
    "        \n",
    "        recall_seq = np.sum(np.sum(truePositive.astype(float),2),1) / (np.sum(np.sum(truePositive.astype(float),2),1) +\n",
    "                                                                       np.sum(np.sum(falseNegative.astype(float),2),1))\n",
    "        \n",
    "#         recall_spa = np.mean(np.nan_to_num(truePositive.astype(float) / \n",
    "#                                           (truePositive.astype(float) + falseNegative.astype(float))),0)\n",
    "        \n",
    "        recall_spa = np.sum(truePositive.astype(float),0) / (np.sum(truePositive.astype(float),0) +\n",
    "                                                             np.sum(falseNegative.astype(float),0))\n",
    "        \n",
    "        #return recall_seq, recall_spa\n",
    "        return np.nan_to_num(recall_seq), np.nan_to_num(recall_spa)\n",
    "    \n",
    "    def precision(pred, label):\n",
    "        \"\"\"\n",
    "        True positive / Total predicted positive\n",
    "        Input fields must contain only 0 / 1. 1 is positive.\n",
    "        \"\"\"\n",
    "        #print(\"Input size must be [seq, lat, lon]\")\n",
    "        seq, lat, lon = pred.shape\n",
    "        # initialize dummy matrix\n",
    "        pred_dummy_1 = np.zeros(pred.shape,dtype=int)\n",
    "        label_dummy_1 = np.zeros(label.shape,dtype=int)\n",
    "        # True positive\n",
    "        # create dummy matrix to save the labels\n",
    "        pred_dummy_1[:] = pred[:]\n",
    "        label_dummy_1[:] = label[:]\n",
    "        # change the label of negative events\n",
    "        pred_dummy_1[pred == 0] = 2\n",
    "        label_dummy_1[label == 0] = 3\n",
    "        # count True Positive events\n",
    "        truePositive = (pred_dummy_1 == label_dummy_1)\n",
    "\n",
    "        # initialize dummy matrix\n",
    "        pred_dummy_2 = np.zeros(pred.shape,dtype=int)\n",
    "        label_dummy_2 = np.zeros(label.shape,dtype=int)\n",
    "        # False positive (is 0 but predict 1)\n",
    "        # create dummy matrix to save the labels (reset dummy)\n",
    "        pred_dummy_2[:] = pred[:]\n",
    "        label_dummy_2[:] = label[:]\n",
    "        pred_dummy_2[pred == 1] = 2\n",
    "        label_dummy_2[label == 0] = 2\n",
    "        # count False Positive events\n",
    "        falsePositive = (pred_dummy_2 == label_dummy_2)\n",
    "        \n",
    "        prec_seq = np.sum(np.sum(truePositive.astype(float),2),1) / (np.sum(np.sum(truePositive.astype(float),2),1) +\n",
    "                                                                     np.sum(np.sum(falsePositive.astype(float),2),1))\n",
    "        \n",
    "        prec_spa = np.sum(truePositive.astype(float),0) / (np.sum(truePositive.astype(float),0) +\n",
    "                                                           np.sum(falsePositive.astype(float),0))\n",
    "        \n",
    "        return np.nan_to_num(prec_seq), np.nan_to_num(prec_spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "############   start prediction with climatology  ############\n",
      "##############################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "G:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:46: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "############   start prediction with persistence  ############\n",
      "##############################################################\n",
      "##############################################################\n",
      "########   start prediction with linear regression   #########\n",
      "##############################################################\n",
      "#################################################################################\n",
      "############   evaluation and statistical matrix for the entire year ############\n",
      "#################################################################################\n",
      "*******************     Lead time 0     *******************\n",
      "Total recall with testing data - ConvLSTM\n",
      "0.7294511802947931\n",
      "Total recall with testing data - Climatology\n",
      "0.7682106239728338\n",
      "Total recall with testing data - Persistence\n",
      "0.6956084994582069\n",
      "*******************     Lead time 1     *******************\n",
      "Total recall with testing data - ConvLSTM\n",
      "0.7050962750794713\n",
      "Total recall with testing data - Persistence\n",
      "0.6436574679557777\n",
      "*******************     Lead time 2     *******************\n",
      "Total recall with testing data - ConvLSTM\n",
      "0.6909375651664893\n",
      "Total recall with testing data - Persistence\n",
      "0.610596193945815\n",
      "*******************     Lead time 3     *******************\n",
      "Total recall with testing data - ConvLSTM\n",
      "0.6749170520140996\n",
      "Total recall with testing data - Persistence\n",
      "0.5745854442827217\n",
      "*******************     Lead time 4     *******************\n",
      "Total recall with testing data - ConvLSTM\n",
      "0.6594568455857532\n",
      "Total recall with testing data - Persistence\n",
      "0.5492875256810292\n",
      "*******************     Lead time 5     *******************\n",
      "Total recall with testing data - ConvLSTM\n",
      "0.6446762471590884\n",
      "Total recall with testing data - Persistence\n",
      "0.5259148468998884\n",
      "##############################################################\n",
      "############           create a txt file          ############\n",
      "##############################################################\n",
      "*******************    1     *******************\n",
      "recall - ConvLSTM       0.860598886960916\n",
      "recall - Climatology    0.9985675754922358\n",
      "recall - Persistence    0.8314841347620789\n",
      "*******************    2     *******************\n",
      "recall - ConvLSTM       0.9453464077344558\n",
      "recall - Climatology    0.9988817097415507\n",
      "recall - Persistence    0.9345966147874042\n",
      "*******************    3     *******************\n",
      "recall - ConvLSTM       0.9346326494497246\n",
      "recall - Climatology    0.9997340425531915\n",
      "recall - Persistence    0.9106219389571815\n",
      "*******************    4     *******************\n",
      "recall - ConvLSTM       0.9685899947294929\n",
      "recall - Climatology    0.998480953251909\n",
      "recall - Persistence    0.967307576852602\n",
      "*******************    5     *******************\n",
      "recall - ConvLSTM       0.9754766488516187\n",
      "recall - Climatology    0.9983039583340307\n",
      "recall - Persistence    0.980571197002486\n",
      "*******************    6     *******************\n",
      "recall - ConvLSTM       0.9473765015441237\n",
      "recall - Climatology    0.99876677278424\n",
      "recall - Persistence    0.97613758406689\n",
      "*******************    7     *******************\n",
      "recall - ConvLSTM       0.6955869319793339\n",
      "recall - Climatology    0.6825157351595051\n",
      "recall - Persistence    0.731919166058951\n",
      "*******************    8     *******************\n",
      "recall - ConvLSTM       0.25801363975690794\n",
      "recall - Climatology    0.17666547941988756\n",
      "recall - Persistence    0.2848559532321151\n",
      "*******************    9     *******************\n",
      "recall - ConvLSTM       0.24191735537190082\n",
      "recall - Climatology    0.08532851239669421\n",
      "recall - Persistence    0.24395041322314048\n",
      "*******************    10     *******************\n",
      "recall - ConvLSTM       0.3462687717754512\n",
      "recall - Climatology    0.31790314876598696\n",
      "recall - Persistence    0.2090523667871815\n",
      "*******************    11     *******************\n",
      "recall - ConvLSTM       0.7261897291259987\n",
      "recall - Climatology    0.96659537082369\n",
      "recall - Persistence    0.5508195922988457\n",
      "*******************    12     *******************\n",
      "recall - ConvLSTM       0.8534166462575934\n",
      "recall - Climatology    0.9967842289510855\n",
      "recall - Persistence    0.7259854554696066\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ########                performance evaluation with recall               ########\n",
    "    #################################################################################\n",
    "    sequence_len, height, width = sic_exp_norm.shape\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with climatology  ############')\n",
    "    print('##############################################################')\n",
    "    # compute climatology\n",
    "    climatology = np.zeros((48, height, width),dtype=float)\n",
    "    for i in range(48):\n",
    "        climatology[i,:,:] = np.mean(sic_exp_norm[i::48,:,:],axis=0)\n",
    "    # repeat this climatology and calculate the RMSE\n",
    "    climatology_seq = np.tile(climatology,(test_year,1,1))\n",
    "    # turn into binary\n",
    "    climatology_denorm = np.zeros(climatology_seq.shape, dtype=float)\n",
    "    for i in np.arange(height):\n",
    "        climatology_denorm[:,i,:] = climatology_seq[:,i,:] / dx[i+12] * dx[35]    \n",
    "    climatology_denorm[climatology_denorm <= criterion_0] = 0\n",
    "    climatology_denorm[climatology_denorm > criterion_0] = 1\n",
    "    # turn matrix into int\n",
    "    climatology_denorm = climatology_denorm.astype(int)\n",
    "    \n",
    "    recall_climatology, _ = recall(climatology_denorm, sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with persistence  ############')\n",
    "    print('##############################################################')\n",
    "    recall_persist_0, _ = recall(sic_exp_bin[-test_year*12*4-1:-1,:,:],sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    recall_persist_1, _ = recall(sic_exp_bin[-test_year*12*4-1:-2,:,:],sic_exp_bin[-test_year*12*4+1:,:,:])\n",
    "    recall_persist_2, _ = recall(sic_exp_bin[-test_year*12*4-1:-3,:,:],sic_exp_bin[-test_year*12*4+2:,:,:])\n",
    "    recall_persist_3, _ = recall(sic_exp_bin[-test_year*12*4-1:-4,:,:],sic_exp_bin[-test_year*12*4+3:,:,:])\n",
    "    recall_persist_4, _ = recall(sic_exp_bin[-test_year*12*4-1:-5,:,:],sic_exp_bin[-test_year*12*4+4:,:,:])\n",
    "    recall_persist_5, _ = recall(sic_exp_bin[-test_year*12*4-1:-6,:,:],sic_exp_bin[-test_year*12*4+5:,:,:])\n",
    "    print('##############################################################')\n",
    "    print('########   start prediction with linear regression   #########')\n",
    "    print('##############################################################')\n",
    "    \n",
    "    print('#################################################################################')\n",
    "    print('############   evaluation and statistical matrix for the entire year ############')\n",
    "    print('#################################################################################')\n",
    "    recall_ConvLSTM_0, _ = recall(lead_pred_sic_bin[:,0,:,:],sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    recall_ConvLSTM_1, _ = recall(lead_pred_sic_bin[:-1,1,:,:],sic_exp_bin[-test_year*12*4+1:,:,:])\n",
    "    recall_ConvLSTM_2, _ = recall(lead_pred_sic_bin[:-2,2,:,:],sic_exp_bin[-test_year*12*4+2:,:,:])\n",
    "    recall_ConvLSTM_3, _ = recall(lead_pred_sic_bin[:-3,3,:,:],sic_exp_bin[-test_year*12*4+3:,:,:])\n",
    "    recall_ConvLSTM_4, _ = recall(lead_pred_sic_bin[:-4,4,:,:],sic_exp_bin[-test_year*12*4+4:,:,:])\n",
    "    recall_ConvLSTM_5, _ = recall(lead_pred_sic_bin[:-5,5,:,:],sic_exp_bin[-test_year*12*4+5:,:,:])\n",
    "    print(\"*******************     Lead time 0     *******************\")\n",
    "    print(\"Total recall with testing data - ConvLSTM\")\n",
    "    print(np.mean(recall_ConvLSTM_0))\n",
    "    print(\"Total recall with testing data - Climatology\")\n",
    "    print(np.mean(recall_climatology))\n",
    "    print(\"Total recall with testing data - Persistence\")\n",
    "    print(np.mean(recall_persist_0))\n",
    "    print(\"*******************     Lead time 1     *******************\")\n",
    "    print(\"Total recall with testing data - ConvLSTM\")\n",
    "    print(np.mean(recall_ConvLSTM_1))\n",
    "    print(\"Total recall with testing data - Persistence\")\n",
    "    print(np.mean(recall_persist_1))\n",
    "    print(\"*******************     Lead time 2     *******************\")\n",
    "    print(\"Total recall with testing data - ConvLSTM\")\n",
    "    print(np.mean(recall_ConvLSTM_2))\n",
    "    print(\"Total recall with testing data - Persistence\")\n",
    "    print(np.mean(recall_persist_2))\n",
    "    print(\"*******************     Lead time 3     *******************\")\n",
    "    print(\"Total recall with testing data - ConvLSTM\")\n",
    "    print(np.mean(recall_ConvLSTM_3))\n",
    "    print(\"Total recall with testing data - Persistence\")\n",
    "    print(np.mean(recall_persist_3))\n",
    "    print(\"*******************     Lead time 4     *******************\")\n",
    "    print(\"Total recall with testing data - ConvLSTM\")\n",
    "    print(np.mean(recall_ConvLSTM_4))\n",
    "    print(\"Total recall with testing data - Persistence\")\n",
    "    print(np.mean(recall_persist_4))\n",
    "    print(\"*******************     Lead time 5     *******************\")\n",
    "    print(\"Total recall with testing data - ConvLSTM\")\n",
    "    print(np.mean(recall_ConvLSTM_5))\n",
    "    print(\"Total recall with testing data - Persistence\")\n",
    "    print(np.mean(recall_persist_5))\n",
    "    print('##############################################################')\n",
    "    print('############           create a txt file          ############')\n",
    "    print('##############################################################')\n",
    "    f = open(os.path.join(output_path,\"report_recall_pred_bin.txt\"),\"w+\")\n",
    "    f.write(\"############   evaluation of prediction   ############\\n\")\n",
    "    f.write(\"############   Total recall with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall_ConvLSTM_0)))\n",
    "    f.write(\"recall - Climatology    {}\\n\".format(np.mean(recall_climatology)))\n",
    "    f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall_persist_0)))\n",
    "    f.write(\"*******************     Lead time 1     *******************\\n\")\n",
    "    f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall_ConvLSTM_1)))\n",
    "    f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall_persist_1)))\n",
    "    f.write(\"*******************     Lead time 2     *******************\\n\")\n",
    "    f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall_ConvLSTM_2)))\n",
    "    f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall_persist_2)))\n",
    "    f.write(\"*******************     Lead time 3     *******************\\n\")\n",
    "    f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall_ConvLSTM_3)))\n",
    "    f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall_persist_3)))\n",
    "    f.write(\"*******************     Lead time 4     *******************\\n\")\n",
    "    f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall_ConvLSTM_4)))\n",
    "    f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall_persist_4)))\n",
    "    f.write(\"*******************     Lead time 5     *******************\\n\")\n",
    "    f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall_ConvLSTM_5)))\n",
    "    f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall_persist_5)))\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"############   Monthly accuracy with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    for i in np.arange(1,13,1):\n",
    "        ConvLSTM_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        persist_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        climatology_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        truth_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        for j in np.arange(4):\n",
    "            ConvLSTM_monthly_series[j::4,:,:] = lead_pred_sic_bin[(i-1)*4+j::48,0,:,:]\n",
    "            persist_monthly_series[j::4,:,:] = sic_exp_bin[-test_year*12*4-1+(i-1)*4+j:-1:48,:,:]\n",
    "            climatology_monthly_series[j::4,:,:] = climatology_denorm[(i-1)*4+j::48,:,:]\n",
    "            truth_monthly_series[j::4,:,:] = sic_exp_bin[-test_year*12*4+(i-1)*4+j::48,:,:]\n",
    "        print(\"*******************    {}     *******************\".format(i))\n",
    "        print(\"recall - ConvLSTM       {}\".format(np.mean(recall(ConvLSTM_monthly_series,truth_monthly_series)[0])))\n",
    "        print(\"recall - Climatology    {}\".format(np.mean(recall(climatology_monthly_series,truth_monthly_series)[0])))\n",
    "        print(\"recall - Persistence    {}\".format(np.mean(recall(persist_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"*******************    {}     *******************\\n\".format(i))\n",
    "        f.write(\"recall - ConvLSTM       {}\\n\".format(np.mean(recall(ConvLSTM_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"recall - Climatology    {}\\n\".format(np.mean(recall(climatology_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"recall - Persistence    {}\\n\".format(np.mean(recall(persist_monthly_series,truth_monthly_series)[0])))\n",
    "    f.write(\"*******************     Lead time 6     *******************\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "############   start prediction with climatology  ############\n",
      "##############################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "############   start prediction with persistence  ############\n",
      "##############################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "########   start prediction with linear regression   #########\n",
      "##############################################################\n",
      "#################################################################################\n",
      "############   evaluation and statistical matrix for the entire year ############\n",
      "#################################################################################\n",
      "*******************     Lead time 0     *******************\n",
      "Total precision with testing data - ConvLSTM\n",
      "0.6626360787901849\n",
      "Total precision with testing data - Climatology\n",
      "0.4079385856750705\n",
      "Total precision with testing data - Persistence\n",
      "0.690738761572815\n",
      "*******************     Lead time 1     *******************\n",
      "Total precision with testing data - ConvLSTM\n",
      "0.6107196257319342\n",
      "Total precision with testing data - Persistence\n",
      "0.6356268444470853\n",
      "*******************     Lead time 2     *******************\n",
      "Total precision with testing data - ConvLSTM\n",
      "0.579523479629473\n",
      "Total precision with testing data - Persistence\n",
      "0.6105407500493609\n",
      "*******************     Lead time 3     *******************\n",
      "Total precision with testing data - ConvLSTM\n",
      "0.5556280316807053\n",
      "Total precision with testing data - Persistence\n",
      "0.5833019876273877\n",
      "*******************     Lead time 4     *******************\n",
      "Total precision with testing data - ConvLSTM\n",
      "0.5321481099096353\n",
      "Total precision with testing data - Persistence\n",
      "0.553914255338053\n",
      "*******************     Lead time 5     *******************\n",
      "Total precision with testing data - ConvLSTM\n",
      "0.5133675059459688\n",
      "Total precision with testing data - Persistence\n",
      "0.5249623371537447\n",
      "##############################################################\n",
      "############           create a txt file          ############\n",
      "##############################################################\n",
      "*******************    1     *******************\n",
      "precision - ConvLSTM       0.9026181601166431\n",
      "precision - Climatology    0.5559542418518143\n",
      "precision - Persistence    0.9267649426825348\n",
      "*******************    2     *******************\n",
      "precision - ConvLSTM       0.9191504507078476\n",
      "precision - Climatology    0.6083904361457534\n",
      "precision - Persistence    0.9307656748230683\n",
      "*******************    3     *******************\n",
      "precision - ConvLSTM       0.9389789991144883\n",
      "precision - Climatology    0.625218252792524\n",
      "precision - Persistence    0.9461523115764381\n",
      "*******************    4     *******************\n",
      "precision - ConvLSTM       0.931422338150755\n",
      "precision - Climatology    0.6066702234474803\n",
      "precision - Persistence    0.9246785425436064\n",
      "*******************    5     *******************\n",
      "precision - ConvLSTM       0.8758113133167318\n",
      "precision - Climatology    0.4990962228132416\n",
      "precision - Persistence    0.8529426820551145\n",
      "*******************    6     *******************\n",
      "precision - ConvLSTM       0.8264382811201926\n",
      "precision - Climatology    0.33860928286279546\n",
      "precision - Persistence    0.7542750415249005\n",
      "*******************    7     *******************\n",
      "precision - ConvLSTM       0.5637202053127027\n",
      "precision - Climatology    0.25354943889363424\n",
      "precision - Persistence    0.53082042568696\n",
      "*******************    8     *******************\n",
      "precision - ConvLSTM       0.25508710795141093\n",
      "precision - Climatology    0.25\n",
      "precision - Persistence    0.2554656667257474\n",
      "*******************    9     *******************\n",
      "precision - ConvLSTM       0.2326843886249756\n",
      "precision - Climatology    0.23414179104477612\n",
      "precision - Persistence    0.23465289256198346\n",
      "*******************    10     *******************\n",
      "precision - ConvLSTM       0.24895253003603335\n",
      "precision - Climatology    0.2184269005947958\n",
      "precision - Persistence    0.24059244560980797\n",
      "*******************    11     *******************\n",
      "precision - ConvLSTM       0.44714826265214447\n",
      "precision - Climatology    0.24949192107359747\n",
      "precision - Persistence    0.7659697420634921\n",
      "*******************    12     *******************\n",
      "precision - ConvLSTM       0.8096209083782928\n",
      "precision - Climatology    0.45571431658043265\n",
      "precision - Persistence    0.9257847710201259\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ########              performance evaluation with precision              ########\n",
    "    #################################################################################\n",
    "    sequence_len, height, width = sic_exp_norm.shape\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with climatology  ############')\n",
    "    print('##############################################################')\n",
    "    # compute climatology\n",
    "    climatology = np.zeros((48, height, width),dtype=float)\n",
    "    for i in range(48):\n",
    "        climatology[i,:,:] = np.mean(sic_exp_norm[i::48,:,:],axis=0)\n",
    "    # repeat this climatology and calculate the RMSE\n",
    "    climatology_seq = np.tile(climatology,(test_year,1,1))\n",
    "    # turn into binary\n",
    "    climatology_denorm = np.zeros(climatology_seq.shape, dtype=float)\n",
    "    for i in np.arange(height):\n",
    "        climatology_denorm[:,i,:] = climatology_seq[:,i,:] / dx[i+12] * dx[35]    \n",
    "    climatology_denorm[climatology_denorm <= criterion_0] = 0\n",
    "    climatology_denorm[climatology_denorm > criterion_0] = 1\n",
    "    # turn matrix into int\n",
    "    climatology_denorm = climatology_denorm.astype(int)\n",
    "    \n",
    "    prec_climatology, _ = precision(climatology_denorm, sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    print('##############################################################')\n",
    "    print('############   start prediction with persistence  ############')\n",
    "    print('##############################################################')\n",
    "    prec_persist_0, _ = precision(sic_exp_bin[-test_year*12*4-1:-1,:,:],sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    prec_persist_1, _ = precision(sic_exp_bin[-test_year*12*4-1:-2,:,:],sic_exp_bin[-test_year*12*4+1:,:,:])\n",
    "    prec_persist_2, _ = precision(sic_exp_bin[-test_year*12*4-1:-3,:,:],sic_exp_bin[-test_year*12*4+2:,:,:])\n",
    "    prec_persist_3, _ = precision(sic_exp_bin[-test_year*12*4-1:-4,:,:],sic_exp_bin[-test_year*12*4+3:,:,:])\n",
    "    prec_persist_4, _ = precision(sic_exp_bin[-test_year*12*4-1:-5,:,:],sic_exp_bin[-test_year*12*4+4:,:,:])\n",
    "    prec_persist_5, _ = precision(sic_exp_bin[-test_year*12*4-1:-6,:,:],sic_exp_bin[-test_year*12*4+5:,:,:])\n",
    "    print('##############################################################')\n",
    "    print('########   start prediction with linear regression   #########')\n",
    "    print('##############################################################')\n",
    "    \n",
    "    print('#################################################################################')\n",
    "    print('############   evaluation and statistical matrix for the entire year ############')\n",
    "    print('#################################################################################')\n",
    "    prec_ConvLSTM_0, _ = precision(lead_pred_sic_bin[:,0,:,:],sic_exp_bin[-test_year*12*4:,:,:])\n",
    "    prec_ConvLSTM_1, _ = precision(lead_pred_sic_bin[:-1,1,:,:],sic_exp_bin[-test_year*12*4+1:,:,:])\n",
    "    prec_ConvLSTM_2, _ = precision(lead_pred_sic_bin[:-2,2,:,:],sic_exp_bin[-test_year*12*4+2:,:,:])\n",
    "    prec_ConvLSTM_3, _ = precision(lead_pred_sic_bin[:-3,3,:,:],sic_exp_bin[-test_year*12*4+3:,:,:])\n",
    "    prec_ConvLSTM_4, _ = precision(lead_pred_sic_bin[:-4,4,:,:],sic_exp_bin[-test_year*12*4+4:,:,:])\n",
    "    prec_ConvLSTM_5, _ = precision(lead_pred_sic_bin[:-5,5,:,:],sic_exp_bin[-test_year*12*4+5:,:,:])\n",
    "    print(\"*******************     Lead time 0     *******************\")\n",
    "    print(\"Total precision with testing data - ConvLSTM\")\n",
    "    print(np.mean(prec_ConvLSTM_0))\n",
    "    print(\"Total precision with testing data - Climatology\")\n",
    "    print(np.mean(prec_climatology))\n",
    "    print(\"Total precision with testing data - Persistence\")\n",
    "    print(np.mean(prec_persist_0))\n",
    "    print(\"*******************     Lead time 1     *******************\")\n",
    "    print(\"Total precision with testing data - ConvLSTM\")\n",
    "    print(np.mean(prec_ConvLSTM_1))\n",
    "    print(\"Total precision with testing data - Persistence\")\n",
    "    print(np.mean(prec_persist_1))\n",
    "    print(\"*******************     Lead time 2     *******************\")\n",
    "    print(\"Total precision with testing data - ConvLSTM\")\n",
    "    print(np.mean(prec_ConvLSTM_2))\n",
    "    print(\"Total precision with testing data - Persistence\")\n",
    "    print(np.mean(prec_persist_2))\n",
    "    print(\"*******************     Lead time 3     *******************\")\n",
    "    print(\"Total precision with testing data - ConvLSTM\")\n",
    "    print(np.mean(prec_ConvLSTM_3))\n",
    "    print(\"Total precision with testing data - Persistence\")\n",
    "    print(np.mean(prec_persist_3))\n",
    "    print(\"*******************     Lead time 4     *******************\")\n",
    "    print(\"Total precision with testing data - ConvLSTM\")\n",
    "    print(np.mean(prec_ConvLSTM_4))\n",
    "    print(\"Total precision with testing data - Persistence\")\n",
    "    print(np.mean(prec_persist_4))\n",
    "    print(\"*******************     Lead time 5     *******************\")\n",
    "    print(\"Total precision with testing data - ConvLSTM\")\n",
    "    print(np.mean(prec_ConvLSTM_5))\n",
    "    print(\"Total precision with testing data - Persistence\")\n",
    "    print(np.mean(prec_persist_5))\n",
    "    print('##############################################################')\n",
    "    print('############           create a txt file          ############')\n",
    "    print('##############################################################')\n",
    "    f = open(os.path.join(output_path,\"report_precision_pred_bin.txt\"),\"w+\")\n",
    "    f.write(\"############   evaluation of prediction   ############\\n\")\n",
    "    f.write(\"############   Total precision with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(prec_ConvLSTM_0)))\n",
    "    f.write(\"precision - Climatology    {}\\n\".format(np.mean(prec_climatology)))\n",
    "    f.write(\"precision - Persistence    {}\\n\".format(np.mean(prec_persist_0)))\n",
    "    f.write(\"*******************     Lead time 1     *******************\\n\")\n",
    "    f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(prec_ConvLSTM_1)))\n",
    "    f.write(\"precision - Persistence    {}\\n\".format(np.mean(prec_persist_1)))\n",
    "    f.write(\"*******************     Lead time 2     *******************\\n\")\n",
    "    f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(prec_ConvLSTM_2)))\n",
    "    f.write(\"precision - Persistence    {}\\n\".format(np.mean(prec_persist_2)))\n",
    "    f.write(\"*******************     Lead time 3     *******************\\n\")\n",
    "    f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(prec_ConvLSTM_3)))\n",
    "    f.write(\"precision - Persistence    {}\\n\".format(np.mean(prec_persist_3)))\n",
    "    f.write(\"*******************     Lead time 4     *******************\\n\")\n",
    "    f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(prec_ConvLSTM_4)))\n",
    "    f.write(\"precision - Persistence    {}\\n\".format(np.mean(prec_persist_4)))\n",
    "    f.write(\"*******************     Lead time 5     *******************\\n\")\n",
    "    f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(prec_ConvLSTM_5)))\n",
    "    f.write(\"precision - Persistence    {}\\n\".format(np.mean(prec_persist_5)))\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"-\\n\")\n",
    "    f.write(\"############   Monthly accuracy with testing data   ############\\n\")\n",
    "    f.write(\"*******************     Lead time 0     *******************\\n\")\n",
    "    for i in np.arange(1,13,1):\n",
    "        ConvLSTM_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        persist_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        climatology_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        truth_monthly_series = np.zeros((test_year*4,height, width),dtype=float)\n",
    "        for j in np.arange(4):\n",
    "            ConvLSTM_monthly_series[j::4,:,:] = lead_pred_sic_bin[(i-1)*4+j::48,0,:,:]\n",
    "            persist_monthly_series[j::4,:,:] = sic_exp_bin[-test_year*12*4-1+(i-1)*4+j:-1:48,:,:]\n",
    "            climatology_monthly_series[j::4,:,:] = climatology_denorm[(i-1)*4+j::48,:,:]\n",
    "            truth_monthly_series[j::4,:,:] = sic_exp_bin[-test_year*12*4+(i-1)*4+j::48,:,:]\n",
    "        print(\"*******************    {}     *******************\".format(i))\n",
    "        print(\"precision - ConvLSTM       {}\".format(np.mean(precision(ConvLSTM_monthly_series,truth_monthly_series)[0])))\n",
    "        print(\"precision - Climatology    {}\".format(np.mean(precision(climatology_monthly_series,truth_monthly_series)[0])))\n",
    "        print(\"precision - Persistence    {}\".format(np.mean(precision(persist_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"*******************    {}     *******************\\n\".format(i))\n",
    "        f.write(\"precision - ConvLSTM       {}\\n\".format(np.mean(precision(ConvLSTM_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"precision - Climatology    {}\\n\".format(np.mean(precision(climatology_monthly_series,truth_monthly_series)[0])))\n",
    "        f.write(\"precision - Persistence    {}\\n\".format(np.mean(precision(persist_monthly_series,truth_monthly_series)[0])))\n",
    "    f.write(\"*******************     Lead time 6     *******************\\n\")\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
