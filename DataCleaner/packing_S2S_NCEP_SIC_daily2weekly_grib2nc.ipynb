{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Packing the 5 daily sea ice concentration fields into weekly fields from S2S as netCDF** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2020.07.17 ** <br>\n",
    "** Last Update  : 2020.07.20 ** <br>\n",
    "Description     : This notebook aims to pack the 5 daily SIC fields to weeky SIC fields from ECMWF S2S dataset.<br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : For the calculation of weekly fields, we assume each month consist of 4 weeks. The first 3 weeks\n",
    "                  including 7 days. The 4th week contain the rest of the days in that month.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time as tttt\n",
    "from netCDF4 import Dataset,num2date\n",
    "import os\n",
    "import pygrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  #########################################\n",
    "#time\n",
    "start_year = 2015\n",
    "end_year = 2017\n",
    "forecast_type = \"ensemble\" # control / ensemble\n",
    "#forecast_type = \"control\"\n",
    "# specify data path\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/S2S/NCEPens/S2S{}'.format(forecast_type)\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/S2S/NCEPens'\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of messages 19995\n",
      "[90.  88.5 87.  85.5 84.  82.5 81.  79.5 78.  76.5 75.  73.5 72.  70.5\n",
      " 69.  67.5 66.  64.5 63.  61.5 60.  58.5 57.  55.5 54.  52.5 51.  49.5\n",
      " 48.  46.5 45. ]\n",
      "[  0.    1.5   3.    4.5   6.    7.5   9.   10.5  12.   13.5  15.   16.5\n",
      "  18.   19.5  21.   22.5  24.   25.5  27.   28.5  30.   31.5  33.   34.5\n",
      "  36.   37.5  39.   40.5  42.   43.5  45.   46.5  48.   49.5  51.   52.5\n",
      "  54.   55.5  57.   58.5  60.   61.5  63.   64.5  66.   67.5  69.   70.5\n",
      "  72.   73.5  75.   76.5  78.   79.5  81.   82.5  84.   85.5  87.   88.5\n",
      "  90.   91.5  93.   94.5  96.   97.5  99.  100.5 102.  103.5 105.  106.5\n",
      " 108.  109.5 111.  112.5 114.  115.5 117.  118.5 120.  121.5 123.  124.5\n",
      " 126.  127.5 129.  130.5 132.  133.5 135.  136.5 138.  139.5 141.  142.5\n",
      " 144.  145.5 147.  148.5 150.  151.5 153.  154.5 156.  157.5 159.  160.5\n",
      " 162.  163.5 165.  166.5 168.  169.5 171.  172.5 174.  175.5 177.  178.5\n",
      " 180.  181.5 183.  184.5 186.  187.5 189.  190.5 192.  193.5 195.  196.5\n",
      " 198.  199.5 201.  202.5 204.  205.5 207.  208.5 210.  211.5 213.  214.5\n",
      " 216.  217.5 219.  220.5 222.  223.5 225.  226.5 228.  229.5 231.  232.5\n",
      " 234.  235.5 237.  238.5 240.  241.5 243.  244.5 246.  247.5 249.  250.5\n",
      " 252.  253.5 255.  256.5 258.  259.5 261.  262.5 264.  265.5 267.  268.5\n",
      " 270.  271.5 273.  274.5 276.  277.5 279.  280.5 282.  283.5 285.  286.5\n",
      " 288.  289.5 291.  292.5 294.  295.5 297.  298.5 300.  301.5 303.  304.5\n",
      " 306.  307.5 309.  310.5 312.  313.5 315.  316.5 318.  319.5 321.  322.5\n",
      " 324.  325.5 327.  328.5 330.  331.5 333.  334.5 336.  337.5 339.  340.5\n",
      " 342.  343.5 345.  346.5 348.  349.5 351.  352.5 354.  355.5 357.  358.5]\n"
     ]
    }
   ],
   "source": [
    "##########################   collect dimension info  ###################################\n",
    "if forecast_type == \"ensemble\":\n",
    "    grbs_SIC = pygrib.open(os.path.join(datapath,'S2S_NCEP_sic_ensemble_201501.grib'))\n",
    "else:\n",
    "    grbs_SIC = pygrib.open(os.path.join(datapath,'S2S_NCEP_control_201501.grib'))\n",
    "print ('Number of messages',grbs_SIC.messages)\n",
    "#for messenger in grbs_SIC:\n",
    "#    print (messenger)\n",
    "key_SIC = grbs_SIC.message(1)\n",
    "sample = key_SIC.values\n",
    "#sample = np.ma.masked_where(sample==0,sample)\n",
    "mask = np.ma.getmask(sample)\n",
    "lats, lons = key_SIC.latlons()\n",
    "latitude_SIC = lats[:31,0]\n",
    "longitude_SIC = lons[0,:]\n",
    "grbs_SIC.close()\n",
    "########################################################################################\n",
    "print(latitude_SIC)\n",
    "print(longitude_SIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output datasets\n",
    "# we only pack our timeseries from 2015 to 2017\n",
    "def create_netcdf_point_control (SIC, period, week, latitude, longitude, output_path):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    print(\"Start creating netcdf file for SIV from 2015 to 2017.\")\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(os.path.join(output_path,'sic_weekly_S2S_NCEP_control_2015_2017.nc'),'w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    year_wrap_dim = data_wrap.createDimension('year', len(period))\n",
    "    week_wrap_dim = data_wrap.createDimension('week', len(week))\n",
    "    leadweek_wrap_dim = data_wrap.createDimension('leadweek', 6)\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude', len(latitude))\n",
    "    lon_wrap_dim = data_wrap.createDimension('longitude', len(longitude))\n",
    "    # create coordinate variables for 3-dimensions\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    week_wrap_var = data_wrap.createVariable('week',np.int32,('week',))\n",
    "    leadweek_wrap_var = data_wrap.createVariable('leadweek',np.int32,('leadweek',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float32,('latitude',))\n",
    "    lon_wrap_var = data_wrap.createVariable('longitude',np.float32,('longitude',))    \n",
    "    # create the actual 4-d variable\n",
    "    SIC_wrap_var = data_wrap.createVariable('sic',np.float64,('year','week','leadweek','latitude','longitude'))\n",
    "    # global attributes\n",
    "    data_wrap.description = 'Lead time dependent weekly Sea Ice Concentration from ECMWF S2S'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    lon_wrap_var.units = 'degree_east'\n",
    "    SIC_wrap_var.units = 'fraction of sea ice'\n",
    "    SIC_wrap_var.long_name = 'sea ice concentration'\n",
    "\n",
    "    # writing data\n",
    "    year_wrap_var[:] = period\n",
    "    week_wrap_var[:] = week\n",
    "    leadweek_wrap_var[:] = range(6)\n",
    "    lat_wrap_var[:] = latitude\n",
    "    lon_wrap_var[:] = longitude\n",
    "    SIC_wrap_var[:] = SIC\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"Create netcdf file successfully\")\n",
    "    \n",
    "    \n",
    "def create_netcdf_point_ensemble (SIC, period, week, latitude, longitude, output_path):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    print(\"Start creating netcdf file for SIV from 2015 to 2017.\")\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(os.path.join(output_path,'sic_weekly_S2S_NCEP_ensemble_2015_2017.nc'),'w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    ensemble_wrap_dim = data_wrap.createDimension('ens', 15)\n",
    "    year_wrap_dim = data_wrap.createDimension('year', len(period))\n",
    "    week_wrap_dim = data_wrap.createDimension('week', len(week))\n",
    "    leadweek_wrap_dim = data_wrap.createDimension('leadweek', 6)\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude', len(latitude))\n",
    "    lon_wrap_dim = data_wrap.createDimension('longitude', len(longitude))\n",
    "    # create coordinate variables for 3-dimensions\n",
    "    ensemble_wrap_var = data_wrap.createVariable('ens',np.int32,('ens',))\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    week_wrap_var = data_wrap.createVariable('week',np.int32,('week',))\n",
    "    leadweek_wrap_var = data_wrap.createVariable('leadweek',np.int32,('leadweek',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float32,('latitude',))\n",
    "    lon_wrap_var = data_wrap.createVariable('longitude',np.float32,('longitude',))    \n",
    "    # create the actual 4-d variable\n",
    "    SIC_wrap_var = data_wrap.createVariable('sic',np.float64,('ens','year','week',\n",
    "                                                              'leadweek','latitude','longitude'))\n",
    "    # global attributes\n",
    "    data_wrap.description = 'Lead time dependent weekly Sea Ice Concentration from ECMWF S2S'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    lon_wrap_var.units = 'degree_east' \n",
    "    SIC_wrap_var.units = 'fraction of sea ice'\n",
    "    SIC_wrap_var.long_name = 'sea ice concentration'\n",
    "    # writing data\n",
    "    ensemble_wrap_var[:] = range(15)\n",
    "    year_wrap_var[:] = period\n",
    "    week_wrap_var[:] = week\n",
    "    leadweek_wrap_var[:] = range(6)\n",
    "    lat_wrap_var[:] = latitude\n",
    "    lon_wrap_var[:] = longitude\n",
    "    SIC_wrap_var[:] = SIC\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"Create netcdf file successfully\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning for S2S ensemble forecast!\n",
      "Processing ensemble forecast of 201501!\n",
      "Processing ensemble forecast of 201502!\n",
      "Processing ensemble forecast of 201503!\n",
      "Processing ensemble forecast of 201504!\n",
      "Processing ensemble forecast of 201505!\n",
      "Processing ensemble forecast of 201506!\n",
      "Processing ensemble forecast of 201507!\n",
      "Processing ensemble forecast of 201508!\n",
      "Processing ensemble forecast of 201509!\n",
      "Processing ensemble forecast of 201510!\n",
      "Processing ensemble forecast of 201511!\n",
      "Processing ensemble forecast of 201512!\n",
      "Processing ensemble forecast of 201601!\n",
      "Processing ensemble forecast of 201602!\n",
      "Processing ensemble forecast of 201603!\n",
      "Processing ensemble forecast of 201604!\n",
      "Processing ensemble forecast of 201605!\n",
      "Processing ensemble forecast of 201606!\n",
      "Processing ensemble forecast of 201607!\n",
      "Processing ensemble forecast of 201608!\n",
      "Processing ensemble forecast of 201609!\n",
      "Processing ensemble forecast of 201610!\n",
      "Processing ensemble forecast of 201611!\n",
      "Processing ensemble forecast of 201612!\n",
      "Processing ensemble forecast of 201701!\n",
      "Processing ensemble forecast of 201702!\n",
      "Processing ensemble forecast of 201703!\n",
      "Processing ensemble forecast of 201704!\n",
      "Processing ensemble forecast of 201705!\n",
      "Processing ensemble forecast of 201706!\n",
      "Processing ensemble forecast of 201707!\n",
      "Processing ensemble forecast of 201708!\n",
      "Processing ensemble forecast of 201709!\n",
      "Processing ensemble forecast of 201710!\n",
      "Processing ensemble forecast of 201711!\n",
      "Processing ensemble forecast of 201712!\n",
      "*******************************************************************\n",
      "*********************** create netcdf file*************************\n",
      "*******************************************************************\n",
      "Start creating netcdf file for SIV from 2015 to 2017.\n",
      "Create netcdf file successfully\n",
      "Packing 2D fields of NCEP S2S on surface level is complete!!!\n",
      "The output is in sleep, safe and sound!!!\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    # index of months\n",
    "    period = np.arange(start_year,end_year+1,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    index_week = np.arange(1,49,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get invariant from benchmark file\n",
    "    Dim_ens = 15\n",
    "    Dim_year = len(period)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_week = len(index_week)\n",
    "    Dim_lead_weeks = 6 # leading time in weeks\n",
    "    Dim_lead_days = 43 # leading time in days\n",
    "    Dim_latitude = len(latitude_SIC) # from 90 - 45 N\n",
    "    Dim_longitude = len(longitude_SIC)\n",
    "    ###################################################\n",
    "    #####   Month classifier for day selection    #####\n",
    "    ###################################################\n",
    "    #date_classifier = [0,2,4,6] # day index, twice sampling by S2S\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    if forecast_type == \"ensemble\":\n",
    "        print(\"Data cleaning for S2S ensemble forecast!\")\n",
    "        # data pool\n",
    "        pool_sic = np.zeros((Dim_ens, Dim_year, Dim_week, Dim_lead_weeks,\n",
    "                             Dim_latitude, Dim_longitude), dtype = float)\n",
    "        # loop for calculation\n",
    "        for i in period:\n",
    "            for j in index_month:\n",
    "                print(\"Processing ensemble forecast of {}{}!\".format(i,namelist_month[j-1]))\n",
    "                grbs_sic = pygrib.open(os.path.join(datapath,'S2S_NCEP_sic_ensemble_{}{}.grib'.format(i,namelist_month[j-1])))\n",
    "                messages = grbs_sic.messages\n",
    "                time_forecast = messages // Dim_lead_days // Dim_ens\n",
    "                pool_sic_month = np.zeros((Dim_ens, time_forecast, Dim_lead_days,\n",
    "                                           Dim_latitude, Dim_longitude),dtype = float)\n",
    "                # retrieve fields from GRIB file\n",
    "                counter_time = 0\n",
    "                counter_ens = 0\n",
    "                counter_lead_day = 0\n",
    "                counter_message = 1\n",
    "                while (counter_message <= messages):\n",
    "                    key_sic = grbs_sic.message(counter_message)\n",
    "                    sic = key_sic.values\n",
    "                    sic[mask==True] = -1.0\n",
    "                    sic[sic>1.1] = 0.0 # missing values\n",
    "                    pool_sic_month[counter_ens, counter_time, counter_lead_day, :, :] = sic[:Dim_latitude,:]\n",
    "                    counter_ens += 1\n",
    "                    if counter_message % Dim_ens == 0:\n",
    "                        counter_ens = 0\n",
    "                        counter_lead_day += 1\n",
    "                    if counter_message % (Dim_lead_days * Dim_ens) == 0:\n",
    "                        counter_time += 1\n",
    "                        counter_lead_day = 0\n",
    "                    counter_message += 1\n",
    "                grbs_sic.close()                    \n",
    "                # save data via classifier\n",
    "                # take weekly mean\n",
    "                # For the calculation of weekly fields, we assume each month consist of 4 weeks.\n",
    "                # The first 3 weeks including 7 days. The 4th week contain the rest of the days in that month.\n",
    "                pool_sic_week = np.zeros((Dim_ens, 4, Dim_lead_days, Dim_latitude, Dim_longitude),dtype=float)\n",
    "                for w in np.arange(4):\n",
    "                    if w < 3:\n",
    "                        pool_sic_week[:,w,:,:,:] = np.mean(pool_sic_month[:,w*7:w*7+7,:,:,:],axis=1)\n",
    "                    else:\n",
    "                        pool_sic_week[:,w,:,:,:] = np.mean(pool_sic_month[:,w*7:,:,:,:],axis=1)\n",
    "                for n in range(6): # 4 weeks per month\n",
    "                    # we take 6 weeks from leading 42 days\n",
    "                    pool_sic[:,i-start_year,j*4-4:j*4,n,:,:] = np.mean(pool_sic_week[:,:,n*7:n*7+7,:,:],2)               \n",
    "        ####################################################################\n",
    "        ######                 Data Wrapping (NetCDF)                #######\n",
    "        ####################################################################\n",
    "        create_netcdf_point_ensemble(pool_sic, period, index_week,\n",
    "                                     latitude_SIC, longitude_SIC, output_path)\n",
    "        \n",
    "    else:\n",
    "        print(\"Data cleaning for S2S control forecast!\")\n",
    "        pool_sic = np.zeros((Dim_year, Dim_week, Dim_lead_weeks, \n",
    "                             Dim_latitude, Dim_longitude), dtype = float)\n",
    "        # loop for calculation\n",
    "        for i in period:\n",
    "            for j in index_month:\n",
    "                print(\"Processing control forecast of {}{}!\".format(i,namelist_month[j-1]))\n",
    "                grbs_sic = pygrib.open(os.path.join(datapath,'S2S_NCEP_control_{}{}.grib'.format(i,namelist_month[j-1])))\n",
    "                messages = grbs_sic.messages\n",
    "                time_forecast = messages // Dim_lead_days\n",
    "                pool_sic_month = np.zeros((time_forecast, Dim_lead_days,\n",
    "                                           Dim_latitude, Dim_longitude),dtype = float)\n",
    "                # retrieve fields from GRIB file\n",
    "                counter_time = 0\n",
    "                counter_lead_day = 0\n",
    "                counter_message = 1\n",
    "                while (counter_message <= messages):\n",
    "                    key_sic = grbs_sic.message(counter_message)\n",
    "                    sic = key_sic.values\n",
    "                    sic[mask==True] = -1.0\n",
    "                    sic[sic>1.1] = 0.0 # missing values\n",
    "                    pool_sic_month[counter_time, counter_lead_day, :, :] = sic[:Dim_latitude,:]\n",
    "                    counter_lead_day += 1\n",
    "                    if counter_message % Dim_lead_days == 0:\n",
    "                        counter_time += 1\n",
    "                        counter_lead_day = 0\n",
    "                    counter_message += 1\n",
    "                grbs_sic.close()\n",
    "                # save data via classifier\n",
    "                # take weekly mean\n",
    "                # For the calculation of weekly fields, we assume each month consist of 4 weeks.\n",
    "                # The first 3 weeks including 7 days. The 4th week contain the rest of the days in that month.\n",
    "                pool_sic_week = np.zeros((4, Dim_lead_days, Dim_latitude, Dim_longitude),dtype=float)\n",
    "                for w in np.arange(4):\n",
    "                    if w < 3:\n",
    "                        pool_sic_week[w,:,:,:] = np.mean(pool_sic_month[w*7:w*7+7,:,:,:],axis=0)\n",
    "                    else:\n",
    "                        pool_sic_week[w,:,:,:] = np.mean(pool_sic_month[w*7:,:,:,:],axis=0)\n",
    "                \n",
    "                for n in range(6):\n",
    "                    # we take 6 weeks from leading 42 days\n",
    "                    pool_sic[i-start_year,j*4-4:j*4,n,:,:] = np.mean(pool_sic_week[:,n*7:n*7+7,:,:],1)\n",
    "        ####################################################################\n",
    "        ######                 Data Wrapping (NetCDF)                #######\n",
    "        ####################################################################\n",
    "        create_netcdf_point_control(pool_sic, period, index_week,\n",
    "                                    latitude_SIC, longitude_SIC, output_path)\n",
    "    print ('Packing 2D fields of NCEP S2S on surface level is complete!!!')\n",
    "    print ('The output is in sleep, safe and sound!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
