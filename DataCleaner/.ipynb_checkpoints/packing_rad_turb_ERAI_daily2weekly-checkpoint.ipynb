{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Packing the subdaily radiation and turbulent flux fields into weekly fields from ERA-Interim as netCDF** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2019.05.17 ** <br>\n",
    "** Last Update  : 2019.08.17 ** <br>\n",
    "Description     : This notebook aims to pack the subdaily SIC fields to weekly SIC fields from ERA-Interim.<br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : The data is subdaily spatial distribution of radiation and turbulent flux fields from 40N to 90N, dated from 1979 to 2017. It has sampling times as:<br>\n",
    "0:00 + 12:00 <br>\n",
    "\n",
    "he radiations fields are forecast fields instead of analysis fields. It is accumulated from a certain forecast time and thus for the values at certain time we should subtract the accumulated values. The prediction is 12 hrs. The starting time for each prediction as well as the predicted time are given below: <br>\n",
    "\n",
    "00:00 : 3:00 + 6:00 + 9:00 + 12:00 <br>\n",
    "12:00 : 3:00 + 6:00 + 9:00 + 12:00 <br>\n",
    "\n",
    "For the calculation of weekly fields, we assume each month consist of 4 weeks. The first 3 weeks including 7 days. The 4th week contain the rest of the days in that month.<br>\n",
    "\n",
    "For all the flux generated by ECMWF model, downward is positive (regardless of the standard name). So it is with ERA-Interim. !!! Note that the standard name in netcdf file doesn't not account for the direction in this case!! (upward for some variables, but actually with downward positively).\n",
    "* Net shortwave radiation at surface - downward \n",
    "* Net shortwave radiation at TOA - downward  \n",
    "* Net longwave radiation at surface - downward \n",
    "* Upwelling longwave radiation at TOA - downward \n",
    "* Latent energy flux - downward \n",
    "* Sensible heat flux - downward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time as tttt\n",
    "from netCDF4 import Dataset,num2date\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  #########################################\n",
    "# specify starting and ending time\n",
    "start_year = 1979\n",
    "end_year = 2017\n",
    "# specify data path\n",
    "# ERAI 3D fields on pressure level\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ERA-Interim/rad_daily'\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ERA-Interim'\n",
    "########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_key_retrieve(datapath, year, month):\n",
    "    # get the path to each datasets\n",
    "    print (\"Start retrieving datasets {} (y) {} (m)\".format(year,month))\n",
    "    # The shape of each variable is (67,480)\n",
    "    datapath_full = os.path.join(datapath, 'era{}'.format(year),'pressure_daily_075_diagnostic_{}_{}_rad.nc'.format(year,month))\n",
    "    # get the variable keys\n",
    "    var_key = Dataset(datapath_full)\n",
    "    \n",
    "    print (\"Retrieving datasets successfully and return the variable key!\")\n",
    "    return var_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriver(key):\n",
    "    print ('Extract subdaily fields and calculate weekly fields.')\n",
    "    sshf_accumulate = var_key.variables['sshf'][:]\n",
    "    slhf_accumulate = var_key.variables['slhf'][:]\n",
    "    ssr_accumulate = var_key.variables['ssr'][:]\n",
    "    str_accumulate = var_key.variables['str'][:]\n",
    "    tsr_accumulate = var_key.variables['tsr'][:]\n",
    "    ttr_accumulate = var_key.variables['ttr'][:]\n",
    "    # create arrays to store the values after removing accumulation\n",
    "    sshf_synoptic = np.zeros(sshf_accumulate.shape)\n",
    "    slhf_synoptic = np.zeros(slhf_accumulate.shape)\n",
    "    ssr_synoptic = np.zeros(ssr_accumulate.shape)\n",
    "    str_synoptic = np.zeros(str_accumulate.shape)\n",
    "    tsr_synoptic = np.zeros(tsr_accumulate.shape)\n",
    "    ttr_synoptic = np.zeros(ttr_accumulate.shape)\n",
    "    # remove the accumulation and take the monthly mean\n",
    "    sshf_synoptic[0::4,:,:] = sshf_accumulate[0::4,:,:]\n",
    "    slhf_synoptic[0::4,:,:] = slhf_accumulate[0::4,:,:]\n",
    "    ssr_synoptic[0::4,:,:] = ssr_accumulate[0::4,:,:]\n",
    "    str_synoptic[0::4,:,:] = str_accumulate[0::4,:,:]\n",
    "    tsr_synoptic[0::4,:,:] = tsr_accumulate[0::4,:,:]\n",
    "    ttr_synoptic[0::4,:,:] = ttr_accumulate[0::4,:,:]\n",
    "    for i in np.arange(3):\n",
    "        sshf_synoptic[i+1::4,:,:] = sshf_accumulate[i+1::4,:,:] - sshf_accumulate[i::4,:,:]\n",
    "        slhf_synoptic[i+1::4,:,:] = slhf_accumulate[i+1::4,:,:] - slhf_accumulate[i::4,:,:]\n",
    "        ssr_synoptic[i+1::4,:,:] = ssr_accumulate[i+1::4,:,:] - ssr_accumulate[i::4,:,:]\n",
    "        str_synoptic[i+1::4,:,:] = str_accumulate[i+1::4,:,:] - str_accumulate[i::4,:,:]\n",
    "        tsr_synoptic[i+1::4,:,:] = tsr_accumulate[i+1::4,:,:] - tsr_accumulate[i::4,:,:]\n",
    "        ttr_synoptic[i+1::4,:,:] = ttr_accumulate[i+1::4,:,:] - ttr_accumulate[i::4,:,:]\n",
    "    # create the arrays for daily mean\n",
    "    lat = var_key.variables['latitude'][:]\n",
    "    lon = var_key.variables['longitude'][:]\n",
    "    time = var_key.variables['time'][:]\n",
    "    sshf_daily = np.zeros((len(time)//8, len(lat), len(lon)),dtype=float)\n",
    "    slhf_daily = np.zeros((len(time)//8, len(lat), len(lon)),dtype=float)\n",
    "    ssr_daily = np.zeros((len(time)//8, len(lat), len(lon)),dtype=float)\n",
    "    str_daily = np.zeros((len(time)//8, len(lat), len(lon)),dtype=float)\n",
    "    tsr_daily = np.zeros((len(time)//8, len(lat), len(lon)),dtype=float)\n",
    "    ttr_daily = np.zeros((len(time)//8, len(lat), len(lon)),dtype=float)\n",
    "    # take the mean per month and change the unit to W/m2\n",
    "    for i in np.arange(len(time)//8):\n",
    "        sshf_daily[i,:,:] = np.mean(sshf_synoptic[i*8:i*8+8,:,:], 0) / (3 * 3600)\n",
    "        slhf_daily[i,:,:] = np.mean(slhf_synoptic[i*8:i*8+8,:,:], 0) / (3 * 3600)\n",
    "        ssr_daily[i,:,:] = np.mean(ssr_synoptic[i*8:i*8+8,:,:], 0) / (3 * 3600)\n",
    "        str_daily[i,:,:] = np.mean(str_synoptic[i*8:i*8+8,:,:], 0) / (3 * 3600)\n",
    "        tsr_daily[i,:,:] = np.mean(tsr_synoptic[i*8:i*8+8,:,:], 0) / (3 * 3600)\n",
    "        ttr_daily[i,:,:] = np.mean(ttr_synoptic[i*8:i*8+8,:,:], 0) / (3 * 3600)\n",
    "    SFlux_daily = sshf_daily[:] + slhf_daily[:] + ssr_daily[:] + str_daily[:]\n",
    "    TOAFlux_daily = tsr_daily[:] + ttr_daily[:]\n",
    "    # take weekly mean\n",
    "    SFlux_weekly = np.zeros((4,len(lat),len(lon)),dtype=float)\n",
    "    TOAFlux_weekly = np.zeros((4,len(lat),len(lon)),dtype=float)\n",
    "    for i in np.arange(4):\n",
    "        if i < 3:\n",
    "            SFlux_weekly[i,:,:] = np.mean(SFlux_daily[i*7:i*7+7,:,:],axis=0)\n",
    "            TOAFlux_weekly[i,:,:] = np.mean(TOAFlux_daily[i*7:i*7+7,:,:],axis=0)\n",
    "        else:\n",
    "            SFlux_weekly[i,:,:] = np.mean(SFlux_daily[i*7:,:,:],axis=0)\n",
    "            TOAFlux_weekly[i,:,:] = np.mean(TOAFlux_daily[i*7:,:,:],axis=0)\n",
    "\n",
    "    return SFlux_weekly, TOAFlux_weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output datasets\n",
    "# we only pack our timeseries from 1979 to 2017\n",
    "def create_netcdf_point (SFlux_weekly, TOAFlux_weekly, period, week,\n",
    "                         latitude, longitude, output_path):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    print(\"Start creating netcdf file for UV10M from 1979 to 2017.\")\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(output_path + os.sep + 'rad_flux_weekly_erai_1979_2017.nc','w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    year_wrap_dim = data_wrap.createDimension('year', len(period))\n",
    "    week_wrap_dim = data_wrap.createDimension('week', len(week))\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude', len(latitude))\n",
    "    lon_wrap_dim = data_wrap.createDimension('longitude', len(longitude))\n",
    "    # create coordinate variables for 3-dimensions\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    week_wrap_var = data_wrap.createVariable('week',np.int32,('week',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float64,('latitude',))\n",
    "    lon_wrap_var = data_wrap.createVariable('longitude',np.float64,('longitude',))    \n",
    "    # create the actual 4-d variable\n",
    "    SFlux_wrap_var = data_wrap.createVariable('SFlux',np.float64,('year','week','latitude','longitude'))\n",
    "    TOAFlux_wrap_var = data_wrap.createVariable('TOAFlux',np.float64,('year','week','latitude','longitude'))\n",
    "\n",
    "    # global attributes\n",
    "    data_wrap.description = 'Weekly Net Surface/TOA Flux'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    lon_wrap_var.units = 'degree_east'\n",
    "    SFlux_wrap_var.units = 'W/m2'\n",
    "    TOAFlux_wrap_var.units = 'W/m2'\n",
    "    SFlux_wrap_var.long_name = 'Net Surface Flux'\n",
    "    TOAFlux_wrap_var.long_name = 'Net TOA Flux'\n",
    "\n",
    "    # writing data\n",
    "    year_wrap_var[:] = period\n",
    "    week_wrap_var[:] = week\n",
    "    lat_wrap_var[:] = latitude\n",
    "    lon_wrap_var[:] = longitude\n",
    "    SFlux_wrap_var[:] = SFlux_weekly\n",
    "    TOAFlux_wrap_var[:] = TOAFlux_weekly\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"Create netcdf file successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start retrieving datasets 1979 (y) 1 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 2 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 3 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 4 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 5 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 6 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 7 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 8 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 9 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 10 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 11 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1979 (y) 12 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 1 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 2 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 3 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 4 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 5 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 6 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 7 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 8 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 9 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 10 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 11 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1980 (y) 12 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 1 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 2 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 3 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 4 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 5 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 6 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 7 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 8 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 9 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 10 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 11 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1981 (y) 12 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 1 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 2 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 3 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 4 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 5 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 6 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 7 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 8 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 9 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 10 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 11 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1982 (y) 12 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 1 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 2 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 3 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 4 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 5 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 6 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 7 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 8 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 9 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n",
      "Start retrieving datasets 1983 (y) 10 (m)\n",
      "Retrieving datasets successfully and return the variable key!\n",
      "Extract subdaily fields and calculate weekly fields.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    # index of months\n",
    "    period = np.arange(start_year,end_year+1,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    index_week = np.arange(1,49,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get invariant from benchmark file\n",
    "    Dim_year = len(period)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_week = len(index_week)\n",
    "    Dim_latitude = 67\n",
    "    Dim_longitude = 480\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    # data pool\n",
    "    pool_SFlux = np.zeros((Dim_year,Dim_week,Dim_latitude,Dim_longitude),dtype = float)\n",
    "    pool_TOAFlux = np.zeros((Dim_year,Dim_week,Dim_latitude,Dim_longitude),dtype = float)\n",
    "    # loop for calculation\n",
    "    for i in period:\n",
    "        for j in index_month:\n",
    "            var_key = var_key_retrieve(datapath,i,j)\n",
    "            # get the key of each variable\n",
    "            latitude = var_key.variables['latitude'][:]\n",
    "            longitude = var_key.variables['longitude'][:]\n",
    "            SFlux_weekly, TOAFlux_weekly = retriver(var_key)\n",
    "            pool_SFlux[i-1979,j*4-4:j*4,:,:] = SFlux_weekly\n",
    "            pool_TOAFlux[i-1979,j*4-4:j*4,:,:] = TOAFlux_weekly\n",
    "    ####################################################################\n",
    "    ######                 Data Wrapping (NetCDF)                #######\n",
    "    ####################################################################\n",
    "    # round off the values in case of leaking\n",
    "    #pool_sic = np.around(pool_sic,decimals=6)\n",
    "    create_netcdf_point(pool_SFlux, pool_TOAFlux, period, index_week,\n",
    "                        latitude, longitude, output_path)\n",
    "    print ('Packing 2D fields of ERA-Interim on surface level is complete!!!')\n",
    "    print ('The output is in sleep, safe and sound!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
