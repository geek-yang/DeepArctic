{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Packing netCDF for monthly sea ice concentration fields from NOAA/NSIDC (passive microwave)** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2020.07.23 ** <br>\n",
    "** Last Update  : 2020.07.23 ** <br>\n",
    "Description     : This notebook aims to pack the sea ice concentration fields from NOAA/NSIDC.<br>\n",
    "Return Values   : netCDF4 <br>\n",
    "Caveat          : The data is further processed by certain algorithms from NASA Goddard Center. The dataset consists of mulitple variables, but we only use the Merged GSFC NASA Team/Bootstrap daily sea ice concentrations from 1978 through most recent processing (variable name:\"goddard_merged_seaice_conc\"). It combines the results from two algorithms by NASA The details about these two algorithms are provided via the link:<br>\n",
    "https://nsidc.org/support/faq/nasa-team-vs-bootstrap-algorithm<br>\n",
    "\n",
    "!!! It should be noticed that the data before 1987 is saved bi-daily and afterwards daily. We process them seperately and this script only works with structured data after 1987.<br>\n",
    "\n",
    "More information (incl. description of variables) is available through:<br>\n",
    "https://nsidc.org/data/g02202<br>\n",
    "\n",
    "The projection center coordinate (refernce for ygrid and xgrid) info is included in the netCDF file:<br>\n",
    "Latitude: North pole (90 deg)<br>\n",
    "Longitude: -45 deg w.r.t. 0 deg (greenwitch)<br>\n",
    "\n",
    "The coordinate values (latitude & longitude) are the exact values.<br>\n",
    "\n",
    "We also apply nearest neighbour interpolation to the ERA-Interim grid. We use the iris module.scipy function. An alternative can be the scipy module  \"scipy.interpolate.NearestNDInterpolator\".<br>\n",
    "\n",
    "Reference\n",
    "Meier, W. N., F. Fetterer, M. Savoie, S. Mallory, R. Duerr, and J. Stroeve. 2017. NOAA/NSIDC Climate Data Record of Passive Microwave Sea Ice Concentration, Version 3. Boulder, Colorado USA. NSIDC: National Snow and Ice Data Center. doi: https://doi.org/10.7265/N59P2ZTG.<br>\n",
    "Peng, G., W. N. Meier, D. Scott, and M. Savoie. 2013. A long-term and reproducible passive microwave sea ice concentration data record for climate studies and monitoring, Earth Syst. Sci. Data. 5. 311-318. https://doi.org/10.5194/essd-5-311-2013<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "import glob\n",
    "import iris\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################   Input zone  ######################################\n",
    "# specify starting and ending time\n",
    "start_year = 1988\n",
    "end_year = 2018\n",
    "# specify data path\n",
    "# SICpm fields\n",
    "datapath = '/home/ESLT0068/WorkFlow/Core_Database_AMET_OMET_reanalysis/SIC_passive_microwave_NASA/daily'\n",
    "datapath_coordinate = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ERA-Interim'\n",
    "# sample\n",
    "benchmark_key = Dataset(os.path.join(datapath,\"2004\",\"seaice_conc_daily_nh_f13_20040112_v03r01.nc\"))\n",
    "coordinate_key = Dataset(os.path.join(datapath_coordinate,\"sic_weekly_erai_1979_2017.nc\"))\n",
    "# specify output path for figures\n",
    "output_path = '/home/ESLT0068/WorkFlow/Core_Database_AMET_OMET_reanalysis/SIC_passive_microwave_NASA'\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 304)\n",
      "(448, 304)\n",
      "(448, 304)\n",
      "(448,)\n",
      "(304,)\n",
      "89.8368159996152\n",
      "31.1026717524309\n",
      "179.813975395493\n",
      "-180.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#########################   Basic dimensions of NSIDC sic  #########################\n",
    "latitude = benchmark_key.variables['latitude'][:]\n",
    "longitude = benchmark_key.variables['longitude'][:]\n",
    "ygrid = benchmark_key.variables['ygrid'][:]\n",
    "xgrid = benchmark_key.variables['xgrid'][:]\n",
    "sic_sample = benchmark_key.variables['goddard_merged_seaice_conc'][0,:,:]\n",
    "print(sic_sample.shape)\n",
    "print(latitude.shape)\n",
    "print(longitude.shape)\n",
    "print(ygrid.shape)\n",
    "print(xgrid.shape)\n",
    "print(np.amax(latitude))\n",
    "print(np.amin(latitude))\n",
    "print(np.amax(longitude))\n",
    "print(np.amin(longitude))\n",
    "print(np.amax(sic_sample))\n",
    "print(np.amin(sic_sample))\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################   Target coordinate for interpolation   ######################\n",
    "latitude_ERAI = coordinate_key.variables['latitude'][:]\n",
    "longitude_ERAI = coordinate_key.variables['longitude'][:]\n",
    "#value_sample_coordinate = coordinate_key.variables['sic'][0,0,:,:]\n",
    "#print(lat_coordinate)\n",
    "#print(lon_coordinate)\n",
    "#print(value_sample_coordinate[:3,:])\n",
    "#reshape_test = np.reshape(value_sample_coordinate,[len(lat_coordinate)*len(lon_coordinate)], order='F')\n",
    "#print(reshape_test[:100])\n",
    "#reshape_back = np.reshape(reshape_test,[len(lat_coordinate),len(lon_coordinate)], order='F')\n",
    "#print(reshape_back[:3,:])\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_key_retrieve(datapath, year, month, day):\n",
    "    # get the path to each datasets\n",
    "    print (\"Start retrieving datasets {} (y) - {} (m) - {}(d)\".format(year,namelist_month[month-1],namelist_month[day]))\n",
    "    # Sea Ice Concentration\n",
    "    datapath_key = glob.glob(os.path.join(datapath,\"seaice_conc_daily_nh_*_{0}{1}{2}_v03r01.nc\".format(year,namelist_month[month-1],namelist_month[day])))[0]\n",
    "    # get the variable keys\n",
    "    var_key = Dataset(datapath_key)\n",
    "\n",
    "    print (\"Retrieving datasets successfully and return the variable key!\")\n",
    "    return var_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(field, latitude, longitude, latitude_new, longitude_new):\n",
    "    '''\n",
    "    The input field should be 2D array include information on latitude and longitude,\n",
    "    with latitude and longitude the unstructured grid. The target coordinate must be structured grid\n",
    "    and they are represented as 1D array latitude_new and longitude_new.\n",
    "    '''\n",
    "    # basic dimensions for cube in iris\n",
    "    lat_iris = iris.coords.AuxCoord(latitude, standard_name='latitude', long_name='latitude',\n",
    "                                    var_name='lat', units='degrees')\n",
    "    lon_iris = iris.coords.AuxCoord(longitude, standard_name='longitude', long_name='longitude',\n",
    "                                    var_name='lon', units='degrees')\n",
    "    # assembly the cube\n",
    "    cube_iris = iris.cube.Cube(field, long_name='unstructured field', var_name='field', \n",
    "                                units='1', aux_coords_and_dims=[(lat_iris, (0,1)), (lon_iris, (0,1))])\n",
    "    coord_sys = iris.coord_systems.GeogCS(iris.fileformats.pp.EARTH_RADIUS)\n",
    "    cube_iris.coord('latitude').coord_system = coord_sys\n",
    "    cube_iris.coord('longitude').coord_system = coord_sys\n",
    "    projection = ccrs.PlateCarree()\n",
    "    lat_grid = latitude_new\n",
    "    lon_grid = longitude_new\n",
    "    lat_aux = iris.coords.DimCoord(lat_grid, standard_name='latitude',\n",
    "                                    units='degrees_north', coord_system='GeogCS')\n",
    "    lon_aux = iris.coords.DimCoord(lon_grid, standard_name='longitude',\n",
    "                                    units='degrees_east', coord_system='GeogCS')\n",
    "    dummy_data = np.zeros((len(lat_grid), len(lon_grid)))\n",
    "    cube_tar = iris.cube.Cube(dummy_data,dim_coords_and_dims=[(lat_aux, 0), (lon_aux, 1)])\n",
    "    # create the coordinate system for the target cube\n",
    "    cube_tar.coord('latitude').guess_bounds()\n",
    "    cube_tar.coord('longitude').guess_bounds()\n",
    "    cube_tar.coord('latitude').coord_system = coord_sys\n",
    "    cube_tar.coord('longitude').coord_system = coord_sys\n",
    "    # create a weight matrix for regridding\n",
    "    weights = np.ones(cube_iris.shape)\n",
    "    # get regridder from given cubes\n",
    "    base = iris.analysis.UnstructuredNearest()\n",
    "    regridder = base.regridder(cube_iris,cube_tar)\n",
    "    # Transform cube to target projection\n",
    "    cube_regrid = regridder(cube_iris)\n",
    "    regrid_sic = cube_regrid.data\n",
    "    regrid_sic[regrid_sic>1.000001] = 0\n",
    "    \n",
    "    return regrid_sic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_netcdf_point(pool_sic, output_path):\n",
    "    print ('*******************************************************************')\n",
    "    print ('*********************** create netcdf file*************************')\n",
    "    print ('*******************************************************************')\n",
    "    # wrap the datasets into netcdf file\n",
    "    # 'NETCDF3_CLASSIC', 'NETCDF3_64BIT', 'NETCDF4_CLASSIC', and 'NETCDF4'\n",
    "    data_wrap = Dataset(os.path.join(output_path, 'noaa_nsidc_weekly_regress_1979_2018_sic_passive_microwave.nc'),'w',format = 'NETCDF4')\n",
    "    # create dimensions for netcdf data\n",
    "    year_wrap_dim = data_wrap.createDimension('year',Dim_year)\n",
    "    week_wrap_dim = data_wrap.createDimension('week', Dim_week)\n",
    "    lat_wrap_dim = data_wrap.createDimension('latitude',Dim_latitude)\n",
    "    lon_wrap_dim = data_wrap.createDimension('longitude',Dim_longitude)\n",
    "    # create coordinate variables for 3-dimensions\n",
    "    year_wrap_var = data_wrap.createVariable('year',np.int32,('year',))\n",
    "    week_wrap_var = data_wrap.createVariable('month',np.int32,('week',))\n",
    "    lat_wrap_var = data_wrap.createVariable('latitude',np.float32,('latitude',))\n",
    "    lon_wrap_var = data_wrap.createVariable('longitude',np.float32,('longitude',))\n",
    "    # create the actual 3-d variable\n",
    "    sic_wrap_var = data_wrap.createVariable('sic',np.float32,('year','week','latitude','longitude'),zlib=True)\n",
    "    # global attributes\n",
    "    data_wrap.description = 'Weekly mean sea ice concentration with passive microwave by NOAA/NSIDC'\n",
    "    # variable attributes\n",
    "    lat_wrap_var.units = 'degree_north'\n",
    "    lon_wrap_var.units = 'degree_east'\n",
    "\n",
    "    sicpm_wrap_var.units = '1'\n",
    "\n",
    "    sicpm_wrap_var.long_name = 'sea ice concentration with passive microwave'\n",
    "\n",
    "    # writing data\n",
    "    lat_wrap_var[:] = latitude_ERAI\n",
    "    lon_wrap_var[:] = longitude_ERAI\n",
    "    week_wrap_var[:] = index_week\n",
    "    year_wrap_var[:] = period\n",
    "\n",
    "    sic_wrap_var[:] = pool_sic\n",
    "\n",
    "    # close the file\n",
    "    data_wrap.close()\n",
    "    print (\"Create netcdf file successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    ####################################################################\n",
    "    ######  Create time namelist matrix for variable extraction  #######\n",
    "    ####################################################################\n",
    "    # date and time arrangement\n",
    "    # namelist of month and days for file manipulation\n",
    "    namelist_month = ['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "    namelist_day = ['01','02','03','04','05','06','07','08','09','10',\n",
    "                    '11','12','13','14','15','16','17','18','19','20',\n",
    "                    '21','22','23','24','25','26','27','28','29','30',\n",
    "                    '31']\n",
    "    # index of months\n",
    "    index_days_long = np.arange(31)\n",
    "    index_days_short = np.arange(30)\n",
    "    index_days_Feb_short = np.arange(28)\n",
    "    index_days_Feb_long = np.arange(29)\n",
    "    long_month_list = np.array([1,3,5,7,8,10,12])\n",
    "    leap_year_list = np.array([1976,1980,1984,1988,1992,1996,2000,2004,2008,2012,2016,2020])\n",
    "    # index of months\n",
    "    period = np.arange(start_year,end_year+1,1)\n",
    "    index_month = np.arange(1,13,1)\n",
    "    index_week = np.arange(1,49,1)\n",
    "    ####################################################################\n",
    "    ######       Extract invariant and calculate constants       #######\n",
    "    ####################################################################\n",
    "    # get invariant from benchmark file\n",
    "    Dim_year = len(period)\n",
    "    Dim_month = len(index_month)\n",
    "    Dim_week = len(index_week)\n",
    "    Dim_latitude = len(latitude_ERAI)\n",
    "    Dim_longitude = len(longitude_ERAI)\n",
    "    #############################################\n",
    "    #####   Create space for stroing data   #####\n",
    "    #############################################\n",
    "    # data pool for zonal integral\n",
    "    pool_sic_weekly_interpolate = np.zeros((Dim_year,Dim_week,Dim_latitude,Dim_longitude),dtype = float)\n",
    "    # loop for calculation\n",
    "    for i in period:\n",
    "        for j in index_month:\n",
    "            ###################################################################\n",
    "            ######                   begin the month loop                ######\n",
    "            ###################################################################\n",
    "            # determine how many days are there in a month\n",
    "            if j in long_month_list:\n",
    "                days = index_days_long\n",
    "            elif j == 2:\n",
    "                if i in leap_year_list:\n",
    "                    days = index_days_Feb_long\n",
    "                else:\n",
    "                    days = index_days_Feb_short\n",
    "            else:\n",
    "                days = index_days_short \n",
    "            pool_sic_daily = np.zeros((len(days),len(ygrid),len(xgrid)),dtype = float)\n",
    "            for k in days:\n",
    "                var_key = var_key_retrieve(datapath, i, j, k)\n",
    "                pool_sic_daily[k,:,:] = var_key.variables['goddard_merged_seaice_conc_monthly'][0,:,:]\n",
    "            # For the calculation of weekly fields, we assume each month consist of 4 weeks.\n",
    "            # The first 3 weeks including 7 days. The 4th week contain the rest of the days in that month.\n",
    "            pool_sic_weekly = np.zeros((4, len(ygrid),len(xgrid)),dtype=float)\n",
    "            for w in np.arange(4):\n",
    "                if w < 3:\n",
    "                    pool_sic_weekly[w,:,:] = np.mean(pool_sic_daily[w*7:w*7+7,:,:],axis=0)\n",
    "                else:\n",
    "                    pool_sic_weekly[w,:,:] = np.mean(pool_sic_daily[w*7:,:,:],axis=0)\n",
    "            # interpolation on the erai grid\n",
    "            for w in np.arange(4):\n",
    "                pool_sic_weekly_interpolate[i-start_year,j*4-4+w,:,:] = interpolation(pool_sic_weekly[w,:,:], latitude,\n",
    "                                                                                      longitude, latitude_ERAI, longitude_ERAI)\n",
    "    ####################################################################\n",
    "    ######                 Data Wrapping (NetCDF)                #######\n",
    "    ####################################################################\n",
    "    create_netcdf_point(pool_sic_weekly_interpolate, output_path)\n",
    "    print ('Packing 2D fields of NOAA is complete!!!')\n",
    "    print ('The output is in sleep, safe and sound!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
