{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright Netherlands eScience Center <br>\n",
    "** Function     : Predict the Spatial Sea Ice Concentration with BayesConvLSTM at weekly time scale** <br>\n",
    "** Author       : Yang Liu ** <br>\n",
    "** First Built  : 2020.03.02 ** <br>\n",
    "** Last Update  : 2020.03.09 ** <br>\n",
    "** Library      : Pytorth, Numpy, NetCDF4, os, iris, cartopy, dlacs, matplotlib **<br>\n",
    "Description     : This notebook serves to predict the Arctic sea ice using deep learning. The Bayesian Convolutional Long Short Time Memory neural network is used to deal with this spatial-temporal sequence problem. We use Pytorch as the deep learning framework. <br>\n",
    "<br>\n",
    "** Here we predict sea ice concentration with one extra relevant field from either ocean or atmosphere to test the predictor.** <br>\n",
    "\n",
    "Return Values   : pkl model and figures <br>\n",
    "\n",
    "The regionalization adopted here follows that of the MASIE (Multisensor Analyzed Sea Ice Extent) product available from the National Snow and Ice Data Center:<br>\n",
    "https://nsidc.org/data/masie/browse_regions<br>\n",
    "It is given by paper J.Walsh et. al., 2019. Benchmark seasonal prediction skill estimates based on regional indices.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "import numbers\n",
    "\n",
    "# for data loading\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "# for pre-processing and machine learning\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#import scipy\n",
    "import torch\n",
    "import torch.nn.functional\n",
    "\n",
    "#sys.path.append(os.path.join('C:','Users','nosta','ML4Climate','Scripts','DLACs'))\n",
    "#sys.path.append(\"C:\\\\Users\\\\nosta\\\\ML4Climate\\\\Scripts\\\\DLACs\")\n",
    "sys.path.append(\"../../../../DLACs\")\n",
    "import dlacs\n",
    "import dlacs.BayesConvLSTM\n",
    "import dlacs.preprocess\n",
    "import dlacs.function\n",
    "import dlacs.saveNetCDF\n",
    "\n",
    "# for visualization\n",
    "import dlacs.visual\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import iris # also helps with regriding\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# ignore all the DeprecationWarnings by pytorch\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing device is Dell Inspirion 5680 with Intel Core i7-8700 x64 CPU and Nvidia GTX 1060 6GB GPU.<br>\n",
    "Here is a benchmark about cpu v.s. gtx 1060 <br>\n",
    "https://www.analyticsindiamag.com/deep-learning-tensorflow-benchmark-intel-i5-4210u-vs-geforce-nvidia-1060-6gb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "constant = {'g' : 9.80616,      # gravititional acceleration [m / s2]\n",
    "            'R' : 6371009,      # radius of the earth [m]\n",
    "            'cp': 1004.64,      # heat capacity of air [J/(Kg*K)]\n",
    "            'Lv': 2500000,      # Latent heat of vaporization [J/Kg]\n",
    "            'R_dry' : 286.9,    # gas constant of dry air [J/(kg*K)]\n",
    "            'R_vap' : 461.5,    # gas constant for water vapour [J/(kg*K)]\n",
    "            'rho' : 1026,       # sea water density [kg/m3]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Data ** <br>\n",
    "Time span of each product included: <br>\n",
    "** Reanalysis ** <br>\n",
    "- **ERA-Interim** 1979 - 2016 (ECMWF)\n",
    "- **ORAS4**       1958 - 2014 (ECMWF)\n",
    "\n",
    "** Index ** <br>\n",
    "- **NINO3.4**     1950 - 2017 (NOAA)\n",
    "- **AO**          1950 - 2017 (NOAA)\n",
    "- **NAO**         1950 - 2017 (NOAA)\n",
    "- **AMO**         1950 - 2017 (NOAA)\n",
    "- **PDO**         1950 - 2017 (University of Washington)\n",
    "\n",
    "!! These index are given by NCEP/NCAR Reanalysis (CDAS) <br>\n",
    "\n",
    "\n",
    "Alternative (not in use yet) <br>\n",
    "** Reanalysis ** <br>\n",
    "- **MERRA2**      1980 - 2016 (NASA)\n",
    "- **JRA55**       1979 - 2015 (JMA)\n",
    "- **GLORYS2V3**   1993 - 2014 (Mercartor Ocean)\n",
    "- **SODA3**       1980 - 2015\n",
    "- **PIOMASS**     1980 - 2015\n",
    "\n",
    "** Observations ** <br>\n",
    "- **NSIDC**       1958 - 2017 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# \n",
    "#########                           datapath                             ########\n",
    "#################################################################################\n",
    "# please specify data path\n",
    "#datapath_ERAI = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ERA-Interim'\n",
    "datapath_ERAI = 'H:\\\\Creator_Zone\\\\Core_Database_DeepLearn\\\\ERA-Interim'\n",
    "#datapath_ORAS4 = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ORAS4'\n",
    "datapath_ORAS4 = 'H:\\\\Creator_Zone\\\\Core_Database_DeepLearn\\\\ORAS4'\n",
    "#datapath_ORAS4_mask = '/home/ESLT0068/WorkFlow/Core_Database_DeepLearn/ORAS4'\n",
    "datapath_ORAS4_mask = 'H:\\\\Creator_Zone\\\\Core_Database_DeepLearn\\\\ORAS4'\n",
    "#datapath_PIOMASS = '/home/ESLT0068/WorkFlow/Core_Database_AMET_OMET_reanalysis/PIOMASS'\n",
    "#datapath_PIOMASS = 'H:\\\\Creator_Zone\\\\Core_Database_AMET_OMET_reanalysis\\\\PIOMASS'\n",
    "#datapath_clim_index = '/home/ESLT0068/WorkFlow/Core_Database_AMET_OMET_reanalysis/Climate_index'\n",
    "#datapath_clim_index = 'F:\\\\PhD_essential\\\\Core_Database_AMET_OMET_reanalysis\\\\Climate_index'\n",
    "#output_path = '/home/ESLT0068/NLeSC/Computation_Modeling/ML4Climate/PredictArctic/BayesMaps'\n",
    "output_path = 'C:\\\\Users\\\\nosta\\\\ML4Climate\\\\PredictArctic\\\\BayesMaps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** get the key to the datasets *************************\n",
      "*********************** extract variables *************************\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    print ('*********************** get the key to the datasets *************************')\n",
    "    # weekly variables on ERAI grid\n",
    "    dataset_ERAI_fields_sic = Dataset(os.path.join(datapath_ERAI,\n",
    "                                      'sic_weekly_erai_1979_2017.nc'))\n",
    "#     dataset_ERAI_fields_slp = Dataset(os.path.join(datapath_ERAI,\n",
    "#                                       'slp_weekly_erai_1979_2017.nc'))\n",
    "#     dataset_ERAI_fields_t2m = Dataset(os.path.join(datapath_ERAI,\n",
    "#                                       't2m_weekly_erai_1979_2017.nc'))\n",
    "#     dataset_ERAI_fields_z500 = Dataset(os.path.join(datapath_ERAI,\n",
    "#                                        'z500_weekly_erai_1979_2017.nc'))\n",
    "#     dataset_ERAI_fields_z850 = Dataset(os.path.join(datapath_ERAI,\n",
    "#                                        'z850_weekly_erai_1979_2017.nc'))\n",
    "#     dataset_ERAI_fields_uv10m = Dataset(os.path.join(datapath_ERAI,\n",
    "#                                        'uv10m_weekly_erai_1979_2017.nc'))\n",
    "#     dataset_ERAI_fields_rad = Dataset(os.path.join(datapath_ERAI,\n",
    "#                                         'rad_flux_weekly_erai_1979_2017.nc'))\n",
    "    #dataset_PIOMASS_siv = Dataset(os.path.join(datapath_PIOMASS,\n",
    "    #                             'siv_monthly_PIOMASS_1979_2017.nc'))\n",
    "    # OHC interpolated on ERA-Interim grid\n",
    "    dataset_ORAS4_OHC = Dataset(os.path.join(datapath_ORAS4,\n",
    "                                'ohc_monthly_oras2erai_1978_2017.nc'))\n",
    "#     dataset_index = Dataset(os.path.join(datapath_clim_index,\n",
    "#                             'index_climate_monthly_regress_1950_2017.nc'))\n",
    "    #dataset_ERAI_fields_flux = Dataset(os.path.join(datapath_ERAI_fields,\n",
    "    #                                  'surface_erai_monthly_regress_1979_2017_radiation.nc'))\n",
    "    # mask\n",
    "    dataset_ORAS4_mask = Dataset(os.path.join(datapath_ORAS4_mask, 'mesh_mask.nc'))\n",
    "    print ('*********************** extract variables *************************')\n",
    "    #################################################################################\n",
    "    #########                        data gallery                           #########\n",
    "    #################################################################################\n",
    "    # we use time series from 1979 to 2016 (468 months in total)\n",
    "    # training data: 1979 - 2013\n",
    "    # validation: 2014 - 2016\n",
    "    # variables list:\n",
    "    # SIC (ERA-Interim) / SIV (PIOMASS) / SST (ERA-Interim) / ST (ERA-Interim) / OHC (ORAS4) / AO-NAO-AMO-NINO3.4 (NOAA)\n",
    "    # integrals from spatial fields cover the area from 20N - 90N (4D fields [year, month, lat, lon])\n",
    "    # *************************************************************************************** #\n",
    "    # SIC (ERA-Interim) - benckmark\n",
    "    SIC_ERAI = dataset_ERAI_fields_sic.variables['sic'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "    year_ERAI = dataset_ERAI_fields_sic.variables['year'][:-1]\n",
    "    week_ERAI = dataset_ERAI_fields_sic.variables['week'][:]\n",
    "    latitude_ERAI = dataset_ERAI_fields_sic.variables['latitude'][:]\n",
    "    longitude_ERAI = dataset_ERAI_fields_sic.variables['longitude'][:]\n",
    "    # T2M (ERA-Interim)\n",
    "#     T2M_ERAI = dataset_ERAI_fields_t2m.variables['t2m'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     year_ERAI_t2m = dataset_ERAI_fields_t2m.variables['year'][:-1]\n",
    "#     week_ERAI_t2m = dataset_ERAI_fields_t2m.variables['week'][:]\n",
    "#     latitude_ERAI_t2m = dataset_ERAI_fields_t2m.variables['latitude'][:]\n",
    "#     longitude_ERAI_t2m = dataset_ERAI_fields_t2m.variables['longitude'][:]\n",
    "    # SLP (ERA-Interim)\n",
    "#     SLP_ERAI = dataset_ERAI_fields_slp.variables['slp'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     year_ERAI_slp = dataset_ERAI_fields_slp.variables['year'][:-1]\n",
    "#     week_ERAI_slp = dataset_ERAI_fields_slp.variables['week'][:]\n",
    "#     latitude_ERAI_slp = dataset_ERAI_fields_slp.variables['latitude'][:]\n",
    "#     longitude_ERAI_slp = dataset_ERAI_fields_slp.variables['longitude'][:]\n",
    "    # Z500 (ERA-Interim)\n",
    "#     Z500_ERAI = dataset_ERAI_fields_z500.variables['z'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     year_ERAI_z500 = dataset_ERAI_fields_z500.variables['year'][:-1]\n",
    "#     week_ERAI_z500 = dataset_ERAI_fields_z500.variables['week'][:]\n",
    "#     latitude_ERAI_z500 = dataset_ERAI_fields_z500.variables['latitude'][:]\n",
    "#     longitude_ERAI_z500 = dataset_ERAI_fields_z500.variables['longitude'][:]\n",
    "    # Z850 (ERA-Interim)\n",
    "#     Z850_ERAI = dataset_ERAI_fields_z850.variables['z'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     year_ERAI_z850 = dataset_ERAI_fields_z850.variables['year'][:-1]\n",
    "#     week_ERAI_z850 = dataset_ERAI_fields_z850.variables['week'][:]\n",
    "#     latitude_ERAI_z850 = dataset_ERAI_fields_z850.variables['latitude'][:]\n",
    "#     longitude_ERAI_z850 = dataset_ERAI_fields_z850.variables['longitude'][:]\n",
    "    # UV10M (ERA-Interim)\n",
    "#     U10M_ERAI = dataset_ERAI_fields_uv10m.variables['u10m'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     V10M_ERAI = dataset_ERAI_fields_uv10m.variables['v10m'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     year_ERAI_uv10m = dataset_ERAI_fields_uv10m.variables['year'][:-1]\n",
    "#     week_ERAI_uv10m = dataset_ERAI_fields_uv10m.variables['week'][:]\n",
    "#     latitude_ERAI_uv10m = dataset_ERAI_fields_uv10m.variables['latitude'][:]\n",
    "#     longitude_ERAI_uv10m = dataset_ERAI_fields_uv10m.variables['longitude'][:]\n",
    "    # SFlux (ERA-Interim)\n",
    "#     SFlux_ERAI = dataset_ERAI_fields_rad.variables['SFlux'][:-1,:,:,:] # 4D fields [year, week, lat, lon]\n",
    "#     year_ERAI_SFlux = dataset_ERAI_fields_rad.variables['year'][:-1]\n",
    "#     week_ERAI_SFlux = dataset_ERAI_fields_rad.variables['week'][:]\n",
    "#     latitude_ERAI_SFlux = dataset_ERAI_fields_rad.variables['latitude'][:]\n",
    "#     longitude_ERAI_SFlux = dataset_ERAI_fields_rad.variables['longitude'][:]\n",
    "    #SIV (PIOMASS)\n",
    "    #SIV_PIOMASS = dataset_PIOMASS_siv.variables['SIV'][:-12]\n",
    "    #year_SIV = dataset_PIOMASS_siv.variables['year'][:-1]\n",
    "    # OHC (ORAS4)\n",
    "    # from 1978 - 2017 (for interpolation) / from 90 N upto 40 N\n",
    "    OHC_300_ORAS4 = dataset_ORAS4_OHC.variables['OHC'][:-1,:,:67,:]/1000 # unit Peta Joule\n",
    "    latitude_ORAS4 = dataset_ORAS4_OHC.variables['latitude'][:]\n",
    "    longitude_ORAS4 = dataset_ORAS4_OHC.variables['longitude'][:]\n",
    "    mask_OHC = np.ma.getmask(OHC_300_ORAS4[0,0,:,:])\n",
    "    # AO-NAO-AMO-NINO3.4 (NOAA)\n",
    "#     AO = dataset_index.variables['AO'][348:-1] # from 1979 - 2017\n",
    "#     NAO = dataset_index.variables['NAO'][348:-1]\n",
    "#     NINO = dataset_index.variables['NINO'][348:-1]\n",
    "#     AMO = dataset_index.variables['AMO'][348:-1]\n",
    "#     PDO = dataset_index.variables['PDO'][348:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # first check of grid\n",
    "    print(latitude_ERAI)\n",
    "    print(longitude_ERAI)\n",
    "    print(longitude_ORAS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************** create mask *************************\n",
      "*********************** calc mask *************************\n",
      "*********************** packing *************************\n"
     ]
    }
   ],
   "source": [
    "    #################################################################################\n",
    "    ###########                 global land-sea mask                      ###########\n",
    "    #################################################################################\n",
    "    sea_ice_mask_global = np.ones((len(latitude_ERAI),len(longitude_ERAI)),dtype=float)\n",
    "    sea_ice_mask_global[SIC_ERAI[0,0,:,:]==-1] = 0\n",
    "    #################################################################################\n",
    "    ###########                regionalization sea mask                   ###########\n",
    "    #################################################################################\n",
    "    print ('*********************** create mask *************************')\n",
    "    # W:-156 E:-124 N:80 S:67\n",
    "    mask_Beaufort = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:-180 E:-156 N:80 S:66\n",
    "    mask_Chukchi = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:146 E:180 N:80 S:67\n",
    "    mask_EastSiberian = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:100 E:146 N:80 S:67\n",
    "    mask_Laptev = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:60 E:100 N:80 S:67\n",
    "    mask_Kara = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:18 E:60 N:80 S:64\n",
    "    mask_Barents = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:-44 E:18 N:80 S:55\n",
    "    mask_Greenland = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    # W:-180 E:180 N:90 S:80\n",
    "    mask_CenArctic = np.zeros((len(latitude_ERAI),len(longitude_ERAI)),dtype=int)\n",
    "    print ('*********************** calc mask *************************')\n",
    "    mask_Beaufort[13:31,32:76] = 1\n",
    "\n",
    "    mask_Chukchi[13:32,0:32] = 1\n",
    "    mask_Chukchi[13:32,-1] = 1\n",
    "\n",
    "    mask_EastSiberian[13:31,434:479] = 1\n",
    "\n",
    "    mask_Laptev[13:31,374:434] = 1\n",
    "\n",
    "    mask_Kara[13:31,320:374] = 1\n",
    "\n",
    "    mask_Barents[13:36,264:320] = 1\n",
    "\n",
    "    mask_Greenland[13:47,179:264] = 1\n",
    "    mask_Greenland[26:47,240:264] = 0\n",
    "\n",
    "    mask_CenArctic[:13,:] = 1\n",
    "    print ('*********************** packing *************************')\n",
    "    mask_dict = {'Beaufort': mask_Beaufort[:,:],\n",
    "                 'Chukchi': mask_Chukchi[:,:],\n",
    "                 'EastSiberian': mask_EastSiberian[:,:],\n",
    "                 'Laptev': mask_Laptev[:,:],\n",
    "                 'Kara': mask_Kara[:,:],\n",
    "                 'Barents': mask_Barents[:,:],\n",
    "                 'Greenland': mask_Greenland[:,:],\n",
    "                 'CenArctic': mask_CenArctic[:,:]}\n",
    "    seas_namelist = ['Beaufort','Chukchi','EastSiberian','Laptev',\n",
    "                     'Kara', 'Barents', 'Greenland','CenArctic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #################################################################################\n",
    "    ########                  temporal interpolation matrix                  ########\n",
    "    #################################################################################\n",
    "    # interpolate from monthly to weekly\n",
    "    # original monthly data will be taken as the last week of the month\n",
    "    OHC_300_ORAS4_weekly_series = np.zeros(SIC_ERAI.reshape(len(year_ERAI)*48,len(latitude_ERAI),len(longitude_ERAI)).shape,\n",
    "                                           dtype=float)\n",
    "    OHC_300_ORAS4_series= dlacs.preprocess.operator.unfold(OHC_300_ORAS4)\n",
    "    # calculate the difference between two months\n",
    "    OHC_300_ORAS4_deviation_series = (OHC_300_ORAS4_series[1:,:,:] - OHC_300_ORAS4_series[:-1,:,:]) / 4\n",
    "    for i in np.arange(4):\n",
    "        OHC_300_ORAS4_weekly_series[3-i::4,:,:] = OHC_300_ORAS4_series[12:,:,:] - i * OHC_300_ORAS4_deviation_series[11:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************  calculate extent from spatial fields  *******************\n",
      "================  reshape input data into time series  =================\n"
     ]
    }
   ],
   "source": [
    "    print ('******************  calculate extent from spatial fields  *******************')\n",
    "    # size of the grid box\n",
    "    dx = 2 * np.pi * constant['R'] * np.cos(2 * np.pi * latitude_ERAI /\n",
    "                                            360) / len(longitude_ERAI)\n",
    "    dy = np.pi * constant['R'] / 480\n",
    "    # calculate the sea ice area\n",
    "    SIC_ERAI_area = np.zeros(SIC_ERAI.shape, dtype=float)\n",
    "#     SFlux_ERAI_area = np.zeros(SFlux_ERAI.shape, dtype=float)\n",
    "    for i in np.arange(len(latitude_ERAI[:])):\n",
    "        # change the unit to terawatt\n",
    "        SIC_ERAI_area[:,:,i,:] = SIC_ERAI[:,:,i,:]* dx[i] * dy / 1E+6 # unit km2\n",
    "#         SFlux_ERAI_area[:,:,i,:] = SFlux_ERAI[:,:,i,:]* dx[i] * dy / 1E+12 # unit TeraWatt\n",
    "    SIC_ERAI_area[SIC_ERAI_area<0] = 0 # switch the mask from -1 to 0\n",
    "    print ('================  reshape input data into time series  =================')\n",
    "    SIC_ERAI_area_series = dlacs.preprocess.operator.unfold(SIC_ERAI_area)\n",
    "#     T2M_ERAI_series = dlacs.preprocess.operator.unfold(T2M_ERAI)\n",
    "#     SLP_ERAI_series = dlacs.preprocess.operator.unfold(SLP_ERAI)\n",
    "#     Z500_ERAI_series = dlacs.preprocess.operator.unfold(Z500_ERAI)\n",
    "#     Z850_ERAI_series = dlacs.preprocess.operator.unfold(Z850_ERAI)\n",
    "#     U10M_ERAI_series = dlacs.preprocess.operator.unfold(U10M_ERAI)\n",
    "#     V10M_ERAI_series = dlacs.preprocess.operator.unfold(V10M_ERAI)\n",
    "#     SFlux_ERAI_area_series = dlacs.preprocess.operator.unfold(SFlux_ERAI_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************  choose the fields from target region  *******************\n",
      "******************  choose the fields from target region  *******************\n",
      "(1824, 24, 56)\n",
      "(1824, 24, 56)\n",
      "[80.5  79.75 79.   78.25 77.5  76.75 76.   75.25 74.5  73.75 73.   72.25\n",
      " 71.5  70.75 70.   69.25 68.5  67.75 67.   66.25 65.5  64.75 64.   63.25]\n",
      "[18.   18.75 19.5  20.25 21.   21.75 22.5  23.25 24.   24.75 25.5  26.25\n",
      " 27.   27.75 28.5  29.25 30.   30.75 31.5  32.25 33.   33.75 34.5  35.25\n",
      " 36.   36.75 37.5  38.25 39.   39.75 40.5  41.25 42.   42.75 43.5  44.25\n",
      " 45.   45.75 46.5  47.25 48.   48.75 49.5  50.25 51.   51.75 52.5  53.25\n",
      " 54.   54.75 55.5  56.25 57.   57.75 58.5  59.25]\n",
      "[80.5  79.75 79.   78.25 77.5  76.75 76.   75.25 74.5  73.75 73.   72.25\n",
      " 71.5  70.75 70.   69.25 68.5  67.75 67.   66.25 65.5  64.75 64.   63.25]\n",
      "[18.   18.75 19.5  20.25 21.   21.75 22.5  23.25 24.   24.75 25.5  26.25\n",
      " 27.   27.75 28.5  29.25 30.   30.75 31.5  32.25 33.   33.75 34.5  35.25\n",
      " 36.   36.75 37.5  38.25 39.   39.75 40.5  41.25 42.   42.75 43.5  44.25\n",
      " 45.   45.75 46.5  47.25 48.   48.75 49.5  50.25 51.   51.75 52.5  53.25\n",
      " 54.   54.75 55.5  56.25 57.   57.75 58.5  59.25]\n"
     ]
    }
   ],
   "source": [
    "    print ('******************  choose the fields from target region  *******************')\n",
    "    # select land-sea mask\n",
    "    sea_ice_mask_barents = sea_ice_mask_global[12:36,264:320]\n",
    "    print ('******************  choose the fields from target region  *******************')\n",
    "    # select the area between greenland and ice land for instance 60-70 N / 44-18 W\n",
    "    sic_exp = SIC_ERAI_area_series[:,12:36,264:320]\n",
    "#     t2m_exp = T2M_ERAI_series[:,12:36,264:320]\n",
    "#     slp_exp = SLP_ERAI_series[:,12:36,264:320]\n",
    "#     z500_exp = Z500_ERAI_series[:,12:36,264:320]\n",
    "#     z850_exp = Z850_ERAI_series[:,12:36,264:320]\n",
    "#     u10m_exp = U10M_ERAI_series[:,12:36,264:320]\n",
    "#     v10m_exp = V10M_ERAI_series[:,12:36,264:320]\n",
    "#     sflux_exp = SFlux_ERAI_area_series[:,12:36,264:320]\n",
    "    ohc_exp = OHC_300_ORAS4_weekly_series[:,12:36,264:320]\n",
    "    print(sic_exp.shape)\n",
    "#     print(t2m_exp.shape)\n",
    "#     print(slp_exp.shape)\n",
    "#     print(z500_exp.shape)\n",
    "#     print(u10m_exp.shape)\n",
    "#     print(v10m_exp.shape)\n",
    "#     print(sflux_exp.shape)\n",
    "    print(ohc_exp.shape)\n",
    "    print(latitude_ERAI[12:36])\n",
    "    print(longitude_ERAI[264:320])\n",
    "    print(latitude_ORAS4[12:36])\n",
    "    print(longitude_ORAS4[264:320])\n",
    "    #print(latitude_ERAI[26:40])\n",
    "    #print(longitude_ERAI[180:216])\n",
    "    #print(sic_exp[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  pre-processing  *********************\n",
      "=========================   normalize data   ===========================\n",
      "================  save the normalizing factor  =================\n",
      "1565.2049481856002 km2\n",
      "0.0 km2\n",
      "====================    A series of time (index)    ====================\n",
      "===================  artificial data for evaluation ====================\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  pre-processing  *********************')\n",
    "    print ('=========================   normalize data   ===========================')\n",
    "    sic_exp_norm = dlacs.preprocess.operator.normalize(sic_exp)\n",
    "#     t2m_exp_norm = deepclim.preprocess.operator.normalize(t2m_exp)\n",
    "#     slp_exp_norm = deepclim.preprocess.operator.normalize(slp_exp)\n",
    "#     z500_exp_norm = deepclim.preprocess.operator.normalize(z500_exp)\n",
    "#     z850_exp_norm = deepclim.preprocess.operator.normalize(z850_exp)\n",
    "#     u10m_exp_norm = deepclim.preprocess.operator.normalize(u10m_exp)\n",
    "#     v10m_exp_norm = deepclim.preprocess.operator.normalize(v10m_exp)\n",
    "#     sflux_exp_norm = deepclim.preprocess.operator.normalize(sflux_exp)\n",
    "    ohc_exp_norm = dlacs.preprocess.operator.normalize(ohc_exp)\n",
    "    print('================  save the normalizing factor  =================')\n",
    "    sic_max = np.amax(sic_exp)\n",
    "    sic_min = np.amin(sic_exp)\n",
    "    print(sic_max,\"km2\")\n",
    "    print(sic_min,\"km2\")\n",
    "    print ('====================    A series of time (index)    ====================')\n",
    "    _, yy, xx = sic_exp_norm.shape # get the lat lon dimension\n",
    "    year = np.arange(1979,2017,1)\n",
    "    year_cycle = np.repeat(year,48)\n",
    "    month_cycle = np.repeat(np.arange(1,13,1),4)\n",
    "    month_cycle = np.tile(month_cycle,len(year)+1) # one extra repeat for lead time dependent prediction\n",
    "    month_cycle.astype(float)\n",
    "    month_2D = np.repeat(month_cycle[:,np.newaxis],yy,1)\n",
    "    month_exp = np.repeat(month_2D[:,:,np.newaxis],xx,2)\n",
    "    print ('===================  artificial data for evaluation ====================')\n",
    "    # calculate climatology of SIC\n",
    "#     seansonal_cycle_SIC = np.zeros(48,dtype=float)\n",
    "#     for i in np.arange(48):\n",
    "#         seansonal_cycle_SIC[i] = np.mean(SIC_ERAI_sum_norm[i::48],axis=0)\n",
    "    # weight for loss\n",
    "#     weight_month = np.array([0,1,1,\n",
    "#                              1,0,0,\n",
    "#                              1,1,1,\n",
    "#                              0,0,0])\n",
    "    #weight_loss = np.repeat(weight_month,4)\n",
    "    #weight_loss = np.tile(weight_loss,len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565.2049481856002\n",
      "0.0\n",
      "(1824, 24, 56)\n",
      "[[251.4346045  251.05600413 250.50871172 ... 244.2139345  244.13173904\n",
      "  244.01692955]\n",
      " [246.64799721 246.04600942 245.45885542 ... 245.36829478 245.24715214\n",
      "  245.12353721]\n",
      " [246.7402512  247.31849816 248.16998491 ... 246.47754407 246.37387686\n",
      "  246.26773736]\n",
      " ...\n",
      " [271.39089775 271.56084288 271.75937185 ... 272.40565781 271.30805881\n",
      "  270.25455477]\n",
      " [271.93968032 272.07067828 272.09157428 ... 273.35488503 272.4173081\n",
      "  271.39831464]\n",
      " [272.82825155 272.92514534 272.69329114 ... 274.15672261 273.34753587\n",
      "  272.70551716]]\n",
      "(24, 56)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEylJREFUeJzt3V2sHOV9x/Hf3zYJEEOD42CMDTWNqMCiCZEihEQviNNGlKKSSiEq6gsXqO5FIiUSUetyQxspEpXapJFSVT0NCJACBTUQUGS1QSaR0xsaJ6HCsV01Ly51fOJTq06wRSB2/O/FzsCy3j07O6/Py/cjoXN2vWfnmd2Z73mYnd1j7i4AQPzWDD0AAEA7CDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0Ai1vW5sA0b1viWrb0uEgCit//F08fd/Z3zbtdrXbdsXacnd2/sc5EAEL1fvWL5v6vcjkMuAJAIgg4AiSDoAJAIgg4AiSDoAJAIgg4AAdt9anvl2xJ0AAjUIjGXCDoABGnRmEs9B/2nZ8/X7lPbaw0UAHJRt5GDzdAJOwC0a/APVpkW9VvXHxhgJAAwvCYT3SCPoTN7B5Cjpt0LMuglog4A1QUddImoA8hDG60LPugSUQeQtrYaF0XQAQDzRRN0ZukAUtRm26IJukTUAaSl7aZFFXSJqAPALNEFXSLqADBNlEGXiDqAuHXRsMHf+t9E+YAs+lEBkw8kHzUAIAVRB720+9T2VaM87zfhvJ8HgBjMDbqZXSHpEUmXSToracndP2dmGyQ9LmmbpMOSPuLuJ7ob6uqa/u9L3dk+ACyqq0PGVY6hn5F0j7tfK+lGSR81s+2Sdkna4+5XS9pTXI4eHwwGIFZzg+7uy+7+7eL7k5IOStoi6XZJDxc3e1jSh7oa5BAIO4AudNmVhc5yMbNtkt4r6XlJm9x9WRpFX9KlbQ8uBIQdQCwqB93M1kv6kqRPuPvLC/zcTjPbZ2b7Tp04XWeMQSDsAJrquiGVznIxs/M0ivkX3f3J4upjZrbZ3ZfNbLOklWk/6+5LkpYk6crrLvYWxjwozogZxrwdgecEIetrMljlLBeT9ICkg+7+mbF/ekbSXZLuL74+3ckIA0TU+7HITlDnvQVV7p/nGU30/X/1VWboN0n6Q0kvmtkLxXX3ahTyJ8zsbkkvSbqjmyGGidMcq6vyd2Pb3vDH7+/W9Qdq3z9vQkMVoRyOnRt0d/83STbjnz/Q7nDi0+dsvelG0/U4m8you9Tmsgh8nkIJ9jxJvFN0aF3M1rvYgNo+Dh3LRt6lWY8BoY9DatswQW/R5P/mV7ldSEIdV4wI/bBy3ZYJekdy3aCwuqq/9FEd+9obCDowEOJeDwGfjaADASDusxHw6gg6EJgqp3mGjggPg6ADEQjlTVCEOmwEHUgEsUW0f1MUAPBmBB0AEkHQASARBB0AEkHQASARnOUCAIF57vg1E9fsqfRzBB0ABnRuvOvrNegvnzlfzx2/Rjs2HupzsQAQhDbjPc0gM/RypQg7gFR1He9pBj3kQtgBpGCIeE8TxDF0DsMAiEkoAZ8URNAlog4gbKFGfFwwQZc4BAMgHDEEfFJQQS8xWwfQtxgDPinIoEvM1gF0K4WATwo26CVm6wDakGLAJwUfdInZOoDqcgj3LFEEvcRsHUAp53DPElXQJWbrQG4Id3XRBb3EbB1IC+FuLtqgS8zWgdgR8XYl8Qcu2CiAuDx3/Br22w5EPUMfx2wdCB8R71YyQS8RdiA8hLwfyQW9RNiB4RHyfiUb9BJhB4ZBzJs7+ONNC90+iRdFq2DjAvrBC57tWDTmUs9Bv3jdq9qx8dBgs2U2MqA7hHx4g83Qhwo7GxzQLkLevjqzcymAQy5DhJ2ND2iOkHejbsylCi+KmtmDkm6TtOLu1xXX/YWkP5b0v8XN7nX33bVHoTdetOxrA+GjA4DFEO/wVTnL5SFJn5f0yMT1n3X3v257QH2Gnajn59b1Bxrfx+5T21sYSRyIeL+azM6lCkF3971mtq3RUmroK+xEPV1txHvW/eYQdWLer6Yxl5qdh/4xM/sjSfsk3ePuJxqPZoodGw8RdVTSVcBXW1aqYSfmcar7oujfS3qXpOslLUv6m1k3NLOdZrbPzPadOnG61sKGPNUR4bt1/YFeYw60rY3ZuVRzhu7ux8rvzewfJX1lldsuSVqSpCuvu9jrLK/UxWEYflHEi4gjdm2FvFQr6Ga22d2Xi4u/K2l/e0OabzLCdQJPyONExJGCtkNeqnLa4mOSbpa00cyOSLpP0s1mdr0kl3RY0p90MrqKiHO6CPgw+njtKjddRXxclbNc7pxy9QN1FvZLa15N/sUk1Ee8kZo+Ij5usE9bHN95iXseCDZy0HfExwXx8bnM2tNEwOPGYZfqhoz4uCCCXsrlDRupIuDISSgRHxdU0CVm67Eh4shFiAGfFFzQS8zWw0bI85DzYZcYAj4p2KBLzNZDRczzklPUY4z4uKCDXiLs4SDmSEnsAZ8URdBLhH1YxDxfKc3SU4v4uKiCXpoWFiLfLWKOWKUc8ElRBn2aWcEh9M0Q8tly27ZinKXnFHMpoaDPQuiB9sQU9dxiLmUQ9Fk4bDMfs3PEKMeQl7IN+jSTAcs58MQcs4Q8S8855lL9v1iUhVz/Ek6O64z45R5ziaBXklPgclrXJnL+vzcprL9BcPDHm4h5gaBXlEPocljHNuQe81JIUccIx9AXwGe4g+c9LMzM34yg15TaWTLMzueL+fntypAvkBLzcxH0FjWJ4hCxIOLVEfPZhog6MZ+OoAeiblzrhIaQV0fIq+kz6sR8NoIeOeLcHWKO2BB0YAIhr6ePWTqz89URdKBAyJsL+V2kOSDogIh5DNqcnZ85euHr36+7/JXW7ndoBB3ZIuLdiG2WfubohclEnaAjK0Q8Xtdedoxj6HMQdCSNgA8jtll6Kgg6kkPEw0DU+0fQET0CDowQdESJiMeBWXq/CDqiQMCB+Qg6gkXE09DmLJ0zXVZH0BEE4p02Dr30g6BjEAQcdbU9S0/lTUUSQUdPCDhCsu7yV5J6h2iJoKMTBBxd4lj6dAQdjRFvVBHacfTUZucSQceCiDdCkcssffyTIech6JiJeCN0uUS9qrlBN7MHJd0macXdryuu2yDpcUnbJB2W9BF3P9HdMNEHAo6uhXbYpQ2rzaCbHtZZZHYuVZuhPyTp85IeGbtul6Q97n6/me0qLv/ZQkvGoIg3UjHULL1KbMvb9HW8fm7Q3X2vmW2buPp2STcX3z8s6esi6EEj4EA7Fp01j//MImGvs5y6x9A3ufuyJLn7spldOuuGZrZT0k5JunzL2pqLw6IIOHLS1yy9TmSn/fy8sNddTucvirr7kqQlSfq1d7/Fu15ejog30L2mMZ92X20fiqkb9GNmtrmYnW+WtNLmoHAuog2kZ1rYm/ziqBv0ZyTdJen+4uvTtUeA1xFtpK7LM1y6POzS5uy8y/uvctriYxq9ALrRzI5Iuk+jkD9hZndLeknSHa2MJgNEG0BXqpzlcueMf/pAy2OJHrEGZuvj/PMuZuldz87bxDtFKyLWAEJH0EWsga7F+u7QmGbnUsJBJ9LA8IYIec6f7xJ80AkzEJ9YZ+Sx6zXoPz17PoEGEkbIhxX8DB1AuEINeK6HXQg6gMpCDXhXyr89GguCDmCmmAOe4yydoAMZiznYfYlplk7QgQUQQISMoCMbxDg/bR12iWWWTtARFaIMzEbQ0QtCjKHkNEsn6GgN0QaGRdCxKiKN2OV06mJ0QV8kMDs2HupwJGEjxEBeMZcGDnrX0SFqQL5y/EMXvQb95TPnE1kA6MiaoQcAAG3L7VBLiaADSEquMZcIOoCE5BxzKcKzXIBF9LWDX3vZsV6WA6yGoCN6IczKJsdA4PsVwjYQgqCDvuiTxE6Uvlh2XALfrb63gxhOWZQCDHqTJ2raz7IjxSOWWNex2rqxjc4WwjYRS8ylQILe5ZPW5L7Z0doRwk4ZsiqPT+rbYqjbSEwxlwYKeqhP3qQ2x5naDhnLc5iKeY93SNtXCttGbCEv9Rr0V0+fl8STXUdMO6SUxk6ZE56v9sQacymQQy5ghwSGFnPISwQdQNZSCHmJoAPIUkohLxF0RK/vHXPd5a/0ujy0I9aAX3ik+ie0EHQEJ/Qdr8r4iP6wQt+Gqlok5lJkQQ/5SWIHribk57BNddaTbaia1LehRSM+Ltigx/ak5T5ri+35CtFqj2HK247E9tMk4uOCCHouT+a09YxpR83leQpRDBMGto/q2gr4pN6DzpP+ZvMej753Up6fePHchamreE/Ta9D9NH9PY1HspED4+oz2ahoF3cwOSzop6ReSzrj7+9oYFACEKJRwz9LGDP397n68hfsBgGCEHu9pgnhRFACGEGO0V9M06C7pq2bmkv7B3ZdaGBMA1JJaoBfVNOg3uftRM7tU0rNmdsjd947fwMx2StopSWsvuaTh4hCr3He0ql7ZenboIfSGbaJ9jYLu7keLrytm9pSkGyTtnbjNkqQlSXrrlVd4k+UNrY0NMNYdlp2vHzzOaKJ20M3sbZLWuPvJ4vsPSvpUayNrSWg7SGjjAZCOJjP0TZKeMrPyfh51939Z7QfW/JygAUBXagfd3X8g6T0tjgUA0ACnLQJAoNb/aLHX3Ag6AHRo0Sg3QdABoKI+41wHQQeQlNCj2yWCDqCxnCMaEoIOtICgIQS9Bn3t6Tc2/FNbOB99KMQHSNNgM/TxqBD32YgvgKqCOOSS66ydWANoUxBBL6UedgIOoEtBBb2UStgJOIA+BRn0UqxhJ+QAhhB00EsxhJ2IAxhaFEEvhRh2Qg4gFFEFvTR02Ik4gK5d9MOfLfwzUQa91FbYCTSAvtUJ9jxRB71EkAEMqYs415FE0AFgnlCi2yWCDiBKOQR6Ub0Gfc1rZ3XRD3+mk1dd0OdiAQSGGHdjkBl6+WQSdqAZwohxgx5yIezIFSFGF4I4hj6+cRN3DIHAIgVBBH0cs/a4EEIgHMEFvcSsPVxEHAhTsEEfR9yHR8SB8EUR9HEhhSWHXy4hPd4AVhdd0EMyL3axBp+IA3Ei6B2aDGPIgSfiQPwIeo+mRXPoyBNyIB0EfWB1gtrGLwFCDqSHoEeIGAOYhqBLWvf9H838tzPv2tLjSACgPoIuog0gDeH8tWUAQCO9ztDPvnXN1Bf0OCYMAM0Fcchl1lkbhP5ci5zhwuMH5CWIoM+SY+jbPC/95FUXJP1YAXizRkE3s1skfU7SWklfcPf7WxnVHKmEvo83FRF1IB+1g25mayX9naTflHRE0jfN7Bl3P9DW4BZVJZBDxG3od4MSdSAPTWboN0j6nrv/QJLM7J8k3S5psKBXMXRch0LUgfQ1OW1xi6T/Gbt8pLgOgcr1lxmQiyYzdJtynZ9zI7OdknYWF197/tFP7m+wzBhtlHR86EH0jHVOX27rKw27zr9c5UZNgn5E0hVjl7dKOjp5I3dfkrQkSWa2z93f12CZ0WGd85DbOue2vlIc69zkkMs3JV1tZleZ2Vsk/Z6kZ9oZFgBgUbVn6O5+xsw+JulfNTpt8UF3/25rIwMALKTReejuvlvS7gV+ZKnJ8iLFOucht3XObX2lCNbZ3M95HRMAECE+bREAEtFL0M3sFjP7TzP7npnt6mOZQzCzB81sxcz2j123wcyeNbP/Kr5eMuQY22RmV5jZ18zsoJl918w+Xlyf8jqfb2b/bmb/UazzXxbXX2Vmzxfr/HhxokBSzGytmX3HzL5SXE56nc3ssJm9aGYvmNm+4rqgt+3Ogz72EQG/JWm7pDvNbHvXyx3IQ5Jumbhul6Q97n61pD3F5VSckXSPu18r6UZJHy2e25TX+TVJO9z9PZKul3SLmd0o6a8kfbZY5xOS7h5wjF35uKSDY5dzWOf3u/v1Y6crBr1t9zFDf/0jAtz955LKjwhIjrvvlfR/E1ffLunh4vuHJX2o10F1yN2X3f3bxfcnNdrZtyjtdXZ3P1VcPK/4zyXtkPTPxfVJrbMkmdlWSb8t6QvFZVPi6zxD0Nt2H0HP/SMCNrn7sjQKoKRLBx5PJ8xsm6T3Snpeia9zcejhBUkrkp6V9H1JP3H3M8VNUtzG/1bSn0o6W1x+h9JfZ5f0VTP7VvGOdynwbbuPz0Ov9BEBiJeZrZf0JUmfcPeXR5O3dLn7LyRdb2Zvl/SUpGun3azfUXXHzG6TtOLu3zKzm8urp9w0mXUu3OTuR83sUknPmtmhoQc0Tx8z9EofEZCwY2a2WZKKrysDj6dVZnaeRjH/ors/WVyd9DqX3P0nkr6u0esHbzezcoKU2jZ+k6TfMbPDGh0y3aHRjD3ldZa7Hy2+rmj0i/sGBb5t9xH03D8i4BlJdxXf3yXp6QHH0qriOOoDkg66+2fG/inldX5nMTOXmV0g6Tc0eu3ga5I+XNwsqXV29z93963uvk2j/fc5d/99JbzOZvY2M7uo/F7SByXtV+Dbdi9vLDKzWzX6jV5+RMCnO1/oAMzsMUk3a/SpbMck3Sfpy5KekHSlpJck3eHuky+cRsnMfl3SNyS9qDeOrd6r0XH0VNf53Rq9GLZWownRE+7+KTP7FY1mrxskfUfSH7j7a8ONtBvFIZdPuvttKa9zsW5PFRfXSXrU3T9tZu9QwNs27xQFgETwTlEASARBB4BEEHQASARBB4BEEHQASARBB4BEEHQASARBB4BE/D+b10oRWP6DbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    print(t2m_exp.shape)\n",
    "    ax = plt.contourf(t2m_exp[443,:,:])\n",
    "    print(t2m_exp[443,:,:])\n",
    "    print(month_exp[0,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26267704 0.26046318 0.25661401 ... 0.22950646 0.22708498 0.22442972]\n",
      " [0.20302922 0.20179229 0.20073181 ... 0.23818486 0.23636252 0.23451899]\n",
      " [0.19524795 0.20810658 0.22415041 ... 0.25322432 0.25219251 0.25112267]\n",
      " ...\n",
      " [0.48474634 0.48954066 0.49081374 ... 0.36213768 0.336037   0.3028926 ]\n",
      " [0.49387301 0.5059012  0.52108218 ... 0.37193518 0.34423099 0.31239209]\n",
      " [0.52729484 0.54777388 0.5776589  ... 0.38700331 0.35481465 0.32946398]]\n",
      "(4, 24, 56)\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  pretest input shape  *********************')\n",
    "    x_input = np.stack((sic_exp_norm[1,:,:],\n",
    "                        t2m_exp_norm[1,:,:],\n",
    "                        ohc_exp_norm[1,:,:],\n",
    "                        month_exp[1,:,:]))\n",
    "    print(x_input[1,:,:])\n",
    "    print(x_input[:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure for LSTM <br>\n",
    "** We use Pytorth to implement LSTM neural network with time series of climate data. ** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  parameter for check  *********************\n",
      "*******************  create basic dimensions for tensor and network  *********************\n",
      "*******************  cross validation and testing data  *********************\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  parameter for check  *********************')\n",
    "    choice_exp_norm = ohc_exp_norm\n",
    "    print ('*******************  create basic dimensions for tensor and network  *********************')\n",
    "    # specifications of neural network\n",
    "    input_channels = 3\n",
    "    hidden_channels = [3, 2, 1] # number of channels & hidden layers, the channels of last layer is the channels of output, too\n",
    "    #hidden_channels = [3, 3, 3, 3, 2]\n",
    "    #hidden_channels = [2]\n",
    "    kernel_size = 3\n",
    "    # here we input a sequence and predict the next step only\n",
    "    #step = 1 # how many steps to predict ahead\n",
    "    #effective_step = [0] # step to output\n",
    "    batch_size = 1\n",
    "    #num_layers = 1\n",
    "    learning_rate = 0.01\n",
    "    num_epochs = 1500\n",
    "    print ('*******************  cross validation and testing data  *********************')\n",
    "    # take 10% data as cross-validation data\n",
    "    cross_valid_year = 4\n",
    "    # take 10% years as testing data\n",
    "    test_year = 4\n",
    "    # minibatch\n",
    "    #iterations = 3 # training data divided into 3 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  check the environment  *********************\n",
      "Pytorch version 1.1.0\n",
      "Is CUDA available? True\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  check the environment  *********************')\n",
    "    print (\"Pytorch version {}\".format(torch.__version__))\n",
    "    # check if CUDA is available\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(\"Is CUDA available? {}\".format(use_cuda))\n",
    "    # CUDA settings torch.__version__ must > 0.4\n",
    "    # !!! This is important for the model!!! The first option is gpu\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  preview of input tensor  *********************\n",
      "1824\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  preview of input tensor  *********************')\n",
    "    #plt.plot(SIC_ERAI_sum)\n",
    "    #print(SIC_ERAI_sum_norm[:-test_year*12])\n",
    "    #print(x_input.shape)\n",
    "    #print(x_input[:,:,:])\n",
    "    sequence_len, _, _ = sic_exp_norm.shape\n",
    "    print(sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print ('*******************  module for calculating accuracy  *********************')\n",
    "#     def accuracy(out, labels):\n",
    "#         outputs = np.argmax(out, axis=1)\n",
    "#     return np.sum(outputs==labels)/float(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  load exsited LSTM model  *********************\n",
      "BayesConvLSTM(\n",
      "  (cell0): BayesConvLSTMCell()\n",
      "  (cell1): BayesConvLSTMCell()\n",
      "  (cell2): BayesConvLSTMCell()\n",
      ")\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print ('*******************  load exsited LSTM model  *********************')\n",
    "    # load model parameters\n",
    "    model = dlacs.BayesConvLSTM.BayesConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(output_path, 'map_BayesConvLSTM_sic_ohc_Barents_hl_3_kernel_3_lr_0.01_epoch_1500_validSIC.pkl'),\n",
    "                                     map_location=device))\n",
    "    # load entire model\n",
    "    #model = torch.load(os.path.join(output_path, 'Barents','convlstm_era_sic_oras_ohc_Barents_hl_3_kernel_3_lr_0.005_epoch_1500_validSIC.pkl'))\n",
    "    print(model)\n",
    "    # check the sequence length (dimension in need for post-processing)\n",
    "    sequence_len, height, width = sic_exp_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  run BayesConvLSTM  *********************\n",
      "The model is designed to make many to one prediction.\n",
      "A series of multi-chanel variables will be input to the model.\n",
      "The model learns by verifying the output at each timestep.\n",
      "BayesConvLSTM(\n",
      "  (cell0): BayesConvLSTMCell()\n",
      "  (cell1): BayesConvLSTMCell()\n",
      "  (cell2): BayesConvLSTMCell()\n",
      ")\n",
      "ELBO(\n",
      "  (loss_function): MSELoss()\n",
      ")\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "    print ('*******************  run BayesConvLSTM  *********************')\n",
    "    print ('The model is designed to make many to one prediction.')\n",
    "    print ('A series of multi-chanel variables will be input to the model.')\n",
    "    print ('The model learns by verifying the output at each timestep.')\n",
    "    # check the sequence length\n",
    "    sequence_len, height, width = sic_exp_norm.shape\n",
    "    # initialize our model\n",
    "    model = dlacs.BayesConvLSTM.BayesConvLSTM(input_channels, hidden_channels, kernel_size).to(device)\n",
    "    # use Evidence Lower Bound (ELBO) to quantify the loss\n",
    "    ELBO = dlacs.function.ELBO(height*width)\n",
    "    # for classification, target must be integers (label)\n",
    "    #ELBO = dlacs.function.ELBO(height*width,loss_function=torch.nn.KLDivLoss())\n",
    "    #ELBO = dlacs.function.ELBO(height*width,loss_function=nn.CrossEntropyLoss(reduction='mean'))\n",
    "    #ELBO = dlacs.function.ELBO(height*width,loss_function=nn.NLLLoss(reduction='mean'))\n",
    "    # penalty for kl\n",
    "    penalty_kl = sequence_len\n",
    "    # stochastic gradient descent\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    # Adam optimizer\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(model)\n",
    "    print(ELBO)\n",
    "    print(optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell0.Wxi_mu\n",
      "tensor([[[[ 0.1493, -0.1049, -0.1169],\n",
      "          [ 0.1776,  0.1855,  0.1521],\n",
      "          [-0.1421, -0.0015, -0.1056]],\n",
      "\n",
      "         [[ 0.1557,  0.1495,  0.0020],\n",
      "          [ 0.0067, -0.1735, -0.0694],\n",
      "          [-0.1377,  0.0168, -0.0152]],\n",
      "\n",
      "         [[ 0.0997,  0.1372, -0.1340],\n",
      "          [-0.1373, -0.1903, -0.1407],\n",
      "          [-0.0639,  0.1652, -0.0235]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721,  0.1496,  0.0010],\n",
      "          [-0.0476, -0.1298, -0.0505],\n",
      "          [-0.0263,  0.0179,  0.1862]],\n",
      "\n",
      "         [[-0.1127, -0.1066,  0.1058],\n",
      "          [-0.0141,  0.0440, -0.0584],\n",
      "          [ 0.1735,  0.1856, -0.0975]],\n",
      "\n",
      "         [[ 0.1118,  0.0193, -0.0664],\n",
      "          [-0.1332,  0.0209, -0.1522],\n",
      "          [-0.0414, -0.1464, -0.0622]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1902, -0.1409,  0.0700],\n",
      "          [ 0.1098, -0.0669,  0.0604],\n",
      "          [-0.0547,  0.1620,  0.0425]],\n",
      "\n",
      "         [[ 0.1181, -0.0449,  0.1699],\n",
      "          [ 0.0937,  0.0864,  0.1234],\n",
      "          [-0.0494,  0.0644,  0.0339]],\n",
      "\n",
      "         [[ 0.0069,  0.1626,  0.0623],\n",
      "          [-0.0742,  0.1265,  0.1418],\n",
      "          [ 0.1491,  0.0560, -0.1880]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Whi_mu\n",
      "tensor([[[[ 0.0943, -0.0618,  0.0797],\n",
      "          [-0.0430, -0.0727, -0.1816],\n",
      "          [-0.1410, -0.1445,  0.0432]],\n",
      "\n",
      "         [[ 0.0119, -0.1841, -0.0734],\n",
      "          [-0.1838,  0.0786,  0.1563],\n",
      "          [-0.0471, -0.1161, -0.1679]],\n",
      "\n",
      "         [[ 0.1086, -0.1344,  0.0204],\n",
      "          [ 0.1545,  0.0574,  0.1315],\n",
      "          [ 0.0863, -0.0402,  0.0332]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0098,  0.1127,  0.0432],\n",
      "          [ 0.0291,  0.0218,  0.0684],\n",
      "          [ 0.1294, -0.1548,  0.1449]],\n",
      "\n",
      "         [[ 0.0238, -0.1669,  0.0645],\n",
      "          [-0.1697, -0.1497, -0.1285],\n",
      "          [-0.0152,  0.1681, -0.0140]],\n",
      "\n",
      "         [[ 0.1345, -0.1517, -0.0248],\n",
      "          [ 0.1183, -0.0202,  0.1807],\n",
      "          [-0.0385,  0.1139,  0.0602]]],\n",
      "\n",
      "\n",
      "        [[[-0.0681,  0.0621, -0.0711],\n",
      "          [ 0.1771,  0.1853, -0.1669],\n",
      "          [-0.0411, -0.0277,  0.1600]],\n",
      "\n",
      "         [[ 0.0728, -0.0575,  0.1363],\n",
      "          [ 0.0503,  0.0707, -0.0393],\n",
      "          [-0.0044, -0.1167,  0.1602]],\n",
      "\n",
      "         [[ 0.1890,  0.0799, -0.0004],\n",
      "          [-0.0341,  0.0371, -0.1021],\n",
      "          [ 0.0254,  0.0526,  0.0342]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf_mu\n",
      "tensor([[[[ 0.0529,  0.0488, -0.0763],\n",
      "          [-0.1061,  0.0763,  0.0918],\n",
      "          [-0.1215, -0.0140,  0.1834]],\n",
      "\n",
      "         [[ 0.0044,  0.0120,  0.0523],\n",
      "          [-0.0025,  0.1160, -0.1126],\n",
      "          [-0.1063, -0.1221, -0.0826]],\n",
      "\n",
      "         [[-0.1090,  0.1185,  0.0739],\n",
      "          [-0.0332,  0.0369,  0.1404],\n",
      "          [ 0.0206,  0.0651,  0.1562]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0554,  0.0978, -0.1583],\n",
      "          [ 0.0848,  0.0630,  0.0236],\n",
      "          [ 0.0692,  0.1459,  0.0237]],\n",
      "\n",
      "         [[-0.0580,  0.0711, -0.0153],\n",
      "          [-0.1030, -0.0884, -0.0199],\n",
      "          [ 0.0151, -0.1518,  0.1646]],\n",
      "\n",
      "         [[ 0.0560, -0.0462, -0.1584],\n",
      "          [ 0.1502, -0.1883, -0.0788],\n",
      "          [ 0.1384,  0.0233,  0.1365]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0695, -0.1715, -0.1603],\n",
      "          [-0.0599,  0.1144, -0.1495],\n",
      "          [ 0.0161,  0.0780,  0.1536]],\n",
      "\n",
      "         [[ 0.1006,  0.0766, -0.1521],\n",
      "          [ 0.1192,  0.1713,  0.0780],\n",
      "          [ 0.0730, -0.0692,  0.0669]],\n",
      "\n",
      "         [[ 0.0848,  0.0107,  0.1822],\n",
      "          [-0.1739,  0.1501,  0.1200],\n",
      "          [ 0.0400,  0.0832,  0.0172]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Whf_mu\n",
      "tensor([[[[ 0.1186,  0.0139,  0.0497],\n",
      "          [ 0.1075,  0.0766, -0.1387],\n",
      "          [-0.1570,  0.0355, -0.0293]],\n",
      "\n",
      "         [[ 0.1522,  0.0915,  0.1154],\n",
      "          [-0.0621,  0.1435, -0.1606],\n",
      "          [-0.1780,  0.0797,  0.0165]],\n",
      "\n",
      "         [[ 0.1155, -0.1760,  0.1215],\n",
      "          [ 0.1203,  0.1176,  0.1607],\n",
      "          [ 0.0506,  0.0742, -0.1713]]],\n",
      "\n",
      "\n",
      "        [[[-0.1822,  0.1882, -0.0988],\n",
      "          [ 0.0626, -0.1128,  0.0954],\n",
      "          [ 0.1353,  0.1517,  0.1830]],\n",
      "\n",
      "         [[-0.1166, -0.1028, -0.1198],\n",
      "          [ 0.0754,  0.1441,  0.1353],\n",
      "          [-0.0968, -0.1784, -0.0469]],\n",
      "\n",
      "         [[-0.0597,  0.1524,  0.0483],\n",
      "          [ 0.0824,  0.1786, -0.0922],\n",
      "          [ 0.0832, -0.1387, -0.1318]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1516, -0.0926, -0.0308],\n",
      "          [-0.0904,  0.0345,  0.0801],\n",
      "          [-0.0191, -0.0237,  0.1849]],\n",
      "\n",
      "         [[-0.1693, -0.0538, -0.0074],\n",
      "          [ 0.1452,  0.0168, -0.0507],\n",
      "          [ 0.0187, -0.0094, -0.1043]],\n",
      "\n",
      "         [[-0.1174,  0.1289,  0.1857],\n",
      "          [-0.0692, -0.0909,  0.0727],\n",
      "          [ 0.1554,  0.1605, -0.0100]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc_mu\n",
      "tensor([[[[-0.1144,  0.1685,  0.0667],\n",
      "          [ 0.0159, -0.0466, -0.0374],\n",
      "          [-0.1501, -0.0329, -0.1239]],\n",
      "\n",
      "         [[ 0.1152, -0.1776,  0.0955],\n",
      "          [-0.0496,  0.0114, -0.1283],\n",
      "          [ 0.0137,  0.0954, -0.0234]],\n",
      "\n",
      "         [[-0.0157,  0.0647,  0.0772],\n",
      "          [ 0.1770,  0.1269,  0.0513],\n",
      "          [-0.1160, -0.1546,  0.1804]]],\n",
      "\n",
      "\n",
      "        [[[-0.1479, -0.0817, -0.0773],\n",
      "          [ 0.1854, -0.1648,  0.0270],\n",
      "          [ 0.1418,  0.1885,  0.0063]],\n",
      "\n",
      "         [[ 0.0779,  0.0995, -0.0484],\n",
      "          [ 0.0014,  0.1479, -0.0018],\n",
      "          [-0.1452, -0.1913, -0.0882]],\n",
      "\n",
      "         [[ 0.1778, -0.1899, -0.1603],\n",
      "          [-0.0322, -0.1416,  0.0850],\n",
      "          [-0.0075, -0.0814,  0.1151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1861, -0.1412, -0.1351],\n",
      "          [-0.0244, -0.0375,  0.1700],\n",
      "          [ 0.1631,  0.0307, -0.0997]],\n",
      "\n",
      "         [[-0.1665,  0.1365, -0.1786],\n",
      "          [-0.0210, -0.0599,  0.0596],\n",
      "          [-0.0993, -0.0179, -0.1378]],\n",
      "\n",
      "         [[ 0.0926,  0.0709,  0.0793],\n",
      "          [ 0.0122,  0.0177,  0.0150],\n",
      "          [ 0.0739, -0.0565, -0.1169]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Whc_mu\n",
      "tensor([[[[-0.0167,  0.1517, -0.0837],\n",
      "          [ 0.1230, -0.0482,  0.0758],\n",
      "          [-0.1686,  0.1301,  0.0118]],\n",
      "\n",
      "         [[-0.0972,  0.0184, -0.0601],\n",
      "          [ 0.1602,  0.0266, -0.1751],\n",
      "          [ 0.1907,  0.0927, -0.1915]],\n",
      "\n",
      "         [[-0.1710, -0.1479, -0.0086],\n",
      "          [-0.1717,  0.1600, -0.0442],\n",
      "          [ 0.1552, -0.0994, -0.0114]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0863, -0.0452,  0.1198],\n",
      "          [ 0.0141, -0.1567, -0.0532],\n",
      "          [-0.1526, -0.0263,  0.0229]],\n",
      "\n",
      "         [[ 0.1503, -0.1243,  0.0609],\n",
      "          [ 0.0490,  0.0235,  0.0720],\n",
      "          [ 0.0997,  0.0112, -0.0067]],\n",
      "\n",
      "         [[ 0.1627, -0.1359, -0.0795],\n",
      "          [ 0.1877, -0.1321,  0.0421],\n",
      "          [ 0.0951,  0.0596, -0.0202]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0915, -0.1617, -0.1465],\n",
      "          [ 0.0180,  0.0091,  0.0032],\n",
      "          [ 0.0748, -0.1514,  0.1671]],\n",
      "\n",
      "         [[-0.1893,  0.1789,  0.0887],\n",
      "          [ 0.0397,  0.0134, -0.1189],\n",
      "          [-0.1031,  0.0484, -0.1863]],\n",
      "\n",
      "         [[ 0.1413,  0.0117, -0.0525],\n",
      "          [ 0.0075, -0.1897, -0.0993],\n",
      "          [-0.1217,  0.0763,  0.0619]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo_mu\n",
      "tensor([[[[-0.0675,  0.1405,  0.1330],\n",
      "          [-0.0378,  0.1048,  0.0601],\n",
      "          [-0.1179,  0.0879, -0.1830]],\n",
      "\n",
      "         [[-0.0719, -0.0099,  0.1278],\n",
      "          [-0.1582,  0.1561, -0.0957],\n",
      "          [-0.0884, -0.0496, -0.1363]],\n",
      "\n",
      "         [[ 0.1036,  0.0794,  0.0290],\n",
      "          [ 0.0429,  0.1842,  0.1805],\n",
      "          [ 0.1833, -0.0150, -0.1098]]],\n",
      "\n",
      "\n",
      "        [[[-0.0263,  0.0722, -0.0027],\n",
      "          [ 0.1116,  0.1696,  0.0375],\n",
      "          [-0.1582,  0.0007,  0.0335]],\n",
      "\n",
      "         [[-0.0961, -0.0778, -0.0690],\n",
      "          [ 0.0676, -0.1596,  0.0640],\n",
      "          [-0.0434,  0.0016, -0.0850]],\n",
      "\n",
      "         [[-0.0902,  0.0285, -0.0849],\n",
      "          [ 0.1606, -0.1409,  0.0443],\n",
      "          [-0.0495, -0.1075, -0.0753]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0951,  0.0563, -0.1821],\n",
      "          [ 0.0858, -0.1189, -0.0485],\n",
      "          [ 0.1797,  0.0428,  0.0584]],\n",
      "\n",
      "         [[-0.1257,  0.0316,  0.1343],\n",
      "          [ 0.0625,  0.0306, -0.1583],\n",
      "          [-0.1785, -0.1006, -0.1821]],\n",
      "\n",
      "         [[ 0.1594,  0.1502, -0.0355],\n",
      "          [-0.0148,  0.1676,  0.0492],\n",
      "          [-0.1662, -0.0341,  0.0423]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Who_mu\n",
      "tensor([[[[ 0.0520, -0.0368,  0.0024],\n",
      "          [ 0.0525,  0.1255, -0.0208],\n",
      "          [-0.1432, -0.1784, -0.1576]],\n",
      "\n",
      "         [[-0.1748,  0.0714, -0.0655],\n",
      "          [ 0.0756,  0.0334, -0.1420],\n",
      "          [ 0.1909,  0.0085,  0.1026]],\n",
      "\n",
      "         [[ 0.0702,  0.1882,  0.1884],\n",
      "          [-0.0546, -0.0775,  0.1705],\n",
      "          [-0.0773, -0.0141, -0.1411]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0776,  0.1607,  0.0301],\n",
      "          [-0.0045, -0.0455,  0.1418],\n",
      "          [ 0.0649,  0.0412,  0.0221]],\n",
      "\n",
      "         [[-0.0181, -0.1723,  0.0777],\n",
      "          [-0.0614,  0.1696,  0.1597],\n",
      "          [ 0.1724, -0.0720, -0.1907]],\n",
      "\n",
      "         [[ 0.1352,  0.0950,  0.1500],\n",
      "          [ 0.0501,  0.1724, -0.0706],\n",
      "          [-0.0071,  0.0999,  0.0135]]],\n",
      "\n",
      "\n",
      "        [[[-0.0395, -0.0859, -0.1390],\n",
      "          [ 0.0481, -0.0477, -0.1768],\n",
      "          [-0.1009,  0.1263, -0.0669]],\n",
      "\n",
      "         [[-0.0804, -0.1278, -0.0673],\n",
      "          [ 0.0233, -0.0712,  0.1348],\n",
      "          [-0.0195,  0.0460, -0.1370]],\n",
      "\n",
      "         [[-0.0492,  0.0632, -0.1242],\n",
      "          [ 0.0820, -0.1330,  0.0291],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [ 0.0852,  0.1078,  0.1185]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxi_bias\n",
      "tensor([ 0.0244, -0.0210, -0.1620], device='cuda:0')\n",
      "torch.Size([3])\n",
      "=========================\n",
      "cell0.Wxf_bias\n",
      "tensor([-0.0954, -0.1107,  0.0890], device='cuda:0')\n",
      "torch.Size([3])\n",
      "=========================\n",
      "cell0.Wxc_bias\n",
      "tensor([0.0300, 0.1512, 0.0764], device='cuda:0')\n",
      "torch.Size([3])\n",
      "=========================\n",
      "cell0.Wxo_bias\n",
      "tensor([ 0.1602,  0.1820, -0.0192], device='cuda:0')\n",
      "torch.Size([3])\n",
      "=========================\n",
      "cell0.Wxi_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Whi_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxf_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Whf_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxc_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Whc_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Wxo_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell0.Who_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([3, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Wxi_mu\n",
      "tensor([[[[ 0.0153, -0.1697, -0.1408],\n",
      "          [-0.0018,  0.1373,  0.1711],\n",
      "          [ 0.1192, -0.1612,  0.0700]],\n",
      "\n",
      "         [[-0.0091, -0.0574,  0.1363],\n",
      "          [-0.0141, -0.1873,  0.1533],\n",
      "          [ 0.1372, -0.1521, -0.0765]],\n",
      "\n",
      "         [[ 0.0208,  0.0590, -0.1515],\n",
      "          [ 0.1337,  0.0236, -0.1866],\n",
      "          [ 0.0156, -0.1356, -0.1883]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1474, -0.1821, -0.0268],\n",
      "          [-0.0777, -0.0743, -0.1699],\n",
      "          [-0.1676,  0.1855,  0.1730]],\n",
      "\n",
      "         [[ 0.0886, -0.1258,  0.0275],\n",
      "          [ 0.1652,  0.1600,  0.1263],\n",
      "          [ 0.0711, -0.1183,  0.1697]],\n",
      "\n",
      "         [[-0.0287, -0.0614,  0.0008],\n",
      "          [-0.1069, -0.0204, -0.1324],\n",
      "          [ 0.1212, -0.0731,  0.1649]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Whi_mu\n",
      "tensor([[[[ 1.5725e-01, -1.5141e-01,  1.0610e-01],\n",
      "          [ 1.4651e-01,  1.0527e-01,  6.6280e-02],\n",
      "          [ 6.5894e-02,  8.3149e-02,  6.5683e-02]],\n",
      "\n",
      "         [[-1.5793e-01, -1.2864e-01, -1.5801e-02],\n",
      "          [ 1.5704e-04,  1.6164e-02,  2.2879e-02],\n",
      "          [ 8.3902e-02, -1.5618e-01,  1.8773e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.6246e-02, -1.5021e-01, -6.3143e-02],\n",
      "          [-9.2234e-02,  1.9045e-01,  1.1672e-02],\n",
      "          [ 1.6120e-01,  1.3705e-01, -1.4065e-01]],\n",
      "\n",
      "         [[-3.6743e-02,  1.7553e-01, -5.0262e-02],\n",
      "          [ 1.8370e-01, -3.7199e-02,  8.1537e-02],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [-9.1147e-02, -2.8623e-02,  1.0912e-02]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxf_mu\n",
      "tensor([[[[-0.0750, -0.1233, -0.1644],\n",
      "          [ 0.1721,  0.0521,  0.0610],\n",
      "          [-0.1810,  0.1158,  0.1859]],\n",
      "\n",
      "         [[ 0.1627,  0.1428,  0.0907],\n",
      "          [ 0.1298,  0.1200,  0.1550],\n",
      "          [ 0.1307,  0.0186, -0.0026]],\n",
      "\n",
      "         [[ 0.1204, -0.1486, -0.0690],\n",
      "          [-0.1370,  0.1229, -0.1739],\n",
      "          [-0.0768, -0.0490,  0.0715]]],\n",
      "\n",
      "\n",
      "        [[[-0.0983,  0.0342, -0.1559],\n",
      "          [ 0.1660,  0.1632, -0.0618],\n",
      "          [ 0.1091, -0.1851, -0.0794]],\n",
      "\n",
      "         [[-0.0923,  0.0473,  0.0742],\n",
      "          [ 0.1295,  0.0118, -0.1301],\n",
      "          [-0.0101, -0.0680,  0.0549]],\n",
      "\n",
      "         [[-0.0614, -0.0265, -0.0590],\n",
      "          [-0.0661, -0.1230,  0.1369],\n",
      "          [ 0.1550, -0.0711,  0.1566]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Whf_mu\n",
      "tensor([[[[ 0.0253, -0.0917, -0.0742],\n",
      "          [-0.0364, -0.1231,  0.1785],\n",
      "          [ 0.0222, -0.0949,  0.0741]],\n",
      "\n",
      "         [[ 0.1053,  0.0408,  0.1191],\n",
      "          [ 0.0366, -0.1775, -0.1065],\n",
      "          [ 0.0329, -0.0630, -0.1110]]],\n",
      "\n",
      "\n",
      "        [[[-0.1537,  0.1082,  0.0339],\n",
      "          [ 0.1559,  0.0693, -0.0929],\n",
      "          [ 0.1319, -0.1816, -0.1802]],\n",
      "\n",
      "         [[ 0.0203, -0.0148, -0.1070],\n",
      "          [ 0.1033, -0.1077, -0.1662],\n",
      "          [-0.1251, -0.1069,  0.0066]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxc_mu\n",
      "tensor([[[[-0.0434, -0.1419, -0.1102],\n",
      "          [ 0.0150,  0.1412, -0.0442],\n",
      "          [-0.0090, -0.1363, -0.1249]],\n",
      "\n",
      "         [[-0.1245,  0.1724, -0.0358],\n",
      "          [ 0.1041, -0.1257, -0.1063],\n",
      "          [ 0.0163,  0.1798,  0.0772]],\n",
      "\n",
      "         [[ 0.0126,  0.1609,  0.0686],\n",
      "          [-0.1050, -0.1053, -0.1053],\n",
      "          [ 0.1861,  0.1552,  0.0131]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1576,  0.1289, -0.1330],\n",
      "          [-0.1539,  0.0155, -0.0742],\n",
      "          [ 0.0325, -0.0673,  0.1317]],\n",
      "\n",
      "         [[-0.1007,  0.0573, -0.0160],\n",
      "          [-0.0513, -0.0013,  0.0910],\n",
      "          [-0.0945, -0.0551,  0.0206]],\n",
      "\n",
      "         [[-0.1884, -0.1425, -0.0735],\n",
      "          [-0.0411, -0.1481,  0.0884],\n",
      "          [-0.1459, -0.0706,  0.0293]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Whc_mu\n",
      "tensor([[[[-0.0489, -0.0747,  0.0337],\n",
      "          [-0.1042, -0.0180, -0.0206],\n",
      "          [-0.1352,  0.1294,  0.0486]],\n",
      "\n",
      "         [[ 0.0248,  0.1089, -0.1804],\n",
      "          [-0.1560, -0.1680, -0.0375],\n",
      "          [ 0.0186, -0.0330,  0.1823]]],\n",
      "\n",
      "\n",
      "        [[[-0.0897, -0.0081, -0.0786],\n",
      "          [ 0.0870,  0.0059,  0.0102],\n",
      "          [-0.1446, -0.1287, -0.0491]],\n",
      "\n",
      "         [[-0.0193, -0.0828,  0.1796],\n",
      "          [-0.1801,  0.1136,  0.1269],\n",
      "          [-0.1335,  0.1373,  0.1899]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxo_mu\n",
      "tensor([[[[-0.1127,  0.0689,  0.1345],\n",
      "          [ 0.0955,  0.0250, -0.0166],\n",
      "          [ 0.0465, -0.1274,  0.0696]],\n",
      "\n",
      "         [[ 0.0933, -0.0989,  0.1041],\n",
      "          [ 0.0952,  0.1832, -0.1408],\n",
      "          [-0.0266, -0.1675,  0.0304]],\n",
      "\n",
      "         [[ 0.0929,  0.0130, -0.1815],\n",
      "          [-0.0729,  0.1343,  0.0883],\n",
      "          [ 0.0105,  0.0499,  0.0671]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0998, -0.1112,  0.1096],\n",
      "          [ 0.0093, -0.1162, -0.0683],\n",
      "          [-0.1299, -0.0935,  0.0091]],\n",
      "\n",
      "         [[-0.0130,  0.1409,  0.1021],\n",
      "          [-0.0292, -0.1551,  0.1628],\n",
      "          [-0.0991,  0.0413,  0.1188]],\n",
      "\n",
      "         [[ 0.1455, -0.0684,  0.0630],\n",
      "          [ 0.1893,  0.0588, -0.0878],\n",
      "          [ 0.1177,  0.0469,  0.1342]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Who_mu\n",
      "tensor([[[[-0.0563,  0.1800,  0.1245],\n",
      "          [ 0.1214,  0.1842,  0.0417],\n",
      "          [ 0.1242,  0.1760,  0.0329]],\n",
      "\n",
      "         [[-0.1828, -0.1645, -0.1716],\n",
      "          [-0.0341,  0.1467,  0.0114],\n",
      "          [-0.0983,  0.0603,  0.0631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1008, -0.0627,  0.1410],\n",
      "          [ 0.1726, -0.1381, -0.1629],\n",
      "          [-0.0720, -0.1646,  0.1809]],\n",
      "\n",
      "         [[ 0.0404, -0.0778, -0.1600],\n",
      "          [-0.0935, -0.0441,  0.1502],\n",
      "          [-0.0313,  0.1797, -0.0896]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxi_bias\n",
      "tensor([-0.1438,  0.0661], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell1.Wxf_bias\n",
      "tensor([-0.0901,  0.1862], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell1.Wxc_bias\n",
      "tensor([0.1720, 0.1647], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell1.Wxo_bias\n",
      "tensor([0.0403, 0.0881], device='cuda:0')\n",
      "torch.Size([2])\n",
      "=========================\n",
      "cell1.Wxi_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Whi_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxf_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Whf_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxc_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n",
      "=========================\n",
      "cell1.Whc_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell1.Wxo_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 3, 3, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "cell1.Who_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]],\n",
      "\n",
      "\n",
      "        [[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([2, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Wxi_mu\n",
      "tensor([[[[-0.1891, -0.2187,  0.1254],\n",
      "          [-0.0066,  0.1957,  0.1143],\n",
      "          [-0.2314, -0.0861, -0.1239]],\n",
      "\n",
      "         [[ 0.0534, -0.2034,  0.0671],\n",
      "          [-0.0413,  0.0302,  0.0005],\n",
      "          [ 0.0208, -0.0249, -0.1375]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Whi_mu\n",
      "tensor([[[[ 0.0369,  0.0665,  0.0651],\n",
      "          [ 0.0183, -0.0760, -0.0385],\n",
      "          [ 0.0755,  0.2185, -0.1084]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxf_mu\n",
      "tensor([[[[-0.0874, -0.1304,  0.1828],\n",
      "          [-0.1038, -0.0547,  0.1788],\n",
      "          [-0.1218, -0.0223, -0.2084]],\n",
      "\n",
      "         [[-0.1201,  0.2297,  0.1716],\n",
      "          [-0.2000,  0.0129, -0.0687],\n",
      "          [ 0.2140,  0.1798,  0.1413]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Whf_mu\n",
      "tensor([[[[ 0.1692,  0.2130, -0.0684],\n",
      "          [ 0.1350,  0.1418,  0.1328],\n",
      "          [ 0.1701, -0.1257,  0.2081]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxc_mu\n",
      "tensor([[[[ 0.1194, -0.1790,  0.2335],\n",
      "          [-0.0033, -0.1539,  0.0183],\n",
      "          [ 0.1143, -0.0585, -0.1081]],\n",
      "\n",
      "         [[ 0.1192, -0.2123,  0.1829],\n",
      "          [-0.1877,  0.2216,  0.2267],\n",
      "          [-0.1320, -0.1235,  0.2071]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Whc_mu\n",
      "tensor([[[[-0.0419, -0.1004, -0.0980],\n",
      "          [ 0.0015, -0.1917, -0.1346],\n",
      "          [-0.0504,  0.0411, -0.0626]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxo_mu\n",
      "tensor([[[[-0.0387,  0.0151, -0.0860],\n",
      "          [-0.1617,  0.1361, -0.0197],\n",
      "          [-0.1590, -0.1881,  0.0695]],\n",
      "\n",
      "         [[ 0.0897,  0.1031, -0.0177],\n",
      "          [ 0.2062,  0.2150,  0.0485],\n",
      "          [-0.0886,  0.1134, -0.0364]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Who_mu\n",
      "tensor([[[[ 0.2062,  0.0647,  0.1758],\n",
      "          [-0.1875, -0.1103,  0.0614],\n",
      "          [-0.0664,  0.0972, -0.1035]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxi_bias\n",
      "tensor([-0.1819], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell2.Wxf_bias\n",
      "tensor([-0.0583], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell2.Wxc_bias\n",
      "tensor([0.0530], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell2.Wxo_bias\n",
      "tensor([0.0031], device='cuda:0')\n",
      "torch.Size([1])\n",
      "=========================\n",
      "cell2.Wxi_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Whi_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxf_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Whf_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxc_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Whc_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n",
      "cell2.Wxo_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]],\n",
      "\n",
      "         [[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 2, 3, 3])\n",
      "=========================\n",
      "cell2.Who_log_var\n",
      "tensor([[[[-3., -3., -3.],\n",
      "          [-3., -3., -3.],\n",
      "          [-3., -3., -3.]]]], device='cuda:0')\n",
      "torch.Size([1, 1, 3, 3])\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print (name)\n",
    "            print (param.data)\n",
    "            print (param.size())\n",
    "            print (\"=========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "#############  preview model parameters matrix  ###############\n",
      "##############################################################\n",
      "Number of parameter matrices:  60\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([2, 3, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n",
      "torch.Size([1, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "    print('##############################################################')\n",
    "    print('#############  preview model parameters matrix  ###############')\n",
    "    print('##############################################################')\n",
    "    print('Number of parameter matrices: ', len(list(model.parameters())))\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################################################\n",
      "##################  start training loop  #####################\n",
      "##############################################################\n",
      "Epoch  0 MSE:  79923.5234375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    print('##############################################################')\n",
    "    print('##################  start training loop  #####################')\n",
    "    print('##############################################################')\n",
    "    # track training loss\n",
    "    hist = np.zeros(num_epochs)\n",
    "    # loop of epoch\n",
    "    for t in range(num_epochs):\n",
    "        # Clear stored gradient\n",
    "        model.zero_grad()\n",
    "        # loop of timestep\n",
    "        for timestep in range(sequence_len - cross_valid_year*12*4 - test_year*12*4):\n",
    "            # hidden state re-initialized inside the model when timestep=0\n",
    "            #################################################################################\n",
    "            ########          create input tensor with multi-input dimension         ########\n",
    "            #################################################################################\n",
    "            # create variables\n",
    "            x_input = np.stack((sic_exp_norm[timestep,:,:],\n",
    "                                choice_exp_norm[timestep,:,:],\n",
    "                                month_exp[timestep,:,:])) #vstack,hstack,dstack\n",
    "            x_var = torch.autograd.Variable(torch.Tensor(x_input).view(-1,input_channels,height,width)).to(device)\n",
    "            #################################################################################\n",
    "            ########       create training tensor with multi-input dimension         ########\n",
    "            #################################################################################\n",
    "            y_train_stack = sic_exp_norm[timestep+1,:,:] #vstack,hstack,dstack\n",
    "            y_var = torch.autograd.Variable(torch.Tensor(y_train_stack).view(-1,hidden_channels[-1],height,width)).to(device)\n",
    "            #################################################################################   \n",
    "            # Forward pass\n",
    "            y_pred, kl_loss, _ = model(x_var, timestep)\n",
    "            # choose training data\n",
    "            y_target = y_var\n",
    "            # torch.nn.functional.mse_loss(y_pred, y_train) can work with (scalar,vector) & (vector,vector)\n",
    "            # Please Make Sure y_pred & y_train have the same dimension\n",
    "            # accumulate loss\n",
    "            if timestep == 0:\n",
    "                loss = ELBO(y_pred, y_target, kl_loss, 1 / (len(hidden_channels) * 8 * penalty_kl * kernel_size**2))\n",
    "            else:\n",
    "                loss += ELBO(y_pred, y_target, kl_loss, 1 / (len(hidden_channels) * 8 * penalty_kl * kernel_size**2))\n",
    "            #print (timestep)\n",
    "        #print(y_pred.shape)\n",
    "        #print(y_train.shape)\n",
    "        # print loss at certain iteration\n",
    "        if t % 5 == 0:\n",
    "            print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "            #print(y_pred)\n",
    "            # gradient check\n",
    "            # Gradcheck requires double precision numbers to run\n",
    "            #res = torch.autograd.gradcheck(loss_fn, (y_pred.double(), y_train.double()), eps=1e-6, raise_exception=True)\n",
    "            #print(res)\n",
    "        hist[t] = loss.item()\n",
    "\n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "    # save the model\n",
    "    # (recommended) save the model parameters only\n",
    "    torch.save(model.state_dict(), os.path.join(output_path,'bayesconvlstm.pkl'))\n",
    "    # save the entire model\n",
    "    # torch.save(model, os.path.join(output_path,'bayesconvlstm.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  Loss with time  **********************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    print (\"*******************  Loss with time  **********************\")\n",
    "    fig00 = plt.figure()\n",
    "    try:\n",
    "        plt.plot(hist, label=\"Training loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        fig00.savefig(os.path.join(output_path,'SIC_ERAI_LSTM_pred_error.png'),dpi=200)\n",
    "    except:\n",
    "        print('Model is reloaded instead of trained!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
